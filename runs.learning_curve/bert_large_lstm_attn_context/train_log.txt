Using configurations:
{'BATCH_ITEM_NUM': 30,
 'BERT_LARGE': True,
 'BERT_LAYER': 11,
 'CONFIG_NAME': 'bert_large_lstm_attn_context',
 'CROSS_VALIDATION_FLAG': True,
 'CUDA': True,
 'ELMO_LAYER': 2,
 'ELMO_MODE': 'concat',
 'EXPERIMENT_NAME': 'bert_large_lstm_attn_context',
 'GLOVE_DIM': 100,
 'GPU_NUM': 1,
 'IS_BERT': True,
 'IS_ELMO': False,
 'IS_RANDOM': False,
 'KFOLDS': 5,
 'LSTM': {'ATTN': True,
          'BIDIRECTION': True,
          'DROP_PROB': 0.1,
          'FLAG': True,
          'HIDDEN_DIM': 800,
          'LAYERS': 2,
          'SEQ_LEN': 30},
 'MODE': 'train',
 'OUT_PATH': '/jagupard22/scr1/sebschu/runs.h800/',
 'PREDICTION_TYPE': 'rating',
 'PREDON': 'train',
 'RESUME_DIR': '',
 'SAVE_PREDS': False,
 'SEED': 0,
 'SINGLE_SENTENCE': False,
 'SOME_DATABASE': './some_database.csv',
 'SPLIT_NAME': '',
 'TRAIN': {'BATCH_SIZE': 32,
           'COEFF': {'BETA_1': 0.9, 'BETA_2': 0.999, 'EPS': 1e-08},
           'DROPOUT': {'FC_1': 0.2, 'FC_2': 0.2},
           'FLAG': True,
           'INTERVAL': 10,
           'LR': 0.001,
           'LR_DECAY_EPOCH': 100,
           'LR_DECAY_RATE': 1.0,
           'START_EPOCH': 0,
           'TOTAL_EPOCH': 800}}
Using random seed 0.
Path to the current word embeddings: ./datasets/seed_0_contextual/bert_largelayer_11_lstm/embs_train_30.npy
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.4c88e2dec8f8b017f319f6db2b157fee632c0860d9422e4851bd0d6999f9ce38
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6
Using configurations:
{'BATCH_ITEM_NUM': 30,
 'BERT_LARGE': True,
 'BERT_LAYER': 11,
 'CONFIG_NAME': 'bert_large_lstm_attn_context',
 'CROSS_VALIDATION_FLAG': True,
 'CUDA': True,
 'ELMO_LAYER': 2,
 'ELMO_MODE': 'concat',
 'EXPERIMENT_NAME': 'bert_large_lstm_attn_context',
 'GLOVE_DIM': 100,
 'GPU_NUM': 1,
 'IS_BERT': True,
 'IS_ELMO': False,
 'IS_RANDOM': False,
 'KFOLDS': 5,
 'LSTM': {'ATTN': True,
          'BIDIRECTION': True,
          'DROP_PROB': 0.1,
          'FLAG': True,
          'HIDDEN_DIM': 800,
          'LAYERS': 2,
          'SEQ_LEN': 30},
 'MODE': 'train',
 'OUT_PATH': '/jagupard22/scr1/sebschu/runs.h800/',
 'PREDICTION_TYPE': 'rating',
 'PREDON': 'train',
 'RESUME_DIR': '',
 'SAVE_PREDS': False,
 'SEED': 0,
 'SINGLE_SENTENCE': False,
 'SOME_DATABASE': './some_database.csv',
 'SPLIT_NAME': '',
 'TRAIN': {'BATCH_SIZE': 32,
           'COEFF': {'BETA_1': 0.9, 'BETA_2': 0.999, 'EPS': 1e-08},
           'DROPOUT': {'FC_1': 0.2, 'FC_2': 0.2},
           'FLAG': True,
           'INTERVAL': 10,
           'LR': 0.001,
           'LR_DECAY_EPOCH': 100,
           'LR_DECAY_RATE': 1.0,
           'START_EPOCH': 0,
           'TOTAL_EPOCH': 800}}
Using random seed 0.
Path to the current word embeddings: ./datasets/seed_0_contextual/bert_largelayer_11_lstm/embs_train_30.npy
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.4c88e2dec8f8b017f319f6db2b157fee632c0860d9422e4851bd0d6999f9ce38
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6
Using configurations:
{'BATCH_ITEM_NUM': 30,
 'BERT_LARGE': True,
 'BERT_LAYER': 11,
 'CONFIG_NAME': 'bert_large_lstm_attn_context',
 'CROSS_VALIDATION_FLAG': True,
 'CUDA': True,
 'ELMO_LAYER': 2,
 'ELMO_MODE': 'concat',
 'EXPERIMENT_NAME': 'bert_large_lstm_attn_context',
 'GLOVE_DIM': 100,
 'GPU_NUM': 1,
 'IS_BERT': True,
 'IS_ELMO': False,
 'IS_RANDOM': False,
 'KFOLDS': 5,
 'LSTM': {'ATTN': True,
          'BIDIRECTION': True,
          'DROP_PROB': 0.1,
          'FLAG': True,
          'HIDDEN_DIM': 800,
          'LAYERS': 2,
          'SEQ_LEN': 30},
 'MODE': 'train',
 'OUT_PATH': '/jagupard22/scr1/sebschu/runs.h800/',
 'PREDICTION_TYPE': 'rating',
 'PREDON': 'train',
 'RESUME_DIR': '',
 'SAVE_PREDS': False,
 'SEED': 0,
 'SINGLE_SENTENCE': False,
 'SOME_DATABASE': './some_database.csv',
 'SPLIT_NAME': '',
 'TRAIN': {'BATCH_SIZE': 32,
           'COEFF': {'BETA_1': 0.9, 'BETA_2': 0.999, 'EPS': 1e-08},
           'DROPOUT': {'FC_1': 0.2, 'FC_2': 0.2},
           'FLAG': True,
           'INTERVAL': 10,
           'LR': 0.001,
           'LR_DECAY_EPOCH': 100,
           'LR_DECAY_RATE': 1.0,
           'START_EPOCH': 0,
           'TOTAL_EPOCH': 800}}
Using random seed 0.
Path to the current word embeddings: ./datasets/seed_0_contextual/bert_largelayer_11_lstm/embs_train_30.npy
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.4c88e2dec8f8b017f319f6db2b157fee632c0860d9422e4851bd0d6999f9ce38
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6
Using configurations:
{'BATCH_ITEM_NUM': 30,
 'BERT_LARGE': True,
 'BERT_LAYER': 11,
 'CONFIG_NAME': 'bert_large_lstm_attn_context',
 'CROSS_VALIDATION_FLAG': True,
 'CUDA': True,
 'ELMO_LAYER': 2,
 'ELMO_MODE': 'concat',
 'EXPERIMENT_NAME': 'bert_large_lstm_attn_context',
 'GLOVE_DIM': 100,
 'GPU_NUM': 1,
 'IS_BERT': True,
 'IS_ELMO': False,
 'IS_RANDOM': False,
 'KFOLDS': 5,
 'LSTM': {'ATTN': True,
          'BIDIRECTION': True,
          'DROP_PROB': 0.1,
          'FLAG': True,
          'HIDDEN_DIM': 800,
          'LAYERS': 2,
          'SEQ_LEN': 30},
 'MODE': 'train',
 'OUT_PATH': '/jagupard22/scr1/sebschu/runs.h800/',
 'PREDICTION_TYPE': 'rating',
 'PREDON': 'train',
 'RESUME_DIR': '',
 'SAVE_PREDS': False,
 'SEED': 0,
 'SINGLE_SENTENCE': False,
 'SOME_DATABASE': './some_database.csv',
 'SPLIT_NAME': '',
 'TRAIN': {'BATCH_SIZE': 32,
           'COEFF': {'BETA_1': 0.9, 'BETA_2': 0.999, 'EPS': 1e-08},
           'DROPOUT': {'FC_1': 0.2, 'FC_2': 0.2},
           'FLAG': True,
           'INTERVAL': 10,
           'LR': 0.001,
           'LR_DECAY_EPOCH': 100,
           'LR_DECAY_RATE': 1.0,
           'START_EPOCH': 0,
           'TOTAL_EPOCH': 800}}
Using random seed 0.
Path to the current word embeddings: ./datasets/seed_0_contextual/bert_largelayer_11_lstm/embs_train_30.npy
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.4c88e2dec8f8b017f319f6db2b157fee632c0860d9422e4851bd0d6999f9ce38
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6
Using configurations:
{'BATCH_ITEM_NUM': 30,
 'BERT_LARGE': True,
 'BERT_LAYER': 11,
 'CONFIG_NAME': 'bert_large_lstm_attn_context',
 'CROSS_VALIDATION_FLAG': True,
 'CUDA': True,
 'ELMO_LAYER': 2,
 'ELMO_MODE': 'concat',
 'EXPERIMENT_NAME': 'bert_large_lstm_attn_context',
 'GLOVE_DIM': 100,
 'GPU_NUM': 1,
 'IS_BERT': True,
 'IS_ELMO': False,
 'IS_RANDOM': False,
 'KFOLDS': 5,
 'LSTM': {'ATTN': True,
          'BIDIRECTION': True,
          'DROP_PROB': 0.1,
          'FLAG': True,
          'HIDDEN_DIM': 800,
          'LAYERS': 2,
          'SEQ_LEN': 30},
 'MODE': 'train',
 'OUT_PATH': '/jagupard22/scr1/sebschu/runs.h800/',
 'PREDICTION_TYPE': 'rating',
 'PREDON': 'train',
 'RESUME_DIR': '',
 'SAVE_PREDS': False,
 'SEED': 0,
 'SINGLE_SENTENCE': False,
 'SOME_DATABASE': './some_database.csv',
 'SPLIT_NAME': '',
 'TRAIN': {'BATCH_SIZE': 32,
           'COEFF': {'BETA_1': 0.9, 'BETA_2': 0.999, 'EPS': 1e-08},
           'DROPOUT': {'FC_1': 0.2, 'FC_2': 0.2},
           'FLAG': True,
           'INTERVAL': 10,
           'LR': 0.001,
           'LR_DECAY_EPOCH': 100,
           'LR_DECAY_RATE': 1.0,
           'START_EPOCH': 0,
           'TOTAL_EPOCH': 800}}
Using random seed 0.
Path to the current word embeddings: ./datasets/seed_0_contextual/bert_largelayer_11_lstm/embs_train_30.npy
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.4c88e2dec8f8b017f319f6db2b157fee632c0860d9422e4851bd0d6999f9ce38
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6
Using configurations:
{'BATCH_ITEM_NUM': 30,
 'BERT_LARGE': True,
 'BERT_LAYER': 11,
 'CONFIG_NAME': 'bert_large_lstm_attn_context',
 'CROSS_VALIDATION_FLAG': True,
 'CUDA': True,
 'ELMO_LAYER': 2,
 'ELMO_MODE': 'concat',
 'EXPERIMENT_NAME': 'bert_large_lstm_attn_context',
 'GLOVE_DIM': 100,
 'GPU_NUM': 1,
 'IS_BERT': True,
 'IS_ELMO': False,
 'IS_RANDOM': False,
 'KFOLDS': 5,
 'LSTM': {'ATTN': True,
          'BIDIRECTION': True,
          'DROP_PROB': 0.1,
          'FLAG': True,
          'HIDDEN_DIM': 800,
          'LAYERS': 2,
          'SEQ_LEN': 30},
 'MODE': 'train',
 'OUT_PATH': '/jagupard22/scr1/sebschu/runs.h800/',
 'PREDICTION_TYPE': 'rating',
 'PREDON': 'train',
 'RESUME_DIR': '',
 'SAVE_PREDS': False,
 'SEED': 0,
 'SINGLE_SENTENCE': False,
 'SOME_DATABASE': './some_database.csv',
 'SPLIT_NAME': '',
 'TRAIN': {'BATCH_SIZE': 32,
           'COEFF': {'BETA_1': 0.9, 'BETA_2': 0.999, 'EPS': 1e-08},
           'DROPOUT': {'FC_1': 0.2, 'FC_2': 0.2},
           'FLAG': True,
           'INTERVAL': 10,
           'LR': 0.001,
           'LR_DECAY_EPOCH': 100,
           'LR_DECAY_RATE': 1.0,
           'START_EPOCH': 0,
           'TOTAL_EPOCH': 800}}
Using random seed 0.
Path to the current word embeddings: ./datasets/seed_0_contextual/bert_largelayer_11_lstm/embs_train_30.npy
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.4c88e2dec8f8b017f319f6db2b157fee632c0860d9422e4851bd0d6999f9ce38
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6
Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors
Using configurations:
{'BATCH_ITEM_NUM': 30,
 'BERT_LARGE': True,
 'BERT_LAYER': 11,
 'CONFIG_NAME': 'bert_large_lstm_attn_context',
 'CROSS_VALIDATION_FLAG': True,
 'CUDA': True,
 'ELMO_LAYER': 2,
 'ELMO_MODE': 'concat',
 'EXPERIMENT_NAME': 'bert_large_lstm_attn_context',
 'GLOVE_DIM': 100,
 'GPU_NUM': 1,
 'IS_BERT': True,
 'IS_ELMO': False,
 'IS_RANDOM': False,
 'KFOLDS': 5,
 'LSTM': {'ATTN': True,
          'BIDIRECTION': True,
          'DROP_PROB': 0.1,
          'FLAG': True,
          'HIDDEN_DIM': 800,
          'LAYERS': 2,
          'SEQ_LEN': 30},
 'MODE': 'train',
 'OUT_PATH': '/jagupard22/scr1/sebschu/runs.h800/',
 'PREDICTION_TYPE': 'rating',
 'PREDON': 'train',
 'RESUME_DIR': '',
 'SAVE_PREDS': False,
 'SEED': 0,
 'SINGLE_SENTENCE': False,
 'SOME_DATABASE': './some_database.csv',
 'SPLIT_NAME': '',
 'TRAIN': {'BATCH_SIZE': 32,
           'COEFF': {'BETA_1': 0.9, 'BETA_2': 0.999, 'EPS': 1e-08},
           'DROPOUT': {'FC_1': 0.2, 'FC_2': 0.2},
           'FLAG': True,
           'INTERVAL': 10,
           'LR': 0.001,
           'LR_DECAY_EPOCH': 100,
           'LR_DECAY_RATE': 1.0,
           'START_EPOCH': 0,
           'TOTAL_EPOCH': 800}}
Using random seed 0.
Path to the current word embeddings: ./datasets/seed_0_contextual/bert_largelayer_11_lstm/embs_train_30.npy
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.4c88e2dec8f8b017f319f6db2b157fee632c0860d9422e4851bd0d6999f9ce38
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6
Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors
Using configurations:
{'BATCH_ITEM_NUM': 30,
 'BERT_LARGE': True,
 'BERT_LAYER': 11,
 'CONFIG_NAME': 'bert_large_lstm_attn_context',
 'CROSS_VALIDATION_FLAG': True,
 'CUDA': True,
 'ELMO_LAYER': 2,
 'ELMO_MODE': 'concat',
 'EXPERIMENT_NAME': 'bert_large_lstm_attn_context',
 'GLOVE_DIM': 100,
 'GPU_NUM': 1,
 'IS_BERT': True,
 'IS_ELMO': False,
 'IS_RANDOM': False,
 'KFOLDS': 5,
 'LSTM': {'ATTN': True,
          'BIDIRECTION': True,
          'DROP_PROB': 0.1,
          'FLAG': True,
          'HIDDEN_DIM': 800,
          'LAYERS': 2,
          'SEQ_LEN': 30},
 'MODE': 'train',
 'OUT_PATH': '/jagupard22/scr1/sebschu/runs.h800/',
 'PREDICTION_TYPE': 'rating',
 'PREDON': 'train',
 'RESUME_DIR': '',
 'SAVE_PREDS': False,
 'SEED': 0,
 'SINGLE_SENTENCE': False,
 'SOME_DATABASE': './some_database.csv',
 'SPLIT_NAME': '',
 'TRAIN': {'BATCH_SIZE': 32,
           'COEFF': {'BETA_1': 0.9, 'BETA_2': 0.999, 'EPS': 1e-08},
           'DROPOUT': {'FC_1': 0.2, 'FC_2': 0.2},
           'FLAG': True,
           'INTERVAL': 10,
           'LR': 0.001,
           'LR_DECAY_EPOCH': 100,
           'LR_DECAY_RATE': 1.0,
           'START_EPOCH': 0,
           'TOTAL_EPOCH': 800}}
Using random seed 0.
Path to the current word embeddings: ./datasets/seed_0_contextual/bert_largelayer_11_lstm/embs_train_30.npy
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.4c88e2dec8f8b017f319f6db2b157fee632c0860d9422e4851bd0d6999f9ce38
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6
Using configurations:
{'BATCH_ITEM_NUM': 30,
 'BERT_LARGE': True,
 'BERT_LAYER': 11,
 'CONFIG_NAME': 'bert_large_lstm_attn_context',
 'CROSS_VALIDATION_FLAG': True,
 'CUDA': True,
 'ELMO_LAYER': 2,
 'ELMO_MODE': 'concat',
 'EXPERIMENT_NAME': 'bert_large_lstm_attn_context',
 'GLOVE_DIM': 100,
 'GPU_NUM': 1,
 'IS_BERT': True,
 'IS_ELMO': False,
 'IS_RANDOM': False,
 'KFOLDS': 5,
 'LSTM': {'ATTN': True,
          'BIDIRECTION': True,
          'DROP_PROB': 0.1,
          'FLAG': True,
          'HIDDEN_DIM': 800,
          'LAYERS': 2,
          'SEQ_LEN': 30},
 'MODE': 'train',
 'OUT_PATH': '/jagupard22/scr1/sebschu/runs.h800/',
 'PREDICTION_TYPE': 'rating',
 'PREDON': 'train',
 'RESUME_DIR': '',
 'SAVE_PREDS': False,
 'SEED': 0,
 'SINGLE_SENTENCE': False,
 'SOME_DATABASE': './some_database.csv',
 'SPLIT_NAME': '',
 'TRAIN': {'BATCH_SIZE': 32,
           'COEFF': {'BETA_1': 0.9, 'BETA_2': 0.999, 'EPS': 1e-08},
           'DROPOUT': {'FC_1': 0.2, 'FC_2': 0.2},
           'FLAG': True,
           'INTERVAL': 10,
           'LR': 0.001,
           'LR_DECAY_EPOCH': 100,
           'LR_DECAY_RATE': 1.0,
           'START_EPOCH': 0,
           'TOTAL_EPOCH': 800}}
Using random seed 0.
Path to the current word embeddings: ./datasets/seed_0_contextual/bert_largelayer_11_lstm/embs_train_30.npy
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.4c88e2dec8f8b017f319f6db2b157fee632c0860d9422e4851bd0d6999f9ce38
Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /sailhome/sebschu/.cache/torch/pytorch_transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6
Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors
Start training
===============================
Fold #1
- - - - - - - - - - - - -
initializing neural net
[1/800][24/24] total train loss: 1.2616; total val loss: 0.4373 val r: 0.6939; time: 1.16sec
[2/800][24/24] total train loss: 0.5665; total val loss: 0.4415 val r: 0.7789; time: 0.94sec
[3/800][24/24] total train loss: 0.3966; total val loss: 0.5639 val r: 0.7674; time: 0.94sec
[4/800][24/24] total train loss: 0.2822; total val loss: 0.5156 val r: 0.7568; time: 0.94sec
[5/800][24/24] total train loss: 0.1772; total val loss: 0.5528 val r: 0.7386; time: 0.94sec
[6/800][24/24] total train loss: 0.1188; total val loss: 0.5196 val r: 0.7321; time: 0.94sec
[7/800][24/24] total train loss: 0.0794; total val loss: 0.5148 val r: 0.7287; time: 0.93sec
[8/800][24/24] total train loss: 0.0639; total val loss: 0.5257 val r: 0.7295; time: 0.94sec
[9/800][24/24] total train loss: 0.0503; total val loss: 0.4955 val r: 0.7362; time: 0.94sec
[10/800][24/24] total train loss: 0.0404; total val loss: 0.5298 val r: 0.7314; time: 0.95sec
[11/800][24/24] total train loss: 0.0350; total val loss: 0.5302 val r: 0.7253; time: 0.95sec
[12/800][24/24] total train loss: 0.0274; total val loss: 0.5355 val r: 0.7343; time: 0.94sec
[13/800][24/24] total train loss: 0.0286; total val loss: 0.4604 val r: 0.7295; time: 0.94sec
[14/800][24/24] total train loss: 0.0255; total val loss: 0.5014 val r: 0.7324; time: 0.95sec
[15/800][24/24] total train loss: 0.0248; total val loss: 0.5088 val r: 0.7221; time: 0.94sec
[16/800][24/24] total train loss: 0.0231; total val loss: 0.4866 val r: 0.7242; time: 0.94sec
[17/800][24/24] total train loss: 0.0209; total val loss: 0.5052 val r: 0.7302; time: 0.94sec
[18/800][24/24] total train loss: 0.0225; total val loss: 0.4843 val r: 0.7157; time: 0.94sec
[19/800][24/24] total train loss: 0.0229; total val loss: 0.4835 val r: 0.7346; time: 0.94sec
[20/800][24/24] total train loss: 0.0247; total val loss: 0.5256 val r: 0.7362; time: 0.95sec
[21/800][24/24] total train loss: 0.0219; total val loss: 0.5006 val r: 0.7304; time: 0.95sec
[22/800][24/24] total train loss: 0.0212; total val loss: 0.5178 val r: 0.7324; time: 0.94sec
[23/800][24/24] total train loss: 0.0180; total val loss: 0.5049 val r: 0.7318; time: 0.93sec
[24/800][24/24] total train loss: 0.0182; total val loss: 0.5301 val r: 0.7394; time: 0.94sec
[25/800][24/24] total train loss: 0.0181; total val loss: 0.4790 val r: 0.7398; time: 0.94sec
[26/800][24/24] total train loss: 0.0177; total val loss: 0.5146 val r: 0.7355; time: 0.94sec
[27/800][24/24] total train loss: 0.0172; total val loss: 0.5030 val r: 0.7337; time: 0.94sec
[28/800][24/24] total train loss: 0.0179; total val loss: 0.4962 val r: 0.7329; time: 0.94sec
[29/800][24/24] total train loss: 0.0207; total val loss: 0.5067 val r: 0.7416; time: 0.94sec
[30/800][24/24] total train loss: 0.0196; total val loss: 0.4922 val r: 0.7319; time: 0.94sec
[31/800][24/24] total train loss: 0.0179; total val loss: 0.5111 val r: 0.7313; time: 0.94sec
[32/800][24/24] total train loss: 0.0195; total val loss: 0.4903 val r: 0.7302; time: 0.94sec
[33/800][24/24] total train loss: 0.0173; total val loss: 0.5030 val r: 0.7358; time: 0.94sec
[34/800][24/24] total train loss: 0.0158; total val loss: 0.5128 val r: 0.7384; time: 0.94sec
[35/800][24/24] total train loss: 0.0175; total val loss: 0.5207 val r: 0.7478; time: 0.94sec
[36/800][24/24] total train loss: 0.0164; total val loss: 0.4914 val r: 0.7345; time: 0.94sec
[37/800][24/24] total train loss: 0.0181; total val loss: 0.4881 val r: 0.7358; time: 0.94sec
[38/800][24/24] total train loss: 0.0166; total val loss: 0.4921 val r: 0.7450; time: 0.94sec
[39/800][24/24] total train loss: 0.0152; total val loss: 0.5186 val r: 0.7377; time: 0.94sec
[40/800][24/24] total train loss: 0.0155; total val loss: 0.5138 val r: 0.7352; time: 0.94sec
[41/800][24/24] total train loss: 0.0137; total val loss: 0.5291 val r: 0.7358; time: 0.94sec
[42/800][24/24] total train loss: 0.0150; total val loss: 0.4783 val r: 0.7350; time: 0.94sec
[43/800][24/24] total train loss: 0.0170; total val loss: 0.5189 val r: 0.7373; time: 0.94sec
[44/800][24/24] total train loss: 0.0168; total val loss: 0.5097 val r: 0.7390; time: 0.95sec
[45/800][24/24] total train loss: 0.0155; total val loss: 0.4926 val r: 0.7404; time: 0.94sec
[46/800][24/24] total train loss: 0.0147; total val loss: 0.4847 val r: 0.7349; time: 0.95sec
[47/800][24/24] total train loss: 0.0145; total val loss: 0.4933 val r: 0.7423; time: 0.95sec
[48/800][24/24] total train loss: 0.0146; total val loss: 0.4784 val r: 0.7431; time: 0.95sec
[49/800][24/24] total train loss: 0.0153; total val loss: 0.4887 val r: 0.7328; time: 0.94sec
[50/800][24/24] total train loss: 0.0167; total val loss: 0.4737 val r: 0.7409; time: 0.95sec
[51/800][24/24] total train loss: 0.0178; total val loss: 0.5060 val r: 0.7427; time: 0.95sec
[52/800][24/24] total train loss: 0.0198; total val loss: 0.4613 val r: 0.7382; time: 0.94sec
[53/800][24/24] total train loss: 0.0188; total val loss: 0.4813 val r: 0.7442; time: 0.94sec
[54/800][24/24] total train loss: 0.0169; total val loss: 0.4581 val r: 0.7455; time: 0.94sec
[55/800][24/24] total train loss: 0.0140; total val loss: 0.4964 val r: 0.7422; time: 0.94sec
[56/800][24/24] total train loss: 0.0134; total val loss: 0.4820 val r: 0.7450; time: 0.94sec
[57/800][24/24] total train loss: 0.0125; total val loss: 0.5039 val r: 0.7444; time: 0.95sec
[58/800][24/24] total train loss: 0.0127; total val loss: 0.4967 val r: 0.7409; time: 0.95sec
[59/800][24/24] total train loss: 0.0133; total val loss: 0.4733 val r: 0.7383; time: 0.95sec
[60/800][24/24] total train loss: 0.0132; total val loss: 0.4809 val r: 0.7442; time: 0.95sec
[61/800][24/24] total train loss: 0.0126; total val loss: 0.4843 val r: 0.7435; time: 0.94sec
[62/800][24/24] total train loss: 0.0126; total val loss: 0.5003 val r: 0.7430; time: 0.94sec
[63/800][24/24] total train loss: 0.0133; total val loss: 0.4649 val r: 0.7444; time: 0.94sec
[64/800][24/24] total train loss: 0.0128; total val loss: 0.4912 val r: 0.7422; time: 0.94sec
[65/800][24/24] total train loss: 0.0133; total val loss: 0.5010 val r: 0.7444; time: 1.14sec
[66/800][24/24] total train loss: 0.0140; total val loss: 0.4830 val r: 0.7446; time: 0.95sec
[67/800][24/24] total train loss: 0.0136; total val loss: 0.4960 val r: 0.7444; time: 0.95sec
[68/800][24/24] total train loss: 0.0133; total val loss: 0.5007 val r: 0.7396; time: 0.94sec
[69/800][24/24] total train loss: 0.0131; total val loss: 0.4906 val r: 0.7446; time: 0.94sec
[70/800][24/24] total train loss: 0.0130; total val loss: 0.5121 val r: 0.7472; time: 0.95sec
[71/800][24/24] total train loss: 0.0125; total val loss: 0.5115 val r: 0.7428; time: 0.94sec
[72/800][24/24] total train loss: 0.0136; total val loss: 0.4938 val r: 0.7492; time: 0.94sec
[73/800][24/24] total train loss: 0.0133; total val loss: 0.4813 val r: 0.7399; time: 0.94sec
[74/800][24/24] total train loss: 0.0131; total val loss: 0.4904 val r: 0.7419; time: 0.95sec
[75/800][24/24] total train loss: 0.0126; total val loss: 0.4840 val r: 0.7418; time: 0.94sec
[76/800][24/24] total train loss: 0.0129; total val loss: 0.4935 val r: 0.7423; time: 0.95sec
[77/800][24/24] total train loss: 0.0131; total val loss: 0.5128 val r: 0.7453; time: 0.94sec
[78/800][24/24] total train loss: 0.0144; total val loss: 0.4973 val r: 0.7473; time: 0.94sec
[79/800][24/24] total train loss: 0.0133; total val loss: 0.5150 val r: 0.7449; time: 0.95sec
[80/800][24/24] total train loss: 0.0121; total val loss: 0.5040 val r: 0.7518; time: 0.95sec
[81/800][24/24] total train loss: 0.0121; total val loss: 0.4889 val r: 0.7439; time: 0.94sec
[82/800][24/24] total train loss: 0.0123; total val loss: 0.4880 val r: 0.7462; time: 0.95sec
[83/800][24/24] total train loss: 0.0126; total val loss: 0.5137 val r: 0.7486; time: 0.94sec
[84/800][24/24] total train loss: 0.0120; total val loss: 0.5080 val r: 0.7477; time: 0.95sec
[85/800][24/24] total train loss: 0.0133; total val loss: 0.4916 val r: 0.7452; time: 0.95sec
[86/800][24/24] total train loss: 0.0145; total val loss: 0.4938 val r: 0.7461; time: 0.95sec
[87/800][24/24] total train loss: 0.0137; total val loss: 0.4784 val r: 0.7501; time: 0.95sec
[88/800][24/24] total train loss: 0.0135; total val loss: 0.4912 val r: 0.7485; time: 0.94sec
[89/800][24/24] total train loss: 0.0132; total val loss: 0.5009 val r: 0.7487; time: 0.95sec
[90/800][24/24] total train loss: 0.0135; total val loss: 0.4888 val r: 0.7458; time: 0.95sec
[91/800][24/24] total train loss: 0.0136; total val loss: 0.4873 val r: 0.7483; time: 0.94sec
[92/800][24/24] total train loss: 0.0134; total val loss: 0.4839 val r: 0.7510; time: 0.94sec
[93/800][24/24] total train loss: 0.0125; total val loss: 0.4781 val r: 0.7485; time: 0.95sec
[94/800][24/24] total train loss: 0.0123; total val loss: 0.4863 val r: 0.7538; time: 0.95sec
[95/800][24/24] total train loss: 0.0127; total val loss: 0.4920 val r: 0.7485; time: 0.94sec
[96/800][24/24] total train loss: 0.0133; total val loss: 0.4909 val r: 0.7496; time: 0.95sec
[97/800][24/24] total train loss: 0.0131; total val loss: 0.4967 val r: 0.7528; time: 0.94sec
[98/800][24/24] total train loss: 0.0124; total val loss: 0.4706 val r: 0.7485; time: 0.95sec
[99/800][24/24] total train loss: 0.0120; total val loss: 0.4645 val r: 0.7510; time: 0.95sec
learning rate updated: 0.001
[100/800][24/24] total train loss: 0.0120; total val loss: 0.4904 val r: 0.7538; time: 0.94sec
[101/800][24/24] total train loss: 0.0124; total val loss: 0.4695 val r: 0.7521; time: 0.95sec
[102/800][24/24] total train loss: 0.0141; total val loss: 0.4671 val r: 0.7518; time: 0.95sec
[103/800][24/24] total train loss: 0.0133; total val loss: 0.4802 val r: 0.7513; time: 0.94sec
[104/800][24/24] total train loss: 0.0122; total val loss: 0.4999 val r: 0.7488; time: 0.94sec
[105/800][24/24] total train loss: 0.0118; total val loss: 0.4941 val r: 0.7518; time: 0.94sec
[106/800][24/24] total train loss: 0.0115; total val loss: 0.4914 val r: 0.7498; time: 0.94sec
[107/800][24/24] total train loss: 0.0116; total val loss: 0.5053 val r: 0.7522; time: 0.94sec
[108/800][24/24] total train loss: 0.0109; total val loss: 0.4506 val r: 0.7444; time: 0.94sec
[109/800][24/24] total train loss: 0.0114; total val loss: 0.4779 val r: 0.7501; time: 0.94sec
[110/800][24/24] total train loss: 0.0126; total val loss: 0.4720 val r: 0.7512; time: 0.95sec
[111/800][24/24] total train loss: 0.0114; total val loss: 0.4610 val r: 0.7531; time: 0.94sec
[112/800][24/24] total train loss: 0.0126; total val loss: 0.5022 val r: 0.7469; time: 0.94sec
[113/800][24/24] total train loss: 0.0115; total val loss: 0.4965 val r: 0.7536; time: 0.93sec
[114/800][24/24] total train loss: 0.0108; total val loss: 0.4956 val r: 0.7492; time: 0.94sec
[115/800][24/24] total train loss: 0.0113; total val loss: 0.4921 val r: 0.7489; time: 0.94sec
[116/800][24/24] total train loss: 0.0112; total val loss: 0.4952 val r: 0.7508; time: 0.95sec
[117/800][24/24] total train loss: 0.0113; total val loss: 0.4820 val r: 0.7530; time: 0.94sec
[118/800][24/24] total train loss: 0.0122; total val loss: 0.4935 val r: 0.7511; time: 0.94sec
[119/800][24/24] total train loss: 0.0118; total val loss: 0.4937 val r: 0.7502; time: 0.94sec
[120/800][24/24] total train loss: 0.0110; total val loss: 0.4812 val r: 0.7496; time: 0.94sec
[121/800][24/24] total train loss: 0.0109; total val loss: 0.4918 val r: 0.7491; time: 0.94sec
[122/800][24/24] total train loss: 0.0109; total val loss: 0.4715 val r: 0.7512; time: 0.94sec
[123/800][24/24] total train loss: 0.0105; total val loss: 0.4512 val r: 0.7474; time: 0.95sec
[124/800][24/24] total train loss: 0.0117; total val loss: 0.4889 val r: 0.7553; time: 0.94sec
[125/800][24/24] total train loss: 0.0135; total val loss: 0.4822 val r: 0.7551; time: 0.94sec
[126/800][24/24] total train loss: 0.0127; total val loss: 0.4930 val r: 0.7515; time: 0.94sec
[127/800][24/24] total train loss: 0.0114; total val loss: 0.5053 val r: 0.7542; time: 0.95sec
[128/800][24/24] total train loss: 0.0109; total val loss: 0.4899 val r: 0.7497; time: 0.94sec
[129/800][24/24] total train loss: 0.0117; total val loss: 0.4741 val r: 0.7527; time: 0.94sec
[130/800][24/24] total train loss: 0.0129; total val loss: 0.4890 val r: 0.7516; time: 0.94sec
[131/800][24/24] total train loss: 0.0133; total val loss: 0.4918 val r: 0.7574; time: 0.95sec
[132/800][24/24] total train loss: 0.0121; total val loss: 0.4957 val r: 0.7540; time: 0.93sec
[133/800][24/24] total train loss: 0.0124; total val loss: 0.5091 val r: 0.7531; time: 0.94sec
[134/800][24/24] total train loss: 0.0125; total val loss: 0.4967 val r: 0.7529; time: 0.94sec
[135/800][24/24] total train loss: 0.0116; total val loss: 0.4986 val r: 0.7554; time: 0.94sec
[136/800][24/24] total train loss: 0.0120; total val loss: 0.4914 val r: 0.7571; time: 0.95sec
[137/800][24/24] total train loss: 0.0107; total val loss: 0.4929 val r: 0.7544; time: 0.94sec
[138/800][24/24] total train loss: 0.0107; total val loss: 0.5050 val r: 0.7556; time: 0.93sec
[139/800][24/24] total train loss: 0.0107; total val loss: 0.4948 val r: 0.7554; time: 0.94sec
[140/800][24/24] total train loss: 0.0113; total val loss: 0.5007 val r: 0.7547; time: 0.93sec
[141/800][24/24] total train loss: 0.0107; total val loss: 0.4947 val r: 0.7509; time: 0.94sec
[142/800][24/24] total train loss: 0.0108; total val loss: 0.5105 val r: 0.7577; time: 0.94sec
[143/800][24/24] total train loss: 0.0109; total val loss: 0.4979 val r: 0.7599; time: 0.94sec
[144/800][24/24] total train loss: 0.0114; total val loss: 0.5012 val r: 0.7530; time: 0.94sec
[145/800][24/24] total train loss: 0.0109; total val loss: 0.4351 val r: 0.7567; time: 0.94sec
[146/800][24/24] total train loss: 0.0125; total val loss: 0.4821 val r: 0.7555; time: 0.94sec
[147/800][24/24] total train loss: 0.0128; total val loss: 0.4883 val r: 0.7564; time: 0.94sec
[148/800][24/24] total train loss: 0.0121; total val loss: 0.4978 val r: 0.7562; time: 0.95sec
[149/800][24/24] total train loss: 0.0112; total val loss: 0.4956 val r: 0.7591; time: 0.94sec
[150/800][24/24] total train loss: 0.0108; total val loss: 0.4763 val r: 0.7525; time: 0.94sec
[151/800][24/24] total train loss: 0.0106; total val loss: 0.4995 val r: 0.7539; time: 0.95sec
[152/800][24/24] total train loss: 0.0119; total val loss: 0.5212 val r: 0.7546; time: 0.94sec
[153/800][24/24] total train loss: 0.0129; total val loss: 0.4660 val r: 0.7513; time: 0.94sec
[154/800][24/24] total train loss: 0.0120; total val loss: 0.4869 val r: 0.7578; time: 0.93sec
[155/800][24/24] total train loss: 0.0109; total val loss: 0.4830 val r: 0.7568; time: 0.94sec
[156/800][24/24] total train loss: 0.0112; total val loss: 0.4980 val r: 0.7520; time: 0.94sec
[157/800][24/24] total train loss: 0.0107; total val loss: 0.5038 val r: 0.7580; time: 0.94sec
[158/800][24/24] total train loss: 0.0107; total val loss: 0.4974 val r: 0.7614; time: 0.94sec
[159/800][24/24] total train loss: 0.0112; total val loss: 0.4917 val r: 0.7599; time: 0.95sec
[160/800][24/24] total train loss: 0.0112; total val loss: 0.4769 val r: 0.7557; time: 0.94sec
[161/800][24/24] total train loss: 0.0110; total val loss: 0.4802 val r: 0.7593; time: 0.94sec
[162/800][24/24] total train loss: 0.0109; total val loss: 0.4989 val r: 0.7583; time: 0.95sec
[163/800][24/24] total train loss: 0.0112; total val loss: 0.4895 val r: 0.7596; time: 0.94sec
[164/800][24/24] total train loss: 0.0122; total val loss: 0.4970 val r: 0.7606; time: 0.95sec
[165/800][24/24] total train loss: 0.0118; total val loss: 0.4957 val r: 0.7569; time: 0.94sec
[166/800][24/24] total train loss: 0.0107; total val loss: 0.4940 val r: 0.7576; time: 0.95sec
[167/800][24/24] total train loss: 0.0109; total val loss: 0.4845 val r: 0.7563; time: 0.94sec
[168/800][24/24] total train loss: 0.0101; total val loss: 0.4742 val r: 0.7555; time: 0.95sec
[169/800][24/24] total train loss: 0.0099; total val loss: 0.4838 val r: 0.7564; time: 0.94sec
[170/800][24/24] total train loss: 0.0112; total val loss: 0.4760 val r: 0.7552; time: 0.94sec
[171/800][24/24] total train loss: 0.0104; total val loss: 0.4738 val r: 0.7545; time: 0.94sec
[172/800][24/24] total train loss: 0.0105; total val loss: 0.4821 val r: 0.7554; time: 0.94sec
[173/800][24/24] total train loss: 0.0103; total val loss: 0.4824 val r: 0.7555; time: 0.94sec
[174/800][24/24] total train loss: 0.0096; total val loss: 0.4855 val r: 0.7544; time: 0.95sec
[175/800][24/24] total train loss: 0.0096; total val loss: 0.5010 val r: 0.7591; time: 0.95sec
[176/800][24/24] total train loss: 0.0108; total val loss: 0.4849 val r: 0.7604; time: 0.94sec
[177/800][24/24] total train loss: 0.0107; total val loss: 0.4728 val r: 0.7563; time: 0.94sec
[178/800][24/24] total train loss: 0.0111; total val loss: 0.4530 val r: 0.7579; time: 0.94sec
[179/800][24/24] total train loss: 0.0112; total val loss: 0.4951 val r: 0.7533; time: 0.94sec
[180/800][24/24] total train loss: 0.0110; total val loss: 0.5027 val r: 0.7545; time: 0.94sec
[181/800][24/24] total train loss: 0.0119; total val loss: 0.4950 val r: 0.7576; time: 0.94sec
[182/800][24/24] total train loss: 0.0110; total val loss: 0.4938 val r: 0.7619; time: 0.94sec
[183/800][24/24] total train loss: 0.0111; total val loss: 0.4864 val r: 0.7559; time: 0.94sec
[184/800][24/24] total train loss: 0.0102; total val loss: 0.4857 val r: 0.7591; time: 0.94sec
[185/800][24/24] total train loss: 0.0101; total val loss: 0.4823 val r: 0.7531; time: 0.94sec
[186/800][24/24] total train loss: 0.0101; total val loss: 0.5010 val r: 0.7579; time: 0.94sec
[187/800][24/24] total train loss: 0.0105; total val loss: 0.4852 val r: 0.7515; time: 0.94sec
[188/800][24/24] total train loss: 0.0102; total val loss: 0.4887 val r: 0.7587; time: 0.94sec
[189/800][24/24] total train loss: 0.0100; total val loss: 0.4835 val r: 0.7558; time: 0.94sec
[190/800][24/24] total train loss: 0.0102; total val loss: 0.4832 val r: 0.7582; time: 0.94sec
[191/800][24/24] total train loss: 0.0105; total val loss: 0.4874 val r: 0.7595; time: 0.93sec
[192/800][24/24] total train loss: 0.0109; total val loss: 0.4864 val r: 0.7610; time: 0.94sec
[193/800][24/24] total train loss: 0.0106; total val loss: 0.4925 val r: 0.7558; time: 0.94sec
[194/800][24/24] total train loss: 0.0099; total val loss: 0.4970 val r: 0.7537; time: 0.95sec
[195/800][24/24] total train loss: 0.0096; total val loss: 0.4862 val r: 0.7566; time: 0.95sec
[196/800][24/24] total train loss: 0.0098; total val loss: 0.4711 val r: 0.7576; time: 0.93sec
[197/800][24/24] total train loss: 0.0105; total val loss: 0.4952 val r: 0.7599; time: 0.94sec
[198/800][24/24] total train loss: 0.0102; total val loss: 0.4970 val r: 0.7560; time: 0.94sec
[199/800][24/24] total train loss: 0.0101; total val loss: 0.5116 val r: 0.7578; time: 0.95sec
learning rate updated: 0.001
[200/800][24/24] total train loss: 0.0100; total val loss: 0.4856 val r: 0.7564; time: 0.94sec
[201/800][24/24] total train loss: 0.0102; total val loss: 0.4894 val r: 0.7546; time: 0.94sec
[202/800][24/24] total train loss: 0.0104; total val loss: 0.4891 val r: 0.7573; time: 0.94sec
[203/800][24/24] total train loss: 0.0106; total val loss: 0.4736 val r: 0.7622; time: 0.94sec
[204/800][24/24] total train loss: 0.0102; total val loss: 0.4929 val r: 0.7563; time: 0.94sec
[205/800][24/24] total train loss: 0.0099; total val loss: 0.4864 val r: 0.7592; time: 0.94sec
[206/800][24/24] total train loss: 0.0097; total val loss: 0.4958 val r: 0.7569; time: 0.94sec
[207/800][24/24] total train loss: 0.0102; total val loss: 0.5078 val r: 0.7599; time: 0.94sec
[208/800][24/24] total train loss: 0.0104; total val loss: 0.4796 val r: 0.7600; time: 0.94sec
[209/800][24/24] total train loss: 0.0105; total val loss: 0.4967 val r: 0.7608; time: 0.94sec
[210/800][24/24] total train loss: 0.0102; total val loss: 0.4986 val r: 0.7551; time: 0.94sec
[211/800][24/24] total train loss: 0.0101; total val loss: 0.5076 val r: 0.7517; time: 0.94sec
[212/800][24/24] total train loss: 0.0104; total val loss: 0.5020 val r: 0.7580; time: 0.94sec
[213/800][24/24] total train loss: 0.0099; total val loss: 0.4820 val r: 0.7555; time: 0.94sec
[214/800][24/24] total train loss: 0.0096; total val loss: 0.4709 val r: 0.7526; time: 0.94sec
[215/800][24/24] total train loss: 0.0092; total val loss: 0.4963 val r: 0.7566; time: 0.94sec
[216/800][24/24] total train loss: 0.0095; total val loss: 0.4804 val r: 0.7551; time: 0.94sec
[217/800][24/24] total train loss: 0.0104; total val loss: 0.5121 val r: 0.7591; time: 0.94sec
[218/800][24/24] total train loss: 0.0100; total val loss: 0.4845 val r: 0.7564; time: 0.94sec
[219/800][24/24] total train loss: 0.0094; total val loss: 0.4987 val r: 0.7578; time: 0.95sec
[220/800][24/24] total train loss: 0.0094; total val loss: 0.4836 val r: 0.7593; time: 0.94sec
[221/800][24/24] total train loss: 0.0100; total val loss: 0.4885 val r: 0.7551; time: 0.94sec
[222/800][24/24] total train loss: 0.0098; total val loss: 0.4837 val r: 0.7572; time: 0.95sec
[223/800][24/24] total train loss: 0.0095; total val loss: 0.5150 val r: 0.7632; time: 0.94sec
[224/800][24/24] total train loss: 0.0092; total val loss: 0.5021 val r: 0.7537; time: 0.95sec
[225/800][24/24] total train loss: 0.0098; total val loss: 0.4907 val r: 0.7549; time: 0.94sec
[226/800][24/24] total train loss: 0.0101; total val loss: 0.4965 val r: 0.7560; time: 0.94sec
[227/800][24/24] total train loss: 0.0097; total val loss: 0.5115 val r: 0.7555; time: 0.95sec
[228/800][24/24] total train loss: 0.0098; total val loss: 0.4732 val r: 0.7577; time: 0.94sec
[229/800][24/24] total train loss: 0.0098; total val loss: 0.4852 val r: 0.7551; time: 0.94sec
[230/800][24/24] total train loss: 0.0101; total val loss: 0.5031 val r: 0.7549; time: 0.94sec
[231/800][24/24] total train loss: 0.0100; total val loss: 0.4732 val r: 0.7582; time: 0.94sec
[232/800][24/24] total train loss: 0.0104; total val loss: 0.4882 val r: 0.7564; time: 0.94sec
[233/800][24/24] total train loss: 0.0100; total val loss: 0.5062 val r: 0.7583; time: 0.94sec
[234/800][24/24] total train loss: 0.0100; total val loss: 0.4889 val r: 0.7553; time: 0.94sec
[235/800][24/24] total train loss: 0.0095; total val loss: 0.5112 val r: 0.7567; time: 0.94sec
[236/800][24/24] total train loss: 0.0096; total val loss: 0.5020 val r: 0.7563; time: 0.94sec
[237/800][24/24] total train loss: 0.0093; total val loss: 0.4942 val r: 0.7528; time: 0.94sec
[238/800][24/24] total train loss: 0.0092; total val loss: 0.5020 val r: 0.7560; time: 0.95sec
[239/800][24/24] total train loss: 0.0094; total val loss: 0.4910 val r: 0.7497; time: 0.94sec
[240/800][24/24] total train loss: 0.0101; total val loss: 0.4895 val r: 0.7620; time: 0.94sec
[241/800][24/24] total train loss: 0.0097; total val loss: 0.4911 val r: 0.7565; time: 0.95sec
[242/800][24/24] total train loss: 0.0093; total val loss: 0.4935 val r: 0.7573; time: 0.94sec
[243/800][24/24] total train loss: 0.0099; total val loss: 0.4794 val r: 0.7554; time: 0.95sec
[244/800][24/24] total train loss: 0.0096; total val loss: 0.4921 val r: 0.7591; time: 0.95sec
[245/800][24/24] total train loss: 0.0097; total val loss: 0.4798 val r: 0.7593; time: 0.94sec
[246/800][24/24] total train loss: 0.0094; total val loss: 0.4958 val r: 0.7594; time: 0.94sec
[247/800][24/24] total train loss: 0.0092; total val loss: 0.4934 val r: 0.7566; time: 0.95sec
[248/800][24/24] total train loss: 0.0092; total val loss: 0.4843 val r: 0.7614; time: 0.95sec
[249/800][24/24] total train loss: 0.0100; total val loss: 0.4802 val r: 0.7530; time: 0.94sec
[250/800][24/24] total train loss: 0.0092; total val loss: 0.4685 val r: 0.7564; time: 0.95sec
[251/800][24/24] total train loss: 0.0096; total val loss: 0.4687 val r: 0.7571; time: 0.95sec
[252/800][24/24] total train loss: 0.0099; total val loss: 0.5020 val r: 0.7534; time: 0.94sec
[253/800][24/24] total train loss: 0.0096; total val loss: 0.4957 val r: 0.7513; time: 0.94sec
[254/800][24/24] total train loss: 0.0095; total val loss: 0.5172 val r: 0.7541; time: 0.94sec
[255/800][24/24] total train loss: 0.0100; total val loss: 0.5115 val r: 0.7502; time: 0.94sec
[256/800][24/24] total train loss: 0.0101; total val loss: 0.5097 val r: 0.7583; time: 0.94sec
[257/800][24/24] total train loss: 0.0094; total val loss: 0.5047 val r: 0.7517; time: 0.94sec
[258/800][24/24] total train loss: 0.0090; total val loss: 0.4865 val r: 0.7595; time: 0.93sec
[259/800][24/24] total train loss: 0.0093; total val loss: 0.4902 val r: 0.7578; time: 0.94sec
[260/800][24/24] total train loss: 0.0095; total val loss: 0.5046 val r: 0.7578; time: 0.94sec
[261/800][24/24] total train loss: 0.0094; total val loss: 0.4769 val r: 0.7572; time: 0.93sec
[262/800][24/24] total train loss: 0.0097; total val loss: 0.4779 val r: 0.7514; time: 0.94sec
[263/800][24/24] total train loss: 0.0096; total val loss: 0.4847 val r: 0.7499; time: 0.94sec
[264/800][24/24] total train loss: 0.0091; total val loss: 0.4990 val r: 0.7551; time: 0.94sec
[265/800][24/24] total train loss: 0.0093; total val loss: 0.4902 val r: 0.7533; time: 0.95sec
[266/800][24/24] total train loss: 0.0093; total val loss: 0.5074 val r: 0.7612; time: 0.95sec
[267/800][24/24] total train loss: 0.0093; total val loss: 0.4989 val r: 0.7569; time: 0.95sec
[268/800][24/24] total train loss: 0.0101; total val loss: 0.4972 val r: 0.7565; time: 0.95sec
[269/800][24/24] total train loss: 0.0092; total val loss: 0.4881 val r: 0.7543; time: 0.95sec
[270/800][24/24] total train loss: 0.0096; total val loss: 0.4790 val r: 0.7523; time: 0.94sec
[271/800][24/24] total train loss: 0.0096; total val loss: 0.4921 val r: 0.7526; time: 0.95sec
[272/800][24/24] total train loss: 0.0094; total val loss: 0.4762 val r: 0.7532; time: 0.95sec
[273/800][24/24] total train loss: 0.0098; total val loss: 0.4808 val r: 0.7531; time: 0.94sec
[274/800][24/24] total train loss: 0.0094; total val loss: 0.4912 val r: 0.7555; time: 0.94sec
[275/800][24/24] total train loss: 0.0094; total val loss: 0.4785 val r: 0.7526; time: 0.95sec
[276/800][24/24] total train loss: 0.0096; total val loss: 0.4811 val r: 0.7512; time: 0.94sec
[277/800][24/24] total train loss: 0.0096; total val loss: 0.5019 val r: 0.7540; time: 0.95sec
[278/800][24/24] total train loss: 0.0096; total val loss: 0.5070 val r: 0.7539; time: 0.93sec
[279/800][24/24] total train loss: 0.0094; total val loss: 0.4875 val r: 0.7556; time: 0.94sec
[280/800][24/24] total train loss: 0.0092; total val loss: 0.4880 val r: 0.7548; time: 0.94sec
[281/800][24/24] total train loss: 0.0096; total val loss: 0.4990 val r: 0.7585; time: 0.94sec
[282/800][24/24] total train loss: 0.0099; total val loss: 0.4955 val r: 0.7560; time: 0.95sec
[283/800][24/24] total train loss: 0.0095; total val loss: 0.4807 val r: 0.7569; time: 0.94sec
[284/800][24/24] total train loss: 0.0094; total val loss: 0.4842 val r: 0.7592; time: 0.94sec
[285/800][24/24] total train loss: 0.0093; total val loss: 0.4985 val r: 0.7549; time: 0.95sec
[286/800][24/24] total train loss: 0.0093; total val loss: 0.5137 val r: 0.7543; time: 0.94sec
[287/800][24/24] total train loss: 0.0094; total val loss: 0.4924 val r: 0.7465; time: 0.94sec
[288/800][24/24] total train loss: 0.0091; total val loss: 0.5117 val r: 0.7562; time: 0.94sec
[289/800][24/24] total train loss: 0.0091; total val loss: 0.5176 val r: 0.7533; time: 0.94sec
[290/800][24/24] total train loss: 0.0094; total val loss: 0.4939 val r: 0.7526; time: 0.94sec
[291/800][24/24] total train loss: 0.0093; total val loss: 0.4898 val r: 0.7583; time: 0.94sec
[292/800][24/24] total train loss: 0.0092; total val loss: 0.4891 val r: 0.7481; time: 0.93sec
[293/800][24/24] total train loss: 0.0093; total val loss: 0.4988 val r: 0.7565; time: 0.94sec
[294/800][24/24] total train loss: 0.0091; total val loss: 0.5130 val r: 0.7578; time: 0.95sec
[295/800][24/24] total train loss: 0.0091; total val loss: 0.5077 val r: 0.7540; time: 0.94sec
[296/800][24/24] total train loss: 0.0093; total val loss: 0.4860 val r: 0.7524; time: 0.95sec
[297/800][24/24] total train loss: 0.0092; total val loss: 0.4902 val r: 0.7519; time: 0.95sec
[298/800][24/24] total train loss: 0.0090; total val loss: 0.4847 val r: 0.7596; time: 0.94sec
[299/800][24/24] total train loss: 0.0089; total val loss: 0.4946 val r: 0.7550; time: 0.94sec
learning rate updated: 0.001
[300/800][24/24] total train loss: 0.0088; total val loss: 0.4926 val r: 0.7517; time: 0.95sec
[301/800][24/24] total train loss: 0.0089; total val loss: 0.4781 val r: 0.7525; time: 0.94sec
[302/800][24/24] total train loss: 0.0088; total val loss: 0.4858 val r: 0.7541; time: 0.94sec
[303/800][24/24] total train loss: 0.0090; total val loss: 0.4969 val r: 0.7527; time: 0.95sec
[304/800][24/24] total train loss: 0.0088; total val loss: 0.4964 val r: 0.7521; time: 0.95sec
[305/800][24/24] total train loss: 0.0090; total val loss: 0.4884 val r: 0.7528; time: 0.94sec
[306/800][24/24] total train loss: 0.0092; total val loss: 0.4866 val r: 0.7536; time: 0.94sec
[307/800][24/24] total train loss: 0.0093; total val loss: 0.4944 val r: 0.7551; time: 0.94sec
[308/800][24/24] total train loss: 0.0089; total val loss: 0.4846 val r: 0.7551; time: 0.95sec
[309/800][24/24] total train loss: 0.0090; total val loss: 0.4918 val r: 0.7535; time: 0.95sec
[310/800][24/24] total train loss: 0.0092; total val loss: 0.4795 val r: 0.7498; time: 0.95sec
[311/800][24/24] total train loss: 0.0095; total val loss: 0.5055 val r: 0.7569; time: 0.94sec
[312/800][24/24] total train loss: 0.0095; total val loss: 0.4959 val r: 0.7520; time: 0.94sec
[313/800][24/24] total train loss: 0.0091; total val loss: 0.4879 val r: 0.7560; time: 0.94sec
[314/800][24/24] total train loss: 0.0090; total val loss: 0.4981 val r: 0.7502; time: 0.95sec
[315/800][24/24] total train loss: 0.0090; total val loss: 0.4923 val r: 0.7577; time: 0.94sec
[316/800][24/24] total train loss: 0.0093; total val loss: 0.4995 val r: 0.7568; time: 0.94sec
[317/800][24/24] total train loss: 0.0091; total val loss: 0.4712 val r: 0.7485; time: 0.94sec
[318/800][24/24] total train loss: 0.0094; total val loss: 0.4861 val r: 0.7575; time: 0.94sec
[319/800][24/24] total train loss: 0.0095; total val loss: 0.4885 val r: 0.7545; time: 0.94sec
[320/800][24/24] total train loss: 0.0092; total val loss: 0.4845 val r: 0.7527; time: 0.95sec
[321/800][24/24] total train loss: 0.0092; total val loss: 0.4862 val r: 0.7518; time: 0.95sec
[322/800][24/24] total train loss: 0.0090; total val loss: 0.4999 val r: 0.7569; time: 0.95sec
[323/800][24/24] total train loss: 0.0091; total val loss: 0.5088 val r: 0.7570; time: 0.95sec
[324/800][24/24] total train loss: 0.0092; total val loss: 0.5111 val r: 0.7533; time: 0.95sec
[325/800][24/24] total train loss: 0.0093; total val loss: 0.5010 val r: 0.7538; time: 0.94sec
[326/800][24/24] total train loss: 0.0097; total val loss: 0.4933 val r: 0.7544; time: 0.94sec
[327/800][24/24] total train loss: 0.0093; total val loss: 0.4874 val r: 0.7524; time: 0.95sec
[328/800][24/24] total train loss: 0.0089; total val loss: 0.4975 val r: 0.7554; time: 0.94sec
[329/800][24/24] total train loss: 0.0091; total val loss: 0.4958 val r: 0.7545; time: 0.95sec
[330/800][24/24] total train loss: 0.0091; total val loss: 0.4968 val r: 0.7557; time: 0.94sec
[331/800][24/24] total train loss: 0.0088; total val loss: 0.4848 val r: 0.7484; time: 0.94sec
[332/800][24/24] total train loss: 0.0087; total val loss: 0.4890 val r: 0.7567; time: 0.94sec
[333/800][24/24] total train loss: 0.0090; total val loss: 0.4928 val r: 0.7542; time: 0.93sec
[334/800][24/24] total train loss: 0.0088; total val loss: 0.4882 val r: 0.7556; time: 0.93sec
[335/800][24/24] total train loss: 0.0092; total val loss: 0.5071 val r: 0.7544; time: 0.93sec
[336/800][24/24] total train loss: 0.0093; total val loss: 0.5040 val r: 0.7553; time: 0.94sec
[337/800][24/24] total train loss: 0.0094; total val loss: 0.4888 val r: 0.7520; time: 0.94sec
[338/800][24/24] total train loss: 0.0094; total val loss: 0.5140 val r: 0.7514; time: 0.94sec
[339/800][24/24] total train loss: 0.0093; total val loss: 0.4928 val r: 0.7569; time: 0.96sec
[340/800][24/24] total train loss: 0.0092; total val loss: 0.4825 val r: 0.7551; time: 0.95sec
[341/800][24/24] total train loss: 0.0091; total val loss: 0.4911 val r: 0.7550; time: 0.96sec
[342/800][24/24] total train loss: 0.0088; total val loss: 0.5093 val r: 0.7550; time: 0.95sec
[343/800][24/24] total train loss: 0.0088; total val loss: 0.5071 val r: 0.7534; time: 0.94sec
[344/800][24/24] total train loss: 0.0089; total val loss: 0.4708 val r: 0.7546; time: 0.95sec
[345/800][24/24] total train loss: 0.0091; total val loss: 0.4999 val r: 0.7626; time: 0.93sec
[346/800][24/24] total train loss: 0.0090; total val loss: 0.4903 val r: 0.7569; time: 0.93sec
[347/800][24/24] total train loss: 0.0088; total val loss: 0.4956 val r: 0.7525; time: 0.93sec
[348/800][24/24] total train loss: 0.0087; total val loss: 0.4818 val r: 0.7537; time: 0.93sec
[349/800][24/24] total train loss: 0.0089; total val loss: 0.4894 val r: 0.7551; time: 0.94sec
[350/800][24/24] total train loss: 0.0088; total val loss: 0.4934 val r: 0.7569; time: 0.95sec
[351/800][24/24] total train loss: 0.0089; total val loss: 0.4870 val r: 0.7525; time: 0.94sec
[352/800][24/24] total train loss: 0.0090; total val loss: 0.5016 val r: 0.7531; time: 0.93sec
[353/800][24/24] total train loss: 0.0085; total val loss: 0.4819 val r: 0.7569; time: 0.94sec
[354/800][24/24] total train loss: 0.0090; total val loss: 0.4983 val r: 0.7572; time: 0.93sec
[355/800][24/24] total train loss: 0.0092; total val loss: 0.4974 val r: 0.7595; time: 0.93sec
[356/800][24/24] total train loss: 0.0089; total val loss: 0.5107 val r: 0.7500; time: 0.93sec
[357/800][24/24] total train loss: 0.0088; total val loss: 0.4971 val r: 0.7530; time: 0.93sec
[358/800][24/24] total train loss: 0.0087; total val loss: 0.4886 val r: 0.7497; time: 0.93sec
[359/800][24/24] total train loss: 0.0089; total val loss: 0.4722 val r: 0.7489; time: 0.93sec
[360/800][24/24] total train loss: 0.0091; total val loss: 0.4980 val r: 0.7541; time: 0.93sec
[361/800][24/24] total train loss: 0.0090; total val loss: 0.5010 val r: 0.7517; time: 0.94sec
[362/800][24/24] total train loss: 0.0088; total val loss: 0.4844 val r: 0.7541; time: 0.93sec
[363/800][24/24] total train loss: 0.0089; total val loss: 0.4960 val r: 0.7557; time: 0.93sec
[364/800][24/24] total train loss: 0.0087; total val loss: 0.5028 val r: 0.7600; time: 0.92sec
[365/800][24/24] total train loss: 0.0089; total val loss: 0.4663 val r: 0.7492; time: 0.93sec
[366/800][24/24] total train loss: 0.0090; total val loss: 0.5137 val r: 0.7581; time: 0.93sec
[367/800][24/24] total train loss: 0.0090; total val loss: 0.5020 val r: 0.7556; time: 0.94sec
[368/800][24/24] total train loss: 0.0087; total val loss: 0.5016 val r: 0.7590; time: 0.93sec
[369/800][24/24] total train loss: 0.0090; total val loss: 0.4873 val r: 0.7614; time: 0.94sec
[370/800][24/24] total train loss: 0.0089; total val loss: 0.4933 val r: 0.7497; time: 0.93sec
[371/800][24/24] total train loss: 0.0088; total val loss: 0.4969 val r: 0.7518; time: 0.93sec
[372/800][24/24] total train loss: 0.0087; total val loss: 0.4907 val r: 0.7551; time: 0.93sec
[373/800][24/24] total train loss: 0.0085; total val loss: 0.4927 val r: 0.7541; time: 0.93sec
[374/800][24/24] total train loss: 0.0089; total val loss: 0.5240 val r: 0.7561; time: 0.93sec
[375/800][24/24] total train loss: 0.0090; total val loss: 0.5117 val r: 0.7531; time: 0.93sec
[376/800][24/24] total train loss: 0.0090; total val loss: 0.5009 val r: 0.7532; time: 0.93sec
[377/800][24/24] total train loss: 0.0089; total val loss: 0.4852 val r: 0.7523; time: 0.93sec
[378/800][24/24] total train loss: 0.0089; total val loss: 0.5104 val r: 0.7571; time: 0.94sec
[379/800][24/24] total train loss: 0.0088; total val loss: 0.5102 val r: 0.7495; time: 0.94sec
[380/800][24/24] total train loss: 0.0088; total val loss: 0.4836 val r: 0.7539; time: 0.93sec
[381/800][24/24] total train loss: 0.0086; total val loss: 0.4830 val r: 0.7539; time: 0.93sec
[382/800][24/24] total train loss: 0.0091; total val loss: 0.5020 val r: 0.7571; time: 0.93sec
[383/800][24/24] total train loss: 0.0087; total val loss: 0.4884 val r: 0.7510; time: 0.94sec
[384/800][24/24] total train loss: 0.0090; total val loss: 0.4931 val r: 0.7573; time: 0.93sec
[385/800][24/24] total train loss: 0.0087; total val loss: 0.4994 val r: 0.7594; time: 0.93sec
[386/800][24/24] total train loss: 0.0088; total val loss: 0.5082 val r: 0.7536; time: 0.94sec
[387/800][24/24] total train loss: 0.0087; total val loss: 0.4933 val r: 0.7579; time: 0.94sec
[388/800][24/24] total train loss: 0.0090; total val loss: 0.4892 val r: 0.7550; time: 0.93sec
[389/800][24/24] total train loss: 0.0087; total val loss: 0.4918 val r: 0.7578; time: 0.94sec
[390/800][24/24] total train loss: 0.0088; total val loss: 0.4609 val r: 0.7479; time: 0.94sec
[391/800][24/24] total train loss: 0.0087; total val loss: 0.5183 val r: 0.7539; time: 0.94sec
[392/800][24/24] total train loss: 0.0088; total val loss: 0.5019 val r: 0.7537; time: 0.94sec
[393/800][24/24] total train loss: 0.0086; total val loss: 0.4833 val r: 0.7553; time: 0.94sec
[394/800][24/24] total train loss: 0.0088; total val loss: 0.5096 val r: 0.7542; time: 0.94sec
[395/800][24/24] total train loss: 0.0091; total val loss: 0.4885 val r: 0.7499; time: 0.94sec
[396/800][24/24] total train loss: 0.0087; total val loss: 0.5054 val r: 0.7583; time: 0.94sec
[397/800][24/24] total train loss: 0.0088; total val loss: 0.4886 val r: 0.7539; time: 0.94sec
[398/800][24/24] total train loss: 0.0092; total val loss: 0.4591 val r: 0.7504; time: 0.93sec
[399/800][24/24] total train loss: 0.0087; total val loss: 0.5119 val r: 0.7437; time: 0.94sec
learning rate updated: 0.001
[400/800][24/24] total train loss: 0.0087; total val loss: 0.5001 val r: 0.7518; time: 0.93sec
[401/800][24/24] total train loss: 0.0086; total val loss: 0.4915 val r: 0.7523; time: 0.94sec
[402/800][24/24] total train loss: 0.0087; total val loss: 0.4947 val r: 0.7506; time: 0.94sec
[403/800][24/24] total train loss: 0.0087; total val loss: 0.4950 val r: 0.7577; time: 0.94sec
[404/800][24/24] total train loss: 0.0088; total val loss: 0.5058 val r: 0.7640; time: 0.93sec
[405/800][24/24] total train loss: 0.0086; total val loss: 0.4924 val r: 0.7584; time: 0.93sec
[406/800][24/24] total train loss: 0.0085; total val loss: 0.5052 val r: 0.7530; time: 0.95sec
[407/800][24/24] total train loss: 0.0087; total val loss: 0.4941 val r: 0.7570; time: 0.93sec
[408/800][24/24] total train loss: 0.0087; total val loss: 0.5135 val r: 0.7535; time: 0.93sec
[409/800][24/24] total train loss: 0.0087; total val loss: 0.5048 val r: 0.7521; time: 0.93sec
[410/800][24/24] total train loss: 0.0088; total val loss: 0.5038 val r: 0.7540; time: 0.93sec
[411/800][24/24] total train loss: 0.0090; total val loss: 0.4984 val r: 0.7587; time: 0.94sec
[412/800][24/24] total train loss: 0.0086; total val loss: 0.5034 val r: 0.7544; time: 0.94sec
[413/800][24/24] total train loss: 0.0086; total val loss: 0.4881 val r: 0.7599; time: 0.94sec
[414/800][24/24] total train loss: 0.0087; total val loss: 0.4956 val r: 0.7634; time: 0.93sec
[415/800][24/24] total train loss: 0.0089; total val loss: 0.4918 val r: 0.7526; time: 0.93sec
[416/800][24/24] total train loss: 0.0087; total val loss: 0.4902 val r: 0.7591; time: 0.93sec
[417/800][24/24] total train loss: 0.0086; total val loss: 0.4799 val r: 0.7552; time: 0.93sec
[418/800][24/24] total train loss: 0.0088; total val loss: 0.5074 val r: 0.7571; time: 0.93sec
[419/800][24/24] total train loss: 0.0087; total val loss: 0.4818 val r: 0.7534; time: 0.93sec
[420/800][24/24] total train loss: 0.0086; total val loss: 0.4956 val r: 0.7488; time: 0.94sec
[421/800][24/24] total train loss: 0.0090; total val loss: 0.4838 val r: 0.7463; time: 0.95sec
[422/800][24/24] total train loss: 0.0086; total val loss: 0.5005 val r: 0.7501; time: 0.94sec
[423/800][24/24] total train loss: 0.0086; total val loss: 0.5036 val r: 0.7547; time: 0.94sec
[424/800][24/24] total train loss: 0.0086; total val loss: 0.4846 val r: 0.7543; time: 0.93sec
[425/800][24/24] total train loss: 0.0090; total val loss: 0.4931 val r: 0.7538; time: 0.93sec
[426/800][24/24] total train loss: 0.0090; total val loss: 0.5071 val r: 0.7495; time: 0.94sec
[427/800][24/24] total train loss: 0.0090; total val loss: 0.5150 val r: 0.7484; time: 0.93sec
[428/800][24/24] total train loss: 0.0085; total val loss: 0.4856 val r: 0.7519; time: 0.94sec
[429/800][24/24] total train loss: 0.0087; total val loss: 0.5089 val r: 0.7543; time: 0.94sec
[430/800][24/24] total train loss: 0.0087; total val loss: 0.4916 val r: 0.7530; time: 0.93sec
[431/800][24/24] total train loss: 0.0090; total val loss: 0.4942 val r: 0.7551; time: 0.93sec
[432/800][24/24] total train loss: 0.0090; total val loss: 0.5214 val r: 0.7542; time: 0.94sec
[433/800][24/24] total train loss: 0.0089; total val loss: 0.4908 val r: 0.7552; time: 0.93sec
[434/800][24/24] total train loss: 0.0088; total val loss: 0.4902 val r: 0.7519; time: 0.93sec
[435/800][24/24] total train loss: 0.0091; total val loss: 0.4967 val r: 0.7577; time: 0.94sec
[436/800][24/24] total train loss: 0.0088; total val loss: 0.5084 val r: 0.7534; time: 0.93sec
[437/800][24/24] total train loss: 0.0091; total val loss: 0.5062 val r: 0.7576; time: 0.92sec
[438/800][24/24] total train loss: 0.0091; total val loss: 0.5089 val r: 0.7493; time: 0.93sec
[439/800][24/24] total train loss: 0.0087; total val loss: 0.5229 val r: 0.7550; time: 0.94sec
[440/800][24/24] total train loss: 0.0172; total val loss: 0.4772 val r: 0.7405; time: 0.93sec
[441/800][24/24] total train loss: 0.0371; total val loss: 0.5092 val r: 0.7343; time: 0.93sec
[442/800][24/24] total train loss: 0.0344; total val loss: 0.5092 val r: 0.7204; time: 0.93sec
[443/800][24/24] total train loss: 0.0267; total val loss: 0.5176 val r: 0.7491; time: 0.94sec
[444/800][24/24] total train loss: 0.0221; total val loss: 0.5136 val r: 0.7364; time: 0.93sec
[445/800][24/24] total train loss: 0.0157; total val loss: 0.4857 val r: 0.7365; time: 0.93sec
[446/800][24/24] total train loss: 0.0120; total val loss: 0.4817 val r: 0.7367; time: 0.93sec
[447/800][24/24] total train loss: 0.0100; total val loss: 0.4874 val r: 0.7451; time: 0.93sec
[448/800][24/24] total train loss: 0.0095; total val loss: 0.4737 val r: 0.7434; time: 0.93sec
[449/800][24/24] total train loss: 0.0091; total val loss: 0.4926 val r: 0.7447; time: 0.93sec
[450/800][24/24] total train loss: 0.0094; total val loss: 0.5043 val r: 0.7456; time: 0.93sec
[451/800][24/24] total train loss: 0.0092; total val loss: 0.4913 val r: 0.7393; time: 0.93sec
[452/800][24/24] total train loss: 0.0092; total val loss: 0.4959 val r: 0.7388; time: 0.93sec
[453/800][24/24] total train loss: 0.0092; total val loss: 0.4921 val r: 0.7377; time: 0.94sec
[454/800][24/24] total train loss: 0.0089; total val loss: 0.4923 val r: 0.7434; time: 0.94sec
[455/800][24/24] total train loss: 0.0089; total val loss: 0.4920 val r: 0.7482; time: 0.93sec
[456/800][24/24] total train loss: 0.0088; total val loss: 0.4880 val r: 0.7396; time: 0.93sec
[457/800][24/24] total train loss: 0.0087; total val loss: 0.4666 val r: 0.7436; time: 0.94sec
[458/800][24/24] total train loss: 0.0089; total val loss: 0.4995 val r: 0.7462; time: 0.93sec
[459/800][24/24] total train loss: 0.0090; total val loss: 0.4846 val r: 0.7421; time: 0.94sec
[460/800][24/24] total train loss: 0.0089; total val loss: 0.4902 val r: 0.7408; time: 0.94sec
[461/800][24/24] total train loss: 0.0089; total val loss: 0.4886 val r: 0.7492; time: 0.94sec
[462/800][24/24] total train loss: 0.0087; total val loss: 0.5022 val r: 0.7426; time: 0.94sec
[463/800][24/24] total train loss: 0.0087; total val loss: 0.4898 val r: 0.7440; time: 0.94sec
[464/800][24/24] total train loss: 0.0090; total val loss: 0.4992 val r: 0.7430; time: 0.93sec
[465/800][24/24] total train loss: 0.0086; total val loss: 0.4982 val r: 0.7441; time: 0.93sec
[466/800][24/24] total train loss: 0.0087; total val loss: 0.4828 val r: 0.7398; time: 0.93sec
[467/800][24/24] total train loss: 0.0087; total val loss: 0.4956 val r: 0.7404; time: 0.93sec
[468/800][24/24] total train loss: 0.0085; total val loss: 0.4866 val r: 0.7412; time: 0.93sec
[469/800][24/24] total train loss: 0.0089; total val loss: 0.5173 val r: 0.7442; time: 0.93sec
[470/800][24/24] total train loss: 0.0090; total val loss: 0.4911 val r: 0.7435; time: 0.93sec
[471/800][24/24] total train loss: 0.0087; total val loss: 0.4831 val r: 0.7391; time: 0.93sec
[472/800][24/24] total train loss: 0.0088; total val loss: 0.4898 val r: 0.7443; time: 0.94sec
[473/800][24/24] total train loss: 0.0087; total val loss: 0.4875 val r: 0.7394; time: 0.93sec
[474/800][24/24] total train loss: 0.0086; total val loss: 0.4780 val r: 0.7427; time: 0.93sec
[475/800][24/24] total train loss: 0.0087; total val loss: 0.4918 val r: 0.7359; time: 0.93sec
[476/800][24/24] total train loss: 0.0086; total val loss: 0.5022 val r: 0.7436; time: 0.93sec
[477/800][24/24] total train loss: 0.0088; total val loss: 0.4975 val r: 0.7398; time: 0.94sec
[478/800][24/24] total train loss: 0.0086; total val loss: 0.4790 val r: 0.7396; time: 0.94sec
[479/800][24/24] total train loss: 0.0087; total val loss: 0.4918 val r: 0.7407; time: 0.93sec
[480/800][24/24] total train loss: 0.0085; total val loss: 0.4921 val r: 0.7422; time: 0.93sec
[481/800][24/24] total train loss: 0.0088; total val loss: 0.4912 val r: 0.7435; time: 0.93sec
[482/800][24/24] total train loss: 0.0088; total val loss: 0.4994 val r: 0.7460; time: 0.93sec
[483/800][24/24] total train loss: 0.0083; total val loss: 0.4883 val r: 0.7436; time: 0.92sec
[484/800][24/24] total train loss: 0.0081; total val loss: 0.4851 val r: 0.7399; time: 0.93sec
[485/800][24/24] total train loss: 0.0087; total val loss: 0.4980 val r: 0.7417; time: 0.94sec
[486/800][24/24] total train loss: 0.0086; total val loss: 0.4750 val r: 0.7435; time: 0.93sec
[487/800][24/24] total train loss: 0.0088; total val loss: 0.5037 val r: 0.7405; time: 0.94sec
[488/800][24/24] total train loss: 0.0087; total val loss: 0.5002 val r: 0.7423; time: 0.94sec
[489/800][24/24] total train loss: 0.0087; total val loss: 0.4903 val r: 0.7443; time: 0.93sec
[490/800][24/24] total train loss: 0.0088; total val loss: 0.4991 val r: 0.7418; time: 0.94sec
[491/800][24/24] total train loss: 0.0089; total val loss: 0.4887 val r: 0.7446; time: 0.94sec
[492/800][24/24] total train loss: 0.0088; total val loss: 0.4918 val r: 0.7467; time: 0.93sec
[493/800][24/24] total train loss: 0.0086; total val loss: 0.4826 val r: 0.7409; time: 0.93sec
[494/800][24/24] total train loss: 0.0087; total val loss: 0.4816 val r: 0.7458; time: 0.93sec
[495/800][24/24] total train loss: 0.0084; total val loss: 0.4851 val r: 0.7434; time: 0.94sec
[496/800][24/24] total train loss: 0.0086; total val loss: 0.5054 val r: 0.7431; time: 0.94sec
[497/800][24/24] total train loss: 0.0086; total val loss: 0.4962 val r: 0.7459; time: 0.93sec
[498/800][24/24] total train loss: 0.0085; total val loss: 0.4826 val r: 0.7426; time: 0.94sec
[499/800][24/24] total train loss: 0.0085; total val loss: 0.4830 val r: 0.7408; time: 0.94sec
learning rate updated: 0.001
[500/800][24/24] total train loss: 0.0087; total val loss: 0.4880 val r: 0.7455; time: 0.93sec
[501/800][24/24] total train loss: 0.0087; total val loss: 0.4893 val r: 0.7390; time: 0.93sec
[502/800][24/24] total train loss: 0.0089; total val loss: 0.5008 val r: 0.7419; time: 0.93sec
[503/800][24/24] total train loss: 0.0087; total val loss: 0.4838 val r: 0.7414; time: 0.94sec
[504/800][24/24] total train loss: 0.0089; total val loss: 0.5067 val r: 0.7414; time: 0.94sec
[505/800][24/24] total train loss: 0.0086; total val loss: 0.5009 val r: 0.7500; time: 0.94sec
[506/800][24/24] total train loss: 0.0085; total val loss: 0.4882 val r: 0.7404; time: 0.93sec
[507/800][24/24] total train loss: 0.0084; total val loss: 0.5019 val r: 0.7470; time: 0.94sec
[508/800][24/24] total train loss: 0.0084; total val loss: 0.4968 val r: 0.7409; time: 0.94sec
[509/800][24/24] total train loss: 0.0088; total val loss: 0.4840 val r: 0.7437; time: 0.93sec
[510/800][24/24] total train loss: 0.0086; total val loss: 0.5104 val r: 0.7447; time: 0.93sec
[511/800][24/24] total train loss: 0.0084; total val loss: 0.4950 val r: 0.7481; time: 0.94sec
[512/800][24/24] total train loss: 0.0087; total val loss: 0.4754 val r: 0.7446; time: 0.94sec
[513/800][24/24] total train loss: 0.0086; total val loss: 0.4907 val r: 0.7428; time: 0.94sec
[514/800][24/24] total train loss: 0.0084; total val loss: 0.4880 val r: 0.7433; time: 0.93sec
[515/800][24/24] total train loss: 0.0084; total val loss: 0.4877 val r: 0.7424; time: 0.93sec
[516/800][24/24] total train loss: 0.0087; total val loss: 0.5001 val r: 0.7432; time: 0.93sec
[517/800][24/24] total train loss: 0.0085; total val loss: 0.5033 val r: 0.7436; time: 0.93sec
[518/800][24/24] total train loss: 0.0088; total val loss: 0.4881 val r: 0.7416; time: 0.94sec
[519/800][24/24] total train loss: 0.0085; total val loss: 0.5019 val r: 0.7401; time: 0.94sec
[520/800][24/24] total train loss: 0.0084; total val loss: 0.5087 val r: 0.7488; time: 0.94sec
[521/800][24/24] total train loss: 0.0087; total val loss: 0.4949 val r: 0.7421; time: 0.93sec
[522/800][24/24] total train loss: 0.0084; total val loss: 0.4801 val r: 0.7475; time: 0.92sec
[523/800][24/24] total train loss: 0.0085; total val loss: 0.4943 val r: 0.7435; time: 0.93sec
[524/800][24/24] total train loss: 0.0084; total val loss: 0.4964 val r: 0.7475; time: 0.94sec
[525/800][24/24] total train loss: 0.0085; total val loss: 0.5007 val r: 0.7419; time: 0.93sec
[526/800][24/24] total train loss: 0.0085; total val loss: 0.4960 val r: 0.7411; time: 0.93sec
[527/800][24/24] total train loss: 0.0086; total val loss: 0.4912 val r: 0.7437; time: 0.93sec
[528/800][24/24] total train loss: 0.0084; total val loss: 0.4979 val r: 0.7412; time: 0.94sec
[529/800][24/24] total train loss: 0.0084; total val loss: 0.4994 val r: 0.7445; time: 0.93sec
[530/800][24/24] total train loss: 0.0088; total val loss: 0.4952 val r: 0.7432; time: 0.94sec
[531/800][24/24] total train loss: 0.0086; total val loss: 0.5018 val r: 0.7438; time: 0.93sec
[532/800][24/24] total train loss: 0.0089; total val loss: 0.4886 val r: 0.7429; time: 0.94sec
[533/800][24/24] total train loss: 0.0088; total val loss: 0.5113 val r: 0.7457; time: 0.93sec
[534/800][24/24] total train loss: 0.0085; total val loss: 0.4748 val r: 0.7428; time: 0.94sec
[535/800][24/24] total train loss: 0.0087; total val loss: 0.4855 val r: 0.7402; time: 0.94sec
[536/800][24/24] total train loss: 0.0086; total val loss: 0.4995 val r: 0.7436; time: 0.93sec
[537/800][24/24] total train loss: 0.0088; total val loss: 0.4716 val r: 0.7361; time: 0.93sec
[538/800][24/24] total train loss: 0.0085; total val loss: 0.4877 val r: 0.7428; time: 0.93sec
[539/800][24/24] total train loss: 0.0085; total val loss: 0.4976 val r: 0.7451; time: 0.93sec
[540/800][24/24] total train loss: 0.0084; total val loss: 0.5014 val r: 0.7432; time: 0.94sec
[541/800][24/24] total train loss: 0.0084; total val loss: 0.4899 val r: 0.7413; time: 0.93sec
[542/800][24/24] total train loss: 0.0084; total val loss: 0.4832 val r: 0.7478; time: 0.93sec
[543/800][24/24] total train loss: 0.0085; total val loss: 0.4972 val r: 0.7488; time: 0.93sec
[544/800][24/24] total train loss: 0.0086; total val loss: 0.4965 val r: 0.7425; time: 0.94sec
[545/800][24/24] total train loss: 0.0085; total val loss: 0.4850 val r: 0.7437; time: 0.93sec
[546/800][24/24] total train loss: 0.0084; total val loss: 0.4779 val r: 0.7428; time: 0.94sec
[547/800][24/24] total train loss: 0.0085; total val loss: 0.4931 val r: 0.7433; time: 0.94sec
[548/800][24/24] total train loss: 0.0083; total val loss: 0.5043 val r: 0.7474; time: 0.93sec
[549/800][24/24] total train loss: 0.0086; total val loss: 0.4828 val r: 0.7407; time: 0.94sec
[550/800][24/24] total train loss: 0.0086; total val loss: 0.5093 val r: 0.7465; time: 0.93sec
[551/800][24/24] total train loss: 0.0087; total val loss: 0.4973 val r: 0.7433; time: 0.93sec
[552/800][24/24] total train loss: 0.0085; total val loss: 0.4892 val r: 0.7441; time: 0.93sec
[553/800][24/24] total train loss: 0.0084; total val loss: 0.4851 val r: 0.7411; time: 0.93sec
[554/800][24/24] total train loss: 0.0086; total val loss: 0.5006 val r: 0.7463; time: 0.93sec
[555/800][24/24] total train loss: 0.0087; total val loss: 0.4968 val r: 0.7465; time: 0.93sec
[556/800][24/24] total train loss: 0.0086; total val loss: 0.4853 val r: 0.7448; time: 0.93sec
[557/800][24/24] total train loss: 0.0087; total val loss: 0.5024 val r: 0.7461; time: 0.93sec
[558/800][24/24] total train loss: 0.0090; total val loss: 0.4981 val r: 0.7440; time: 0.93sec
[559/800][24/24] total train loss: 0.0088; total val loss: 0.4954 val r: 0.7406; time: 0.93sec
[560/800][24/24] total train loss: 0.0086; total val loss: 0.4926 val r: 0.7411; time: 0.93sec
[561/800][24/24] total train loss: 0.0084; total val loss: 0.5060 val r: 0.7409; time: 0.94sec
[562/800][24/24] total train loss: 0.0085; total val loss: 0.4851 val r: 0.7386; time: 0.93sec
[563/800][24/24] total train loss: 0.0084; total val loss: 0.4984 val r: 0.7470; time: 0.93sec
[564/800][24/24] total train loss: 0.0085; total val loss: 0.4740 val r: 0.7373; time: 0.94sec
[565/800][24/24] total train loss: 0.0089; total val loss: 0.4972 val r: 0.7462; time: 0.93sec
[566/800][24/24] total train loss: 0.0087; total val loss: 0.4956 val r: 0.7405; time: 0.93sec
[567/800][24/24] total train loss: 0.0086; total val loss: 0.4864 val r: 0.7443; time: 0.93sec
[568/800][24/24] total train loss: 0.0084; total val loss: 0.4926 val r: 0.7417; time: 0.94sec
[569/800][24/24] total train loss: 0.0087; total val loss: 0.4793 val r: 0.7431; time: 0.94sec
[570/800][24/24] total train loss: 0.0084; total val loss: 0.4803 val r: 0.7415; time: 0.93sec
[571/800][24/24] total train loss: 0.0085; total val loss: 0.5007 val r: 0.7387; time: 0.93sec
[572/800][24/24] total train loss: 0.0087; total val loss: 0.4794 val r: 0.7398; time: 0.93sec
[573/800][24/24] total train loss: 0.0086; total val loss: 0.4911 val r: 0.7368; time: 0.93sec
[574/800][24/24] total train loss: 0.0084; total val loss: 0.4799 val r: 0.7434; time: 0.94sec
[575/800][24/24] total train loss: 0.0083; total val loss: 0.4923 val r: 0.7468; time: 0.93sec
[576/800][24/24] total train loss: 0.0084; total val loss: 0.4847 val r: 0.7470; time: 0.93sec
[577/800][24/24] total train loss: 0.0082; total val loss: 0.5151 val r: 0.7425; time: 0.94sec
[578/800][24/24] total train loss: 0.0088; total val loss: 0.4865 val r: 0.7457; time: 0.93sec
[579/800][24/24] total train loss: 0.0084; total val loss: 0.4844 val r: 0.7436; time: 0.93sec
[580/800][24/24] total train loss: 0.0083; total val loss: 0.4988 val r: 0.7428; time: 0.93sec
[581/800][24/24] total train loss: 0.0084; total val loss: 0.4979 val r: 0.7461; time: 0.94sec
[582/800][24/24] total train loss: 0.0087; total val loss: 0.4968 val r: 0.7394; time: 0.94sec
[583/800][24/24] total train loss: 0.0093; total val loss: 0.4865 val r: 0.7428; time: 0.93sec
[584/800][24/24] total train loss: 0.0088; total val loss: 0.4922 val r: 0.7461; time: 0.93sec
[585/800][24/24] total train loss: 0.0089; total val loss: 0.4939 val r: 0.7410; time: 0.94sec
[586/800][24/24] total train loss: 0.0086; total val loss: 0.4976 val r: 0.7423; time: 0.94sec
[587/800][24/24] total train loss: 0.0087; total val loss: 0.4912 val r: 0.7409; time: 0.93sec
[588/800][24/24] total train loss: 0.0083; total val loss: 0.5053 val r: 0.7402; time: 0.94sec
[589/800][24/24] total train loss: 0.0083; total val loss: 0.4793 val r: 0.7406; time: 0.94sec
[590/800][24/24] total train loss: 0.0081; total val loss: 0.4864 val r: 0.7450; time: 0.93sec
[591/800][24/24] total train loss: 0.0087; total val loss: 0.5002 val r: 0.7417; time: 0.93sec
[592/800][24/24] total train loss: 0.0086; total val loss: 0.4805 val r: 0.7425; time: 0.93sec
[593/800][24/24] total train loss: 0.0086; total val loss: 0.4797 val r: 0.7433; time: 0.94sec
[594/800][24/24] total train loss: 0.0085; total val loss: 0.4803 val r: 0.7441; time: 0.93sec
[595/800][24/24] total train loss: 0.0082; total val loss: 0.4799 val r: 0.7421; time: 0.93sec
[596/800][24/24] total train loss: 0.0087; total val loss: 0.4962 val r: 0.7424; time: 0.93sec
[597/800][24/24] total train loss: 0.0084; total val loss: 0.5026 val r: 0.7385; time: 0.94sec
[598/800][24/24] total train loss: 0.0086; total val loss: 0.5034 val r: 0.7433; time: 0.93sec
[599/800][24/24] total train loss: 0.0085; total val loss: 0.5023 val r: 0.7382; time: 0.94sec
learning rate updated: 0.001
[600/800][24/24] total train loss: 0.0083; total val loss: 0.4991 val r: 0.7402; time: 0.93sec
[601/800][24/24] total train loss: 0.0083; total val loss: 0.4754 val r: 0.7369; time: 0.93sec
[602/800][24/24] total train loss: 0.0086; total val loss: 0.4969 val r: 0.7454; time: 0.93sec
[603/800][24/24] total train loss: 0.0082; total val loss: 0.4817 val r: 0.7391; time: 0.93sec
[604/800][24/24] total train loss: 0.0084; total val loss: 0.4999 val r: 0.7399; time: 0.93sec
[605/800][24/24] total train loss: 0.0083; total val loss: 0.4811 val r: 0.7376; time: 0.93sec
[606/800][24/24] total train loss: 0.0084; total val loss: 0.4963 val r: 0.7466; time: 0.94sec
[607/800][24/24] total train loss: 0.0086; total val loss: 0.5040 val r: 0.7392; time: 0.94sec
[608/800][24/24] total train loss: 0.0083; total val loss: 0.4542 val r: 0.7397; time: 0.93sec
[609/800][24/24] total train loss: 0.0083; total val loss: 0.5084 val r: 0.7455; time: 0.93sec
[610/800][24/24] total train loss: 0.0085; total val loss: 0.4702 val r: 0.7439; time: 0.93sec
[611/800][24/24] total train loss: 0.0087; total val loss: 0.4972 val r: 0.7412; time: 0.93sec
[612/800][24/24] total train loss: 0.0085; total val loss: 0.4915 val r: 0.7436; time: 0.94sec
[613/800][24/24] total train loss: 0.0083; total val loss: 0.4908 val r: 0.7444; time: 0.93sec
[614/800][24/24] total train loss: 0.0083; total val loss: 0.5011 val r: 0.7414; time: 0.94sec
[615/800][24/24] total train loss: 0.0085; total val loss: 0.4959 val r: 0.7448; time: 0.93sec
[616/800][24/24] total train loss: 0.0085; total val loss: 0.5020 val r: 0.7449; time: 0.94sec
[617/800][24/24] total train loss: 0.0083; total val loss: 0.5014 val r: 0.7432; time: 0.93sec
[618/800][24/24] total train loss: 0.0084; total val loss: 0.4864 val r: 0.7432; time: 0.94sec
[619/800][24/24] total train loss: 0.0087; total val loss: 0.4949 val r: 0.7412; time: 0.94sec
[620/800][24/24] total train loss: 0.0084; total val loss: 0.4697 val r: 0.7434; time: 0.94sec
[621/800][24/24] total train loss: 0.0082; total val loss: 0.4950 val r: 0.7445; time: 0.93sec
[622/800][24/24] total train loss: 0.0086; total val loss: 0.4976 val r: 0.7413; time: 0.94sec
[623/800][24/24] total train loss: 0.0084; total val loss: 0.4913 val r: 0.7407; time: 0.94sec
[624/800][24/24] total train loss: 0.0082; total val loss: 0.4983 val r: 0.7467; time: 0.93sec
[625/800][24/24] total train loss: 0.0087; total val loss: 0.5040 val r: 0.7415; time: 0.93sec
[626/800][24/24] total train loss: 0.0081; total val loss: 0.4824 val r: 0.7376; time: 0.93sec
[627/800][24/24] total train loss: 0.0082; total val loss: 0.4932 val r: 0.7428; time: 0.94sec
[628/800][24/24] total train loss: 0.0081; total val loss: 0.4896 val r: 0.7415; time: 0.94sec
[629/800][24/24] total train loss: 0.0083; total val loss: 0.4945 val r: 0.7406; time: 0.93sec
[630/800][24/24] total train loss: 0.0080; total val loss: 0.4861 val r: 0.7385; time: 0.93sec
[631/800][24/24] total train loss: 0.0086; total val loss: 0.4734 val r: 0.7398; time: 0.93sec
[632/800][24/24] total train loss: 0.0087; total val loss: 0.4894 val r: 0.7422; time: 0.94sec
[633/800][24/24] total train loss: 0.0084; total val loss: 0.4798 val r: 0.7414; time: 0.93sec
[634/800][24/24] total train loss: 0.0083; total val loss: 0.4728 val r: 0.7464; time: 0.93sec
[635/800][24/24] total train loss: 0.0085; total val loss: 0.4974 val r: 0.7470; time: 0.93sec
[636/800][24/24] total train loss: 0.0084; total val loss: 0.4931 val r: 0.7457; time: 0.93sec
[637/800][24/24] total train loss: 0.0090; total val loss: 0.5090 val r: 0.7439; time: 0.94sec
[638/800][24/24] total train loss: 0.0082; total val loss: 0.4759 val r: 0.7452; time: 0.93sec
[639/800][24/24] total train loss: 0.0086; total val loss: 0.4862 val r: 0.7445; time: 0.94sec
[640/800][24/24] total train loss: 0.0084; total val loss: 0.4896 val r: 0.7423; time: 0.92sec
[641/800][24/24] total train loss: 0.0081; total val loss: 0.5087 val r: 0.7428; time: 0.93sec
[642/800][24/24] total train loss: 0.0081; total val loss: 0.4944 val r: 0.7399; time: 0.94sec
[643/800][24/24] total train loss: 0.0087; total val loss: 0.5050 val r: 0.7398; time: 0.93sec
[644/800][24/24] total train loss: 0.0082; total val loss: 0.4787 val r: 0.7457; time: 0.93sec
[645/800][24/24] total train loss: 0.0086; total val loss: 0.5017 val r: 0.7412; time: 0.93sec
[646/800][24/24] total train loss: 0.0090; total val loss: 0.4952 val r: 0.7432; time: 0.94sec
[647/800][24/24] total train loss: 0.0082; total val loss: 0.4803 val r: 0.7409; time: 0.94sec
[648/800][24/24] total train loss: 0.0085; total val loss: 0.4824 val r: 0.7458; time: 0.93sec
[649/800][24/24] total train loss: 0.0083; total val loss: 0.4897 val r: 0.7418; time: 0.94sec
[650/800][24/24] total train loss: 0.0087; total val loss: 0.4957 val r: 0.7382; time: 0.93sec
[651/800][24/24] total train loss: 0.0085; total val loss: 0.4939 val r: 0.7437; time: 0.93sec
[652/800][24/24] total train loss: 0.0083; total val loss: 0.4819 val r: 0.7400; time: 0.93sec
[653/800][24/24] total train loss: 0.0082; total val loss: 0.4987 val r: 0.7417; time: 0.94sec
[654/800][24/24] total train loss: 0.0086; total val loss: 0.5104 val r: 0.7444; time: 0.93sec
[655/800][24/24] total train loss: 0.0085; total val loss: 0.4727 val r: 0.7454; time: 0.94sec
[656/800][24/24] total train loss: 0.0086; total val loss: 0.4909 val r: 0.7414; time: 0.93sec
[657/800][24/24] total train loss: 0.0086; total val loss: 0.4930 val r: 0.7432; time: 0.93sec
[658/800][24/24] total train loss: 0.0086; total val loss: 0.4963 val r: 0.7482; time: 0.93sec
[659/800][24/24] total train loss: 0.0086; total val loss: 0.4920 val r: 0.7474; time: 0.94sec
[660/800][24/24] total train loss: 0.0084; total val loss: 0.4972 val r: 0.7423; time: 0.93sec
[661/800][24/24] total train loss: 0.0085; total val loss: 0.5044 val r: 0.7435; time: 0.93sec
[662/800][24/24] total train loss: 0.0082; total val loss: 0.4783 val r: 0.7401; time: 0.93sec
[663/800][24/24] total train loss: 0.0086; total val loss: 0.5033 val r: 0.7419; time: 0.93sec
[664/800][24/24] total train loss: 0.0084; total val loss: 0.5026 val r: 0.7444; time: 0.94sec
[665/800][24/24] total train loss: 0.0084; total val loss: 0.5047 val r: 0.7443; time: 0.94sec
[666/800][24/24] total train loss: 0.0086; total val loss: 0.4902 val r: 0.7405; time: 0.93sec
[667/800][24/24] total train loss: 0.0084; total val loss: 0.4855 val r: 0.7392; time: 0.93sec
[668/800][24/24] total train loss: 0.0087; total val loss: 0.5095 val r: 0.7481; time: 0.93sec
[669/800][24/24] total train loss: 0.0083; total val loss: 0.5066 val r: 0.7442; time: 0.93sec
[670/800][24/24] total train loss: 0.0083; total val loss: 0.5022 val r: 0.7439; time: 0.94sec
[671/800][24/24] total train loss: 0.0085; total val loss: 0.5035 val r: 0.7411; time: 0.93sec
[672/800][24/24] total train loss: 0.0082; total val loss: 0.4918 val r: 0.7426; time: 0.93sec
[673/800][24/24] total train loss: 0.0085; total val loss: 0.4845 val r: 0.7429; time: 0.94sec
[674/800][24/24] total train loss: 0.0086; total val loss: 0.4904 val r: 0.7388; time: 0.93sec
[675/800][24/24] total train loss: 0.0083; total val loss: 0.4993 val r: 0.7412; time: 0.95sec
[676/800][24/24] total train loss: 0.0082; total val loss: 0.4897 val r: 0.7462; time: 0.94sec
[677/800][24/24] total train loss: 0.0084; total val loss: 0.4950 val r: 0.7435; time: 0.95sec
[678/800][24/24] total train loss: 0.0084; total val loss: 0.5067 val r: 0.7449; time: 0.95sec
[679/800][24/24] total train loss: 0.0087; total val loss: 0.4975 val r: 0.7400; time: 0.94sec
[680/800][24/24] total train loss: 0.0085; total val loss: 0.4843 val r: 0.7454; time: 0.95sec
[681/800][24/24] total train loss: 0.0082; total val loss: 0.4950 val r: 0.7420; time: 0.94sec
[682/800][24/24] total train loss: 0.0083; total val loss: 0.4779 val r: 0.7438; time: 0.93sec
[683/800][24/24] total train loss: 0.0083; total val loss: 0.4955 val r: 0.7417; time: 0.94sec
[684/800][24/24] total train loss: 0.0083; total val loss: 0.5047 val r: 0.7454; time: 0.93sec
[685/800][24/24] total train loss: 0.0084; total val loss: 0.4921 val r: 0.7432; time: 0.93sec
[686/800][24/24] total train loss: 0.0084; total val loss: 0.4894 val r: 0.7362; time: 0.96sec
[687/800][24/24] total train loss: 0.0082; total val loss: 0.4873 val r: 0.7457; time: 0.94sec
[688/800][24/24] total train loss: 0.0083; total val loss: 0.4913 val r: 0.7390; time: 0.94sec
[689/800][24/24] total train loss: 0.0081; total val loss: 0.4956 val r: 0.7429; time: 0.95sec
[690/800][24/24] total train loss: 0.0085; total val loss: 0.5050 val r: 0.7445; time: 0.95sec
[691/800][24/24] total train loss: 0.0084; total val loss: 0.4903 val r: 0.7436; time: 0.94sec
[692/800][24/24] total train loss: 0.0084; total val loss: 0.4909 val r: 0.7392; time: 0.94sec
[693/800][24/24] total train loss: 0.0086; total val loss: 0.4819 val r: 0.7411; time: 0.94sec
[694/800][24/24] total train loss: 0.0085; total val loss: 0.4934 val r: 0.7439; time: 0.94sec
[695/800][24/24] total train loss: 0.0086; total val loss: 0.5098 val r: 0.7438; time: 0.93sec
[696/800][24/24] total train loss: 0.0086; total val loss: 0.4885 val r: 0.7376; time: 0.94sec
[697/800][24/24] total train loss: 0.0086; total val loss: 0.5184 val r: 0.7427; time: 0.94sec
[698/800][24/24] total train loss: 0.0084; total val loss: 0.5022 val r: 0.7453; time: 0.95sec
[699/800][24/24] total train loss: 0.0084; total val loss: 0.4850 val r: 0.7404; time: 0.94sec
learning rate updated: 0.001
[700/800][24/24] total train loss: 0.0082; total val loss: 0.4920 val r: 0.7430; time: 0.94sec
[701/800][24/24] total train loss: 0.0084; total val loss: 0.4769 val r: 0.7405; time: 0.94sec
[702/800][24/24] total train loss: 0.0084; total val loss: 0.5072 val r: 0.7441; time: 0.95sec
[703/800][24/24] total train loss: 0.0082; total val loss: 0.4999 val r: 0.7362; time: 0.94sec
[704/800][24/24] total train loss: 0.0083; total val loss: 0.5057 val r: 0.7418; time: 0.94sec
[705/800][24/24] total train loss: 0.0082; total val loss: 0.4887 val r: 0.7417; time: 0.94sec
[706/800][24/24] total train loss: 0.0083; total val loss: 0.5044 val r: 0.7413; time: 0.94sec
[707/800][24/24] total train loss: 0.0083; total val loss: 0.4891 val r: 0.7459; time: 0.94sec
[708/800][24/24] total train loss: 0.0082; total val loss: 0.4745 val r: 0.7435; time: 0.94sec
[709/800][24/24] total train loss: 0.0083; total val loss: 0.4871 val r: 0.7417; time: 0.95sec
[710/800][24/24] total train loss: 0.0082; total val loss: 0.4878 val r: 0.7451; time: 0.94sec
[711/800][24/24] total train loss: 0.0081; total val loss: 0.4899 val r: 0.7456; time: 0.95sec
[712/800][24/24] total train loss: 0.0080; total val loss: 0.4774 val r: 0.7398; time: 0.94sec
[713/800][24/24] total train loss: 0.0083; total val loss: 0.4939 val r: 0.7415; time: 0.95sec
[714/800][24/24] total train loss: 0.0081; total val loss: 0.5098 val r: 0.7501; time: 0.94sec
[715/800][24/24] total train loss: 0.0083; total val loss: 0.4865 val r: 0.7447; time: 0.94sec
[716/800][24/24] total train loss: 0.0082; total val loss: 0.4949 val r: 0.7465; time: 0.94sec
[717/800][24/24] total train loss: 0.0088; total val loss: 0.4950 val r: 0.7417; time: 0.95sec
[718/800][24/24] total train loss: 0.0086; total val loss: 0.4917 val r: 0.7408; time: 0.95sec
[719/800][24/24] total train loss: 0.0085; total val loss: 0.5025 val r: 0.7455; time: 0.94sec
[720/800][24/24] total train loss: 0.0084; total val loss: 0.4872 val r: 0.7425; time: 0.95sec
[721/800][24/24] total train loss: 0.0085; total val loss: 0.4867 val r: 0.7418; time: 0.94sec
[722/800][24/24] total train loss: 0.0086; total val loss: 0.4847 val r: 0.7457; time: 0.94sec
[723/800][24/24] total train loss: 0.0083; total val loss: 0.4933 val r: 0.7436; time: 0.94sec
[724/800][24/24] total train loss: 0.0081; total val loss: 0.4983 val r: 0.7437; time: 0.95sec
[725/800][24/24] total train loss: 0.0084; total val loss: 0.5109 val r: 0.7457; time: 0.94sec
[726/800][24/24] total train loss: 0.0084; total val loss: 0.4849 val r: 0.7461; time: 0.94sec
[727/800][24/24] total train loss: 0.0083; total val loss: 0.4983 val r: 0.7465; time: 0.94sec
[728/800][24/24] total train loss: 0.0082; total val loss: 0.4857 val r: 0.7448; time: 0.94sec
[729/800][24/24] total train loss: 0.0084; total val loss: 0.4920 val r: 0.7457; time: 0.95sec
[730/800][24/24] total train loss: 0.0086; total val loss: 0.4878 val r: 0.7482; time: 0.94sec
[731/800][24/24] total train loss: 0.0083; total val loss: 0.5056 val r: 0.7454; time: 0.94sec
[732/800][24/24] total train loss: 0.0083; total val loss: 0.4869 val r: 0.7432; time: 0.94sec
[733/800][24/24] total train loss: 0.0082; total val loss: 0.5000 val r: 0.7435; time: 0.94sec
[734/800][24/24] total train loss: 0.0086; total val loss: 0.5071 val r: 0.7420; time: 0.96sec
[735/800][24/24] total train loss: 0.0080; total val loss: 0.4953 val r: 0.7416; time: 0.94sec
[736/800][24/24] total train loss: 0.0084; total val loss: 0.4984 val r: 0.7437; time: 0.94sec
[737/800][24/24] total train loss: 0.0083; total val loss: 0.4964 val r: 0.7464; time: 0.94sec
[738/800][24/24] total train loss: 0.0085; total val loss: 0.4711 val r: 0.7424; time: 0.95sec
[739/800][24/24] total train loss: 0.0083; total val loss: 0.4901 val r: 0.7392; time: 0.94sec
[740/800][24/24] total train loss: 0.0083; total val loss: 0.4993 val r: 0.7398; time: 0.94sec
[741/800][24/24] total train loss: 0.0082; total val loss: 0.4991 val r: 0.7421; time: 0.94sec
[742/800][24/24] total train loss: 0.0085; total val loss: 0.4897 val r: 0.7425; time: 0.94sec
[743/800][24/24] total train loss: 0.0086; total val loss: 0.5035 val r: 0.7488; time: 0.93sec
[744/800][24/24] total train loss: 0.0082; total val loss: 0.4848 val r: 0.7459; time: 0.94sec
[745/800][24/24] total train loss: 0.0085; total val loss: 0.4868 val r: 0.7407; time: 0.94sec
[746/800][24/24] total train loss: 0.0084; total val loss: 0.4974 val r: 0.7417; time: 0.95sec
[747/800][24/24] total train loss: 0.0085; total val loss: 0.4932 val r: 0.7425; time: 0.95sec
[748/800][24/24] total train loss: 0.0083; total val loss: 0.5123 val r: 0.7434; time: 0.94sec
[749/800][24/24] total train loss: 0.0087; total val loss: 0.4849 val r: 0.7416; time: 0.95sec
[750/800][24/24] total train loss: 0.0083; total val loss: 0.4907 val r: 0.7432; time: 0.95sec
[751/800][24/24] total train loss: 0.0082; total val loss: 0.4859 val r: 0.7419; time: 0.94sec
[752/800][24/24] total train loss: 0.0086; total val loss: 0.5120 val r: 0.7462; time: 0.95sec
[753/800][24/24] total train loss: 0.0086; total val loss: 0.4974 val r: 0.7435; time: 0.95sec
[754/800][24/24] total train loss: 0.0083; total val loss: 0.4842 val r: 0.7401; time: 0.95sec
[755/800][24/24] total train loss: 0.0084; total val loss: 0.4868 val r: 0.7409; time: 0.95sec
[756/800][24/24] total train loss: 0.0081; total val loss: 0.5013 val r: 0.7438; time: 0.95sec
[757/800][24/24] total train loss: 0.0086; total val loss: 0.4987 val r: 0.7462; time: 0.94sec
[758/800][24/24] total train loss: 0.0083; total val loss: 0.4886 val r: 0.7417; time: 0.95sec
[759/800][24/24] total train loss: 0.0082; total val loss: 0.4825 val r: 0.7385; time: 0.95sec
[760/800][24/24] total train loss: 0.0085; total val loss: 0.5040 val r: 0.7382; time: 0.95sec
[761/800][24/24] total train loss: 0.0083; total val loss: 0.4947 val r: 0.7411; time: 0.95sec
[762/800][24/24] total train loss: 0.0083; total val loss: 0.4840 val r: 0.7454; time: 0.96sec
[763/800][24/24] total train loss: 0.0081; total val loss: 0.5017 val r: 0.7411; time: 0.96sec
[764/800][24/24] total train loss: 0.0082; total val loss: 0.5060 val r: 0.7380; time: 0.95sec
[765/800][24/24] total train loss: 0.0085; total val loss: 0.4903 val r: 0.7408; time: 0.95sec
[766/800][24/24] total train loss: 0.0086; total val loss: 0.5074 val r: 0.7426; time: 0.95sec
[767/800][24/24] total train loss: 0.0084; total val loss: 0.4698 val r: 0.7417; time: 0.94sec
[768/800][24/24] total train loss: 0.0084; total val loss: 0.4897 val r: 0.7436; time: 0.94sec
[769/800][24/24] total train loss: 0.0083; total val loss: 0.5023 val r: 0.7443; time: 0.94sec
[770/800][24/24] total train loss: 0.0085; total val loss: 0.5049 val r: 0.7412; time: 0.94sec
[771/800][24/24] total train loss: 0.0082; total val loss: 0.4935 val r: 0.7406; time: 0.95sec
[772/800][24/24] total train loss: 0.0080; total val loss: 0.4915 val r: 0.7445; time: 0.96sec
[773/800][24/24] total train loss: 0.0083; total val loss: 0.5121 val r: 0.7394; time: 0.95sec
[774/800][24/24] total train loss: 0.0085; total val loss: 0.4736 val r: 0.7423; time: 0.95sec
[775/800][24/24] total train loss: 0.0085; total val loss: 0.4930 val r: 0.7438; time: 0.96sec
[776/800][24/24] total train loss: 0.0083; total val loss: 0.5000 val r: 0.7397; time: 0.96sec
[777/800][24/24] total train loss: 0.0082; total val loss: 0.5013 val r: 0.7422; time: 0.95sec
[778/800][24/24] total train loss: 0.0082; total val loss: 0.5066 val r: 0.7382; time: 0.95sec
[779/800][24/24] total train loss: 0.0085; total val loss: 0.5048 val r: 0.7450; time: 0.94sec
[780/800][24/24] total train loss: 0.0085; total val loss: 0.4654 val r: 0.7415; time: 0.95sec
[781/800][24/24] total train loss: 0.0085; total val loss: 0.4880 val r: 0.7422; time: 0.96sec
[782/800][24/24] total train loss: 0.0087; total val loss: 0.4941 val r: 0.7374; time: 0.95sec
[783/800][24/24] total train loss: 0.0085; total val loss: 0.5078 val r: 0.7422; time: 0.95sec
[784/800][24/24] total train loss: 0.0083; total val loss: 0.5008 val r: 0.7476; time: 0.94sec
[785/800][24/24] total train loss: 0.0083; total val loss: 0.4766 val r: 0.7436; time: 0.93sec
[786/800][24/24] total train loss: 0.0081; total val loss: 0.4968 val r: 0.7405; time: 0.94sec
[787/800][24/24] total train loss: 0.0086; total val loss: 0.4996 val r: 0.7419; time: 0.94sec
[788/800][24/24] total train loss: 0.0083; total val loss: 0.4706 val r: 0.7425; time: 0.94sec
[789/800][24/24] total train loss: 0.0083; total val loss: 0.5144 val r: 0.7403; time: 0.94sec
[790/800][24/24] total train loss: 0.0086; total val loss: 0.4842 val r: 0.7450; time: 0.95sec
[791/800][24/24] total train loss: 0.0082; total val loss: 0.4760 val r: 0.7475; time: 0.94sec
[792/800][24/24] total train loss: 0.0085; total val loss: 0.5082 val r: 0.7436; time: 0.94sec
[793/800][24/24] total train loss: 0.0082; total val loss: 0.5036 val r: 0.7486; time: 0.94sec
[794/800][24/24] total train loss: 0.0082; total val loss: 0.4985 val r: 0.7411; time: 0.94sec
[795/800][24/24] total train loss: 0.0081; total val loss: 0.4926 val r: 0.7441; time: 0.94sec
[796/800][24/24] total train loss: 0.0084; total val loss: 0.5098 val r: 0.7449; time: 0.94sec
[797/800][24/24] total train loss: 0.0085; total val loss: 0.4960 val r: 0.7407; time: 0.94sec
[798/800][24/24] total train loss: 0.0083; total val loss: 0.4899 val r: 0.7437; time: 0.94sec
[799/800][24/24] total train loss: 0.0081; total val loss: 0.5132 val r: 0.7442; time: 0.94sec
learning rate updated: 0.001
[800/800][24/24] total train loss: 0.0082; total val loss: 0.4868 val r: 0.7415; time: 0.95sec
Best epoch 2 with val_r = 0.7789.
Fold #2
- - - - - - - - - - - - -
initializing neural net
[1/800][24/24] total train loss: 1.1950; total val loss: 0.4548 val r: 0.6747; time: 0.97sec
[2/800][24/24] total train loss: 0.6358; total val loss: 0.3493 val r: 0.7156; time: 0.94sec
[3/800][24/24] total train loss: 0.4507; total val loss: 0.5340 val r: 0.7520; time: 0.95sec
[4/800][24/24] total train loss: 0.2978; total val loss: 0.5031 val r: 0.7636; time: 0.94sec
[5/800][24/24] total train loss: 0.2003; total val loss: 0.4169 val r: 0.7177; time: 0.94sec
[6/800][24/24] total train loss: 0.1360; total val loss: 0.4988 val r: 0.7572; time: 0.95sec
[7/800][24/24] total train loss: 0.1191; total val loss: 0.4585 val r: 0.7609; time: 0.94sec
[8/800][24/24] total train loss: 0.0794; total val loss: 0.4546 val r: 0.7482; time: 0.94sec
[9/800][24/24] total train loss: 0.0524; total val loss: 0.4509 val r: 0.7489; time: 0.93sec
[10/800][24/24] total train loss: 0.0448; total val loss: 0.4684 val r: 0.7581; time: 0.94sec
[11/800][24/24] total train loss: 0.0355; total val loss: 0.4569 val r: 0.7530; time: 0.94sec
[12/800][24/24] total train loss: 0.0296; total val loss: 0.4264 val r: 0.7561; time: 0.94sec
[13/800][24/24] total train loss: 0.0243; total val loss: 0.4915 val r: 0.7598; time: 0.94sec
[14/800][24/24] total train loss: 0.0240; total val loss: 0.4784 val r: 0.7539; time: 0.95sec
[15/800][24/24] total train loss: 0.0232; total val loss: 0.4340 val r: 0.7640; time: 0.94sec
[16/800][24/24] total train loss: 0.0211; total val loss: 0.4386 val r: 0.7682; time: 0.94sec
[17/800][24/24] total train loss: 0.0216; total val loss: 0.4361 val r: 0.7556; time: 0.94sec
[18/800][24/24] total train loss: 0.0200; total val loss: 0.4423 val r: 0.7578; time: 0.94sec
[19/800][24/24] total train loss: 0.0196; total val loss: 0.4565 val r: 0.7676; time: 0.93sec
[20/800][24/24] total train loss: 0.0192; total val loss: 0.4598 val r: 0.7633; time: 0.94sec
[21/800][24/24] total train loss: 0.0232; total val loss: 0.4476 val r: 0.7542; time: 0.93sec
[22/800][24/24] total train loss: 0.0230; total val loss: 0.4327 val r: 0.7681; time: 0.94sec
[23/800][24/24] total train loss: 0.0198; total val loss: 0.4474 val r: 0.7683; time: 0.94sec
[24/800][24/24] total train loss: 0.0161; total val loss: 0.4419 val r: 0.7709; time: 0.94sec
[25/800][24/24] total train loss: 0.0149; total val loss: 0.4626 val r: 0.7606; time: 0.94sec
[26/800][24/24] total train loss: 0.0158; total val loss: 0.4556 val r: 0.7689; time: 0.94sec
[27/800][24/24] total train loss: 0.0155; total val loss: 0.4463 val r: 0.7654; time: 0.95sec
[28/800][24/24] total train loss: 0.0132; total val loss: 0.4663 val r: 0.7673; time: 0.94sec
[29/800][24/24] total train loss: 0.0145; total val loss: 0.4356 val r: 0.7648; time: 0.94sec
[30/800][24/24] total train loss: 0.0137; total val loss: 0.4521 val r: 0.7699; time: 0.94sec
[31/800][24/24] total train loss: 0.0127; total val loss: 0.4674 val r: 0.7661; time: 0.93sec
[32/800][24/24] total train loss: 0.0130; total val loss: 0.4458 val r: 0.7664; time: 0.95sec
[33/800][24/24] total train loss: 0.0140; total val loss: 0.4702 val r: 0.7742; time: 0.94sec
[34/800][24/24] total train loss: 0.0134; total val loss: 0.4927 val r: 0.7693; time: 0.94sec
[35/800][24/24] total train loss: 0.0178; total val loss: 0.4642 val r: 0.7716; time: 0.93sec
[36/800][24/24] total train loss: 0.0187; total val loss: 0.4740 val r: 0.7744; time: 0.94sec
[37/800][24/24] total train loss: 0.0163; total val loss: 0.4729 val r: 0.7627; time: 0.93sec
[38/800][24/24] total train loss: 0.0138; total val loss: 0.4516 val r: 0.7662; time: 0.93sec
[39/800][24/24] total train loss: 0.0135; total val loss: 0.4397 val r: 0.7627; time: 0.94sec
[40/800][24/24] total train loss: 0.0139; total val loss: 0.4489 val r: 0.7647; time: 0.93sec
[41/800][24/24] total train loss: 0.0144; total val loss: 0.4587 val r: 0.7616; time: 0.94sec
[42/800][24/24] total train loss: 0.0148; total val loss: 0.4588 val r: 0.7650; time: 0.93sec
[43/800][24/24] total train loss: 0.0142; total val loss: 0.4479 val r: 0.7688; time: 0.94sec
[44/800][24/24] total train loss: 0.0129; total val loss: 0.4605 val r: 0.7709; time: 0.93sec
[45/800][24/24] total train loss: 0.0117; total val loss: 0.4759 val r: 0.7693; time: 0.93sec
[46/800][24/24] total train loss: 0.0115; total val loss: 0.4625 val r: 0.7680; time: 0.93sec
[47/800][24/24] total train loss: 0.0117; total val loss: 0.4631 val r: 0.7695; time: 0.94sec
[48/800][24/24] total train loss: 0.0122; total val loss: 0.4510 val r: 0.7690; time: 0.94sec
[49/800][24/24] total train loss: 0.0123; total val loss: 0.4462 val r: 0.7696; time: 0.94sec
[50/800][24/24] total train loss: 0.0143; total val loss: 0.4618 val r: 0.7696; time: 0.94sec
[51/800][24/24] total train loss: 0.0148; total val loss: 0.4618 val r: 0.7682; time: 0.94sec
[52/800][24/24] total train loss: 0.0146; total val loss: 0.4533 val r: 0.7724; time: 0.94sec
[53/800][24/24] total train loss: 0.0145; total val loss: 0.4554 val r: 0.7642; time: 0.94sec
[54/800][24/24] total train loss: 0.0124; total val loss: 0.4662 val r: 0.7687; time: 0.94sec
[55/800][24/24] total train loss: 0.0126; total val loss: 0.4515 val r: 0.7664; time: 0.93sec
[56/800][24/24] total train loss: 0.0135; total val loss: 0.4597 val r: 0.7674; time: 0.94sec
[57/800][24/24] total train loss: 0.0146; total val loss: 0.4713 val r: 0.7692; time: 0.93sec
[58/800][24/24] total train loss: 0.0131; total val loss: 0.4533 val r: 0.7716; time: 0.94sec
[59/800][24/24] total train loss: 0.0127; total val loss: 0.4520 val r: 0.7659; time: 0.94sec
[60/800][24/24] total train loss: 0.0127; total val loss: 0.4521 val r: 0.7657; time: 0.93sec
[61/800][24/24] total train loss: 0.0144; total val loss: 0.4699 val r: 0.7723; time: 0.94sec
[62/800][24/24] total train loss: 0.0143; total val loss: 0.4595 val r: 0.7672; time: 0.93sec
[63/800][24/24] total train loss: 0.0134; total val loss: 0.4687 val r: 0.7760; time: 0.94sec
[64/800][24/24] total train loss: 0.0135; total val loss: 0.4511 val r: 0.7693; time: 0.93sec
[65/800][24/24] total train loss: 0.0130; total val loss: 0.4562 val r: 0.7766; time: 0.93sec
[66/800][24/24] total train loss: 0.0152; total val loss: 0.4597 val r: 0.7736; time: 0.94sec
[67/800][24/24] total train loss: 0.0132; total val loss: 0.4673 val r: 0.7688; time: 0.93sec
[68/800][24/24] total train loss: 0.0119; total val loss: 0.4417 val r: 0.7628; time: 0.94sec
[69/800][24/24] total train loss: 0.0108; total val loss: 0.4470 val r: 0.7748; time: 0.93sec
[70/800][24/24] total train loss: 0.0114; total val loss: 0.4506 val r: 0.7723; time: 0.94sec
[71/800][24/24] total train loss: 0.0119; total val loss: 0.4365 val r: 0.7695; time: 0.93sec
[72/800][24/24] total train loss: 0.0117; total val loss: 0.4540 val r: 0.7660; time: 0.94sec
[73/800][24/24] total train loss: 0.0108; total val loss: 0.4379 val r: 0.7695; time: 0.94sec
[74/800][24/24] total train loss: 0.0107; total val loss: 0.4494 val r: 0.7709; time: 0.93sec
[75/800][24/24] total train loss: 0.0111; total val loss: 0.4596 val r: 0.7709; time: 0.95sec
[76/800][24/24] total train loss: 0.0110; total val loss: 0.4576 val r: 0.7683; time: 0.94sec
[77/800][24/24] total train loss: 0.0130; total val loss: 0.4459 val r: 0.7672; time: 0.93sec
[78/800][24/24] total train loss: 0.0122; total val loss: 0.4507 val r: 0.7728; time: 0.93sec
[79/800][24/24] total train loss: 0.0118; total val loss: 0.4522 val r: 0.7717; time: 0.94sec
[80/800][24/24] total train loss: 0.0112; total val loss: 0.4496 val r: 0.7753; time: 0.94sec
[81/800][24/24] total train loss: 0.0116; total val loss: 0.4490 val r: 0.7676; time: 0.94sec
[82/800][24/24] total train loss: 0.0118; total val loss: 0.4490 val r: 0.7716; time: 0.93sec
[83/800][24/24] total train loss: 0.0104; total val loss: 0.4586 val r: 0.7712; time: 0.93sec
[84/800][24/24] total train loss: 0.0109; total val loss: 0.4627 val r: 0.7745; time: 0.94sec
[85/800][24/24] total train loss: 0.0108; total val loss: 0.4612 val r: 0.7678; time: 0.95sec
[86/800][24/24] total train loss: 0.0117; total val loss: 0.4404 val r: 0.7724; time: 0.93sec
[87/800][24/24] total train loss: 0.0118; total val loss: 0.4511 val r: 0.7687; time: 0.94sec
[88/800][24/24] total train loss: 0.0109; total val loss: 0.4655 val r: 0.7743; time: 0.94sec
[89/800][24/24] total train loss: 0.0122; total val loss: 0.4593 val r: 0.7732; time: 0.95sec
[90/800][24/24] total train loss: 0.0106; total val loss: 0.4510 val r: 0.7733; time: 0.94sec
[91/800][24/24] total train loss: 0.0103; total val loss: 0.4371 val r: 0.7744; time: 0.94sec
[92/800][24/24] total train loss: 0.0103; total val loss: 0.4475 val r: 0.7709; time: 0.94sec
[93/800][24/24] total train loss: 0.0105; total val loss: 0.4790 val r: 0.7779; time: 0.93sec
[94/800][24/24] total train loss: 0.0112; total val loss: 0.4319 val r: 0.7673; time: 0.93sec
[95/800][24/24] total train loss: 0.0110; total val loss: 0.4582 val r: 0.7783; time: 0.93sec
[96/800][24/24] total train loss: 0.0103; total val loss: 0.4635 val r: 0.7690; time: 0.93sec
[97/800][24/24] total train loss: 0.0104; total val loss: 0.4627 val r: 0.7720; time: 0.94sec
[98/800][24/24] total train loss: 0.0101; total val loss: 0.4438 val r: 0.7725; time: 0.93sec
[99/800][24/24] total train loss: 0.0107; total val loss: 0.4475 val r: 0.7732; time: 0.94sec
learning rate updated: 0.001
[100/800][24/24] total train loss: 0.0102; total val loss: 0.4494 val r: 0.7742; time: 0.95sec
[101/800][24/24] total train loss: 0.0104; total val loss: 0.4539 val r: 0.7699; time: 0.94sec
[102/800][24/24] total train loss: 0.0103; total val loss: 0.4571 val r: 0.7694; time: 0.95sec
[103/800][24/24] total train loss: 0.0117; total val loss: 0.4612 val r: 0.7758; time: 0.95sec
[104/800][24/24] total train loss: 0.0113; total val loss: 0.4419 val r: 0.7721; time: 0.95sec
[105/800][24/24] total train loss: 0.0107; total val loss: 0.4543 val r: 0.7716; time: 0.94sec
[106/800][24/24] total train loss: 0.0099; total val loss: 0.4552 val r: 0.7729; time: 0.94sec
[107/800][24/24] total train loss: 0.0102; total val loss: 0.4628 val r: 0.7745; time: 0.94sec
[108/800][24/24] total train loss: 0.0101; total val loss: 0.4502 val r: 0.7736; time: 0.94sec
[109/800][24/24] total train loss: 0.0104; total val loss: 0.4545 val r: 0.7701; time: 0.94sec
[110/800][24/24] total train loss: 0.0098; total val loss: 0.4433 val r: 0.7718; time: 0.95sec
[111/800][24/24] total train loss: 0.0100; total val loss: 0.4605 val r: 0.7775; time: 0.94sec
[112/800][24/24] total train loss: 0.0103; total val loss: 0.4562 val r: 0.7751; time: 0.94sec
[113/800][24/24] total train loss: 0.0122; total val loss: 0.4460 val r: 0.7686; time: 0.95sec
[114/800][24/24] total train loss: 0.0116; total val loss: 0.4480 val r: 0.7730; time: 0.94sec
[115/800][24/24] total train loss: 0.0103; total val loss: 0.4546 val r: 0.7743; time: 0.94sec
[116/800][24/24] total train loss: 0.0096; total val loss: 0.4630 val r: 0.7756; time: 0.94sec
[117/800][24/24] total train loss: 0.0100; total val loss: 0.4566 val r: 0.7761; time: 0.94sec
[118/800][24/24] total train loss: 0.0104; total val loss: 0.4530 val r: 0.7686; time: 0.95sec
[119/800][24/24] total train loss: 0.0104; total val loss: 0.4499 val r: 0.7737; time: 0.93sec
[120/800][24/24] total train loss: 0.0102; total val loss: 0.4588 val r: 0.7801; time: 0.94sec
[121/800][24/24] total train loss: 0.0109; total val loss: 0.4520 val r: 0.7729; time: 0.94sec
[122/800][24/24] total train loss: 0.0110; total val loss: 0.4595 val r: 0.7797; time: 0.94sec
[123/800][24/24] total train loss: 0.0119; total val loss: 0.4584 val r: 0.7770; time: 0.95sec
[124/800][24/24] total train loss: 0.0115; total val loss: 0.4630 val r: 0.7717; time: 0.94sec
[125/800][24/24] total train loss: 0.0110; total val loss: 0.4574 val r: 0.7743; time: 0.93sec
[126/800][24/24] total train loss: 0.0121; total val loss: 0.4425 val r: 0.7706; time: 0.94sec
[127/800][24/24] total train loss: 0.0123; total val loss: 0.4473 val r: 0.7718; time: 0.94sec
[128/800][24/24] total train loss: 0.0112; total val loss: 0.4665 val r: 0.7773; time: 0.94sec
[129/800][24/24] total train loss: 0.0108; total val loss: 0.4423 val r: 0.7709; time: 0.94sec
[130/800][24/24] total train loss: 0.0106; total val loss: 0.4608 val r: 0.7779; time: 0.95sec
[131/800][24/24] total train loss: 0.0102; total val loss: 0.4554 val r: 0.7725; time: 0.95sec
[132/800][24/24] total train loss: 0.0099; total val loss: 0.4579 val r: 0.7785; time: 0.93sec
[133/800][24/24] total train loss: 0.0105; total val loss: 0.4575 val r: 0.7745; time: 0.94sec
[134/800][24/24] total train loss: 0.0099; total val loss: 0.4409 val r: 0.7777; time: 0.94sec
[135/800][24/24] total train loss: 0.0099; total val loss: 0.4571 val r: 0.7784; time: 0.93sec
[136/800][24/24] total train loss: 0.0101; total val loss: 0.4660 val r: 0.7822; time: 0.94sec
[137/800][24/24] total train loss: 0.0107; total val loss: 0.4584 val r: 0.7813; time: 0.94sec
[138/800][24/24] total train loss: 0.0098; total val loss: 0.4464 val r: 0.7772; time: 0.94sec
[139/800][24/24] total train loss: 0.0095; total val loss: 0.4458 val r: 0.7766; time: 0.93sec
[140/800][24/24] total train loss: 0.0093; total val loss: 0.4575 val r: 0.7741; time: 0.93sec
[141/800][24/24] total train loss: 0.0095; total val loss: 0.4609 val r: 0.7764; time: 0.94sec
[142/800][24/24] total train loss: 0.0093; total val loss: 0.4550 val r: 0.7717; time: 0.94sec
[143/800][24/24] total train loss: 0.0094; total val loss: 0.4497 val r: 0.7747; time: 0.94sec
[144/800][24/24] total train loss: 0.0103; total val loss: 0.4437 val r: 0.7754; time: 0.94sec
[145/800][24/24] total train loss: 0.0110; total val loss: 0.4615 val r: 0.7778; time: 0.94sec
[146/800][24/24] total train loss: 0.0107; total val loss: 0.4244 val r: 0.7669; time: 0.94sec
[147/800][24/24] total train loss: 0.0111; total val loss: 0.4393 val r: 0.7784; time: 0.94sec
[148/800][24/24] total train loss: 0.0111; total val loss: 0.4320 val r: 0.7757; time: 0.94sec
[149/800][24/24] total train loss: 0.0108; total val loss: 0.4549 val r: 0.7727; time: 0.94sec
[150/800][24/24] total train loss: 0.0097; total val loss: 0.4482 val r: 0.7758; time: 0.94sec
[151/800][24/24] total train loss: 0.0094; total val loss: 0.4506 val r: 0.7805; time: 0.94sec
[152/800][24/24] total train loss: 0.0102; total val loss: 0.4542 val r: 0.7745; time: 0.93sec
[153/800][24/24] total train loss: 0.0103; total val loss: 0.4383 val r: 0.7793; time: 0.95sec
[154/800][24/24] total train loss: 0.0093; total val loss: 0.4581 val r: 0.7798; time: 0.94sec
[155/800][24/24] total train loss: 0.0095; total val loss: 0.4478 val r: 0.7749; time: 0.94sec
[156/800][24/24] total train loss: 0.0092; total val loss: 0.4494 val r: 0.7745; time: 0.94sec
[157/800][24/24] total train loss: 0.0100; total val loss: 0.4529 val r: 0.7732; time: 0.94sec
[158/800][24/24] total train loss: 0.0093; total val loss: 0.4617 val r: 0.7812; time: 0.94sec
[159/800][24/24] total train loss: 0.0098; total val loss: 0.4532 val r: 0.7757; time: 0.94sec
[160/800][24/24] total train loss: 0.0100; total val loss: 0.4449 val r: 0.7780; time: 0.94sec
[161/800][24/24] total train loss: 0.0098; total val loss: 0.4495 val r: 0.7728; time: 0.94sec
[162/800][24/24] total train loss: 0.0092; total val loss: 0.4535 val r: 0.7781; time: 0.93sec
[163/800][24/24] total train loss: 0.0096; total val loss: 0.4330 val r: 0.7746; time: 0.94sec
[164/800][24/24] total train loss: 0.0102; total val loss: 0.4595 val r: 0.7722; time: 0.94sec
[165/800][24/24] total train loss: 0.0099; total val loss: 0.4661 val r: 0.7790; time: 0.94sec
[166/800][24/24] total train loss: 0.0095; total val loss: 0.4432 val r: 0.7751; time: 0.94sec
[167/800][24/24] total train loss: 0.0097; total val loss: 0.4497 val r: 0.7746; time: 0.94sec
[168/800][24/24] total train loss: 0.0093; total val loss: 0.4389 val r: 0.7724; time: 0.94sec
[169/800][24/24] total train loss: 0.0093; total val loss: 0.4685 val r: 0.7801; time: 0.94sec
[170/800][24/24] total train loss: 0.0098; total val loss: 0.4547 val r: 0.7816; time: 0.94sec
[171/800][24/24] total train loss: 0.0099; total val loss: 0.4396 val r: 0.7745; time: 0.94sec
[172/800][24/24] total train loss: 0.0099; total val loss: 0.4435 val r: 0.7668; time: 0.94sec
[173/800][24/24] total train loss: 0.0097; total val loss: 0.4600 val r: 0.7823; time: 0.95sec
[174/800][24/24] total train loss: 0.0099; total val loss: 0.4582 val r: 0.7799; time: 0.95sec
[175/800][24/24] total train loss: 0.0097; total val loss: 0.4503 val r: 0.7708; time: 0.93sec
[176/800][24/24] total train loss: 0.0100; total val loss: 0.4342 val r: 0.7716; time: 0.94sec
[177/800][24/24] total train loss: 0.0100; total val loss: 0.4285 val r: 0.7767; time: 0.94sec
[178/800][24/24] total train loss: 0.0099; total val loss: 0.4497 val r: 0.7798; time: 0.94sec
[179/800][24/24] total train loss: 0.0101; total val loss: 0.4453 val r: 0.7752; time: 0.94sec
[180/800][24/24] total train loss: 0.0100; total val loss: 0.4385 val r: 0.7740; time: 0.94sec
[181/800][24/24] total train loss: 0.0097; total val loss: 0.4450 val r: 0.7803; time: 0.94sec
[182/800][24/24] total train loss: 0.0093; total val loss: 0.4508 val r: 0.7754; time: 0.94sec
[183/800][24/24] total train loss: 0.0089; total val loss: 0.4565 val r: 0.7794; time: 0.94sec
[184/800][24/24] total train loss: 0.0090; total val loss: 0.4456 val r: 0.7786; time: 0.95sec
[185/800][24/24] total train loss: 0.0091; total val loss: 0.4631 val r: 0.7809; time: 0.94sec
[186/800][24/24] total train loss: 0.0092; total val loss: 0.4525 val r: 0.7752; time: 0.94sec
[187/800][24/24] total train loss: 0.0089; total val loss: 0.4642 val r: 0.7795; time: 0.94sec
[188/800][24/24] total train loss: 0.0086; total val loss: 0.4327 val r: 0.7775; time: 0.94sec
[189/800][24/24] total train loss: 0.0085; total val loss: 0.4440 val r: 0.7792; time: 0.94sec
[190/800][24/24] total train loss: 0.0085; total val loss: 0.4467 val r: 0.7790; time: 0.94sec
[191/800][24/24] total train loss: 0.0090; total val loss: 0.4651 val r: 0.7758; time: 0.94sec
[192/800][24/24] total train loss: 0.0097; total val loss: 0.4624 val r: 0.7812; time: 0.93sec
[193/800][24/24] total train loss: 0.0095; total val loss: 0.4499 val r: 0.7812; time: 0.94sec
[194/800][24/24] total train loss: 0.0093; total val loss: 0.4533 val r: 0.7774; time: 0.93sec
[195/800][24/24] total train loss: 0.0094; total val loss: 0.4572 val r: 0.7800; time: 0.93sec
[196/800][24/24] total train loss: 0.0098; total val loss: 0.4505 val r: 0.7802; time: 0.94sec
[197/800][24/24] total train loss: 0.0102; total val loss: 0.4604 val r: 0.7833; time: 0.94sec
[198/800][24/24] total train loss: 0.0094; total val loss: 0.4535 val r: 0.7784; time: 0.93sec
[199/800][24/24] total train loss: 0.0092; total val loss: 0.4526 val r: 0.7775; time: 0.94sec
learning rate updated: 0.001
[200/800][24/24] total train loss: 0.0094; total val loss: 0.4533 val r: 0.7802; time: 0.94sec
[201/800][24/24] total train loss: 0.0088; total val loss: 0.4547 val r: 0.7765; time: 0.95sec
[202/800][24/24] total train loss: 0.0091; total val loss: 0.4695 val r: 0.7804; time: 0.95sec
[203/800][24/24] total train loss: 0.0091; total val loss: 0.4555 val r: 0.7794; time: 0.94sec
[204/800][24/24] total train loss: 0.0089; total val loss: 0.4526 val r: 0.7768; time: 0.94sec
[205/800][24/24] total train loss: 0.0093; total val loss: 0.4697 val r: 0.7786; time: 0.95sec
[206/800][24/24] total train loss: 0.0092; total val loss: 0.4557 val r: 0.7784; time: 0.94sec
[207/800][24/24] total train loss: 0.0088; total val loss: 0.4508 val r: 0.7765; time: 0.94sec
[208/800][24/24] total train loss: 0.0087; total val loss: 0.4513 val r: 0.7791; time: 0.94sec
[209/800][24/24] total train loss: 0.0090; total val loss: 0.4486 val r: 0.7828; time: 0.95sec
[210/800][24/24] total train loss: 0.0093; total val loss: 0.4487 val r: 0.7772; time: 0.95sec
[211/800][24/24] total train loss: 0.0093; total val loss: 0.4505 val r: 0.7767; time: 0.94sec
[212/800][24/24] total train loss: 0.0090; total val loss: 0.4603 val r: 0.7811; time: 0.94sec
[213/800][24/24] total train loss: 0.0086; total val loss: 0.4423 val r: 0.7713; time: 0.94sec
[214/800][24/24] total train loss: 0.0088; total val loss: 0.4362 val r: 0.7795; time: 0.95sec
[215/800][24/24] total train loss: 0.0084; total val loss: 0.4569 val r: 0.7832; time: 0.94sec
[216/800][24/24] total train loss: 0.0085; total val loss: 0.4646 val r: 0.7839; time: 1.06sec
[217/800][24/24] total train loss: 0.0087; total val loss: 0.4468 val r: 0.7808; time: 0.94sec
[218/800][24/24] total train loss: 0.0095; total val loss: 0.4472 val r: 0.7797; time: 0.94sec
[219/800][24/24] total train loss: 0.0090; total val loss: 0.4463 val r: 0.7740; time: 0.94sec
[220/800][24/24] total train loss: 0.0083; total val loss: 0.4665 val r: 0.7795; time: 0.94sec
[221/800][24/24] total train loss: 0.0087; total val loss: 0.4460 val r: 0.7766; time: 0.95sec
[222/800][24/24] total train loss: 0.0092; total val loss: 0.4692 val r: 0.7851; time: 0.94sec
[223/800][24/24] total train loss: 0.0094; total val loss: 0.4486 val r: 0.7755; time: 0.94sec
[224/800][24/24] total train loss: 0.0091; total val loss: 0.4429 val r: 0.7793; time: 0.94sec
[225/800][24/24] total train loss: 0.0083; total val loss: 0.4420 val r: 0.7740; time: 0.94sec
[226/800][24/24] total train loss: 0.0086; total val loss: 0.4620 val r: 0.7820; time: 0.95sec
[227/800][24/24] total train loss: 0.0098; total val loss: 0.4767 val r: 0.7862; time: 0.95sec
[228/800][24/24] total train loss: 0.0101; total val loss: 0.4580 val r: 0.7764; time: 0.94sec
[229/800][24/24] total train loss: 0.0100; total val loss: 0.4372 val r: 0.7819; time: 0.94sec
[230/800][24/24] total train loss: 0.0104; total val loss: 0.4421 val r: 0.7786; time: 0.94sec
[231/800][24/24] total train loss: 0.0103; total val loss: 0.4486 val r: 0.7768; time: 0.94sec
[232/800][24/24] total train loss: 0.0093; total val loss: 0.4510 val r: 0.7794; time: 0.95sec
[233/800][24/24] total train loss: 0.0094; total val loss: 0.4654 val r: 0.7813; time: 0.94sec
[234/800][24/24] total train loss: 0.0095; total val loss: 0.4562 val r: 0.7752; time: 0.95sec
[235/800][24/24] total train loss: 0.0091; total val loss: 0.4480 val r: 0.7804; time: 0.95sec
[236/800][24/24] total train loss: 0.0094; total val loss: 0.4588 val r: 0.7773; time: 0.95sec
[237/800][24/24] total train loss: 0.0094; total val loss: 0.4463 val r: 0.7733; time: 0.95sec
[238/800][24/24] total train loss: 0.0094; total val loss: 0.4575 val r: 0.7744; time: 0.94sec
[239/800][24/24] total train loss: 0.0088; total val loss: 0.4629 val r: 0.7782; time: 0.95sec
[240/800][24/24] total train loss: 0.0090; total val loss: 0.4444 val r: 0.7780; time: 0.95sec
[241/800][24/24] total train loss: 0.0089; total val loss: 0.4460 val r: 0.7752; time: 0.95sec
[242/800][24/24] total train loss: 0.0087; total val loss: 0.4517 val r: 0.7815; time: 0.94sec
[243/800][24/24] total train loss: 0.0088; total val loss: 0.4530 val r: 0.7760; time: 0.95sec
[244/800][24/24] total train loss: 0.0087; total val loss: 0.4535 val r: 0.7765; time: 0.94sec
[245/800][24/24] total train loss: 0.0086; total val loss: 0.4559 val r: 0.7784; time: 0.94sec
[246/800][24/24] total train loss: 0.0087; total val loss: 0.4384 val r: 0.7819; time: 0.95sec
[247/800][24/24] total train loss: 0.0083; total val loss: 0.4581 val r: 0.7755; time: 0.94sec
[248/800][24/24] total train loss: 0.0085; total val loss: 0.4450 val r: 0.7744; time: 0.95sec
[249/800][24/24] total train loss: 0.0083; total val loss: 0.4571 val r: 0.7791; time: 0.95sec
[250/800][24/24] total train loss: 0.0086; total val loss: 0.4446 val r: 0.7803; time: 0.94sec
[251/800][24/24] total train loss: 0.0087; total val loss: 0.4469 val r: 0.7737; time: 0.94sec
[252/800][24/24] total train loss: 0.0091; total val loss: 0.4508 val r: 0.7800; time: 0.95sec
[253/800][24/24] total train loss: 0.0087; total val loss: 0.4628 val r: 0.7827; time: 0.94sec
[254/800][24/24] total train loss: 0.0084; total val loss: 0.4482 val r: 0.7765; time: 0.94sec
[255/800][24/24] total train loss: 0.0088; total val loss: 0.4620 val r: 0.7818; time: 0.94sec
[256/800][24/24] total train loss: 0.0085; total val loss: 0.4558 val r: 0.7811; time: 0.94sec
[257/800][24/24] total train loss: 0.0085; total val loss: 0.4526 val r: 0.7759; time: 0.95sec
[258/800][24/24] total train loss: 0.0082; total val loss: 0.4508 val r: 0.7799; time: 0.94sec
[259/800][24/24] total train loss: 0.0085; total val loss: 0.4500 val r: 0.7804; time: 0.94sec
[260/800][24/24] total train loss: 0.0084; total val loss: 0.4589 val r: 0.7806; time: 0.95sec
[261/800][24/24] total train loss: 0.0088; total val loss: 0.4628 val r: 0.7826; time: 0.94sec
[262/800][24/24] total train loss: 0.0084; total val loss: 0.4572 val r: 0.7755; time: 0.95sec
[263/800][24/24] total train loss: 0.0080; total val loss: 0.4519 val r: 0.7773; time: 0.94sec
[264/800][24/24] total train loss: 0.0080; total val loss: 0.4623 val r: 0.7800; time: 0.94sec
[265/800][24/24] total train loss: 0.0081; total val loss: 0.4678 val r: 0.7797; time: 0.95sec
[266/800][24/24] total train loss: 0.0078; total val loss: 0.4578 val r: 0.7795; time: 0.95sec
[267/800][24/24] total train loss: 0.0083; total val loss: 0.4509 val r: 0.7763; time: 0.94sec
[268/800][24/24] total train loss: 0.0085; total val loss: 0.4496 val r: 0.7817; time: 0.94sec
[269/800][24/24] total train loss: 0.0088; total val loss: 0.4606 val r: 0.7810; time: 0.95sec
[270/800][24/24] total train loss: 0.0086; total val loss: 0.4521 val r: 0.7829; time: 0.95sec
[271/800][24/24] total train loss: 0.0087; total val loss: 0.4783 val r: 0.7843; time: 0.94sec
[272/800][24/24] total train loss: 0.0085; total val loss: 0.4661 val r: 0.7783; time: 0.94sec
[273/800][24/24] total train loss: 0.0089; total val loss: 0.4764 val r: 0.7801; time: 0.95sec
[274/800][24/24] total train loss: 0.0099; total val loss: 0.4560 val r: 0.7805; time: 0.94sec
[275/800][24/24] total train loss: 0.0096; total val loss: 0.4607 val r: 0.7777; time: 0.95sec
[276/800][24/24] total train loss: 0.0090; total val loss: 0.4561 val r: 0.7816; time: 0.94sec
[277/800][24/24] total train loss: 0.0084; total val loss: 0.4332 val r: 0.7758; time: 0.94sec
[278/800][24/24] total train loss: 0.0083; total val loss: 0.4628 val r: 0.7858; time: 0.95sec
[279/800][24/24] total train loss: 0.0085; total val loss: 0.4487 val r: 0.7796; time: 0.94sec
[280/800][24/24] total train loss: 0.0081; total val loss: 0.4591 val r: 0.7805; time: 0.95sec
[281/800][24/24] total train loss: 0.0081; total val loss: 0.4606 val r: 0.7772; time: 0.95sec
[282/800][24/24] total train loss: 0.0082; total val loss: 0.4481 val r: 0.7841; time: 0.94sec
[283/800][24/24] total train loss: 0.0081; total val loss: 0.4396 val r: 0.7752; time: 0.95sec
[284/800][24/24] total train loss: 0.0081; total val loss: 0.4647 val r: 0.7820; time: 0.95sec
[285/800][24/24] total train loss: 0.0085; total val loss: 0.4606 val r: 0.7769; time: 0.94sec
[286/800][24/24] total train loss: 0.0086; total val loss: 0.4622 val r: 0.7826; time: 0.94sec
[287/800][24/24] total train loss: 0.0086; total val loss: 0.4707 val r: 0.7747; time: 0.94sec
[288/800][24/24] total train loss: 0.0087; total val loss: 0.4648 val r: 0.7821; time: 0.94sec
[289/800][24/24] total train loss: 0.0089; total val loss: 0.4443 val r: 0.7818; time: 0.94sec
[290/800][24/24] total train loss: 0.0085; total val loss: 0.4622 val r: 0.7795; time: 0.94sec
[291/800][24/24] total train loss: 0.0086; total val loss: 0.4722 val r: 0.7817; time: 0.94sec
[292/800][24/24] total train loss: 0.0085; total val loss: 0.4457 val r: 0.7803; time: 0.95sec
[293/800][24/24] total train loss: 0.0086; total val loss: 0.4529 val r: 0.7822; time: 0.95sec
[294/800][24/24] total train loss: 0.0087; total val loss: 0.4565 val r: 0.7855; time: 0.95sec
[295/800][24/24] total train loss: 0.0090; total val loss: 0.4522 val r: 0.7844; time: 0.95sec
[296/800][24/24] total train loss: 0.0092; total val loss: 0.4562 val r: 0.7860; time: 0.94sec
[297/800][24/24] total train loss: 0.0089; total val loss: 0.4505 val r: 0.7822; time: 0.94sec
[298/800][24/24] total train loss: 0.0087; total val loss: 0.4516 val r: 0.7698; time: 0.94sec
[299/800][24/24] total train loss: 0.0092; total val loss: 0.4668 val r: 0.7820; time: 0.94sec
learning rate updated: 0.001
[300/800][24/24] total train loss: 0.0097; total val loss: 0.4680 val r: 0.7814; time: 0.95sec
[301/800][24/24] total train loss: 0.0092; total val loss: 0.4425 val r: 0.7722; time: 0.94sec
[302/800][24/24] total train loss: 0.0092; total val loss: 0.4649 val r: 0.7812; time: 0.94sec
[303/800][24/24] total train loss: 0.0089; total val loss: 0.4751 val r: 0.7793; time: 0.94sec
[304/800][24/24] total train loss: 0.0085; total val loss: 0.4507 val r: 0.7733; time: 0.94sec
[305/800][24/24] total train loss: 0.0085; total val loss: 0.4594 val r: 0.7791; time: 0.94sec
[306/800][24/24] total train loss: 0.0083; total val loss: 0.4548 val r: 0.7784; time: 0.94sec
[307/800][24/24] total train loss: 0.0082; total val loss: 0.4633 val r: 0.7821; time: 0.95sec
[308/800][24/24] total train loss: 0.0079; total val loss: 0.4729 val r: 0.7787; time: 0.94sec
[309/800][24/24] total train loss: 0.0078; total val loss: 0.4552 val r: 0.7767; time: 0.95sec
[310/800][24/24] total train loss: 0.0083; total val loss: 0.4471 val r: 0.7785; time: 0.94sec
[311/800][24/24] total train loss: 0.0082; total val loss: 0.4660 val r: 0.7802; time: 0.94sec
[312/800][24/24] total train loss: 0.0081; total val loss: 0.4605 val r: 0.7800; time: 0.94sec
[313/800][24/24] total train loss: 0.0081; total val loss: 0.4567 val r: 0.7789; time: 0.94sec
[314/800][24/24] total train loss: 0.0078; total val loss: 0.4528 val r: 0.7763; time: 0.94sec
[315/800][24/24] total train loss: 0.0081; total val loss: 0.4457 val r: 0.7721; time: 0.95sec
[316/800][24/24] total train loss: 0.0081; total val loss: 0.4611 val r: 0.7808; time: 0.95sec
[317/800][24/24] total train loss: 0.0077; total val loss: 0.4764 val r: 0.7836; time: 0.95sec
[318/800][24/24] total train loss: 0.0083; total val loss: 0.4557 val r: 0.7791; time: 0.95sec
[319/800][24/24] total train loss: 0.0081; total val loss: 0.4717 val r: 0.7835; time: 0.95sec
[320/800][24/24] total train loss: 0.0081; total val loss: 0.4386 val r: 0.7735; time: 0.94sec
[321/800][24/24] total train loss: 0.0081; total val loss: 0.4457 val r: 0.7744; time: 0.95sec
[322/800][24/24] total train loss: 0.0083; total val loss: 0.4517 val r: 0.7816; time: 0.94sec
[323/800][24/24] total train loss: 0.0085; total val loss: 0.4673 val r: 0.7791; time: 0.95sec
[324/800][24/24] total train loss: 0.0086; total val loss: 0.4701 val r: 0.7803; time: 0.95sec
[325/800][24/24] total train loss: 0.0080; total val loss: 0.4589 val r: 0.7739; time: 0.95sec
[326/800][24/24] total train loss: 0.0079; total val loss: 0.4660 val r: 0.7821; time: 0.94sec
[327/800][24/24] total train loss: 0.0082; total val loss: 0.4532 val r: 0.7791; time: 0.95sec
[328/800][24/24] total train loss: 0.0079; total val loss: 0.4642 val r: 0.7832; time: 0.95sec
[329/800][24/24] total train loss: 0.0078; total val loss: 0.4633 val r: 0.7792; time: 0.94sec
[330/800][24/24] total train loss: 0.0078; total val loss: 0.4555 val r: 0.7741; time: 0.95sec
[331/800][24/24] total train loss: 0.0076; total val loss: 0.4687 val r: 0.7793; time: 0.95sec
[332/800][24/24] total train loss: 0.0078; total val loss: 0.4572 val r: 0.7776; time: 0.95sec
[333/800][24/24] total train loss: 0.0078; total val loss: 0.4539 val r: 0.7803; time: 0.95sec
[334/800][24/24] total train loss: 0.0078; total val loss: 0.4585 val r: 0.7752; time: 0.95sec
[335/800][24/24] total train loss: 0.0083; total val loss: 0.4627 val r: 0.7793; time: 0.94sec
[336/800][24/24] total train loss: 0.0081; total val loss: 0.4581 val r: 0.7814; time: 0.94sec
[337/800][24/24] total train loss: 0.0083; total val loss: 0.4624 val r: 0.7810; time: 0.95sec
[338/800][24/24] total train loss: 0.0083; total val loss: 0.4426 val r: 0.7767; time: 0.94sec
[339/800][24/24] total train loss: 0.0080; total val loss: 0.4693 val r: 0.7840; time: 0.95sec
[340/800][24/24] total train loss: 0.0079; total val loss: 0.4571 val r: 0.7793; time: 0.95sec
[341/800][24/24] total train loss: 0.0078; total val loss: 0.4591 val r: 0.7777; time: 0.95sec
[342/800][24/24] total train loss: 0.0087; total val loss: 0.4525 val r: 0.7804; time: 0.94sec
[343/800][24/24] total train loss: 0.0083; total val loss: 0.4633 val r: 0.7764; time: 0.95sec
[344/800][24/24] total train loss: 0.0081; total val loss: 0.4674 val r: 0.7768; time: 0.94sec
[345/800][24/24] total train loss: 0.0079; total val loss: 0.4641 val r: 0.7813; time: 0.94sec
[346/800][24/24] total train loss: 0.0081; total val loss: 0.4619 val r: 0.7804; time: 0.94sec
[347/800][24/24] total train loss: 0.0083; total val loss: 0.4562 val r: 0.7776; time: 0.94sec
[348/800][24/24] total train loss: 0.0080; total val loss: 0.4564 val r: 0.7776; time: 0.94sec
[349/800][24/24] total train loss: 0.0082; total val loss: 0.4626 val r: 0.7734; time: 0.94sec
[350/800][24/24] total train loss: 0.0087; total val loss: 0.4597 val r: 0.7780; time: 0.94sec
[351/800][24/24] total train loss: 0.0083; total val loss: 0.4615 val r: 0.7805; time: 0.95sec
[352/800][24/24] total train loss: 0.0083; total val loss: 0.4490 val r: 0.7749; time: 0.94sec
[353/800][24/24] total train loss: 0.0083; total val loss: 0.4674 val r: 0.7806; time: 0.94sec
[354/800][24/24] total train loss: 0.0081; total val loss: 0.4716 val r: 0.7809; time: 0.94sec
[355/800][24/24] total train loss: 0.0081; total val loss: 0.4541 val r: 0.7821; time: 0.94sec
[356/800][24/24] total train loss: 0.0081; total val loss: 0.4706 val r: 0.7836; time: 0.95sec
[357/800][24/24] total train loss: 0.0078; total val loss: 0.4658 val r: 0.7756; time: 0.95sec
[358/800][24/24] total train loss: 0.0076; total val loss: 0.4604 val r: 0.7777; time: 0.95sec
[359/800][24/24] total train loss: 0.0078; total val loss: 0.4689 val r: 0.7812; time: 0.94sec
[360/800][24/24] total train loss: 0.0078; total val loss: 0.4627 val r: 0.7791; time: 0.95sec
[361/800][24/24] total train loss: 0.0078; total val loss: 0.4558 val r: 0.7792; time: 0.94sec
[362/800][24/24] total train loss: 0.0077; total val loss: 0.4631 val r: 0.7815; time: 0.95sec
[363/800][24/24] total train loss: 0.0078; total val loss: 0.4630 val r: 0.7805; time: 0.95sec
[364/800][24/24] total train loss: 0.0076; total val loss: 0.4571 val r: 0.7824; time: 0.95sec
[365/800][24/24] total train loss: 0.0079; total val loss: 0.4431 val r: 0.7817; time: 0.95sec
[366/800][24/24] total train loss: 0.0076; total val loss: 0.4591 val r: 0.7776; time: 0.95sec
[367/800][24/24] total train loss: 0.0075; total val loss: 0.4556 val r: 0.7785; time: 0.94sec
[368/800][24/24] total train loss: 0.0079; total val loss: 0.4478 val r: 0.7814; time: 0.95sec
[369/800][24/24] total train loss: 0.0078; total val loss: 0.4698 val r: 0.7857; time: 0.95sec
[370/800][24/24] total train loss: 0.0081; total val loss: 0.4488 val r: 0.7782; time: 0.94sec
[371/800][24/24] total train loss: 0.0081; total val loss: 0.4550 val r: 0.7757; time: 0.95sec
[372/800][24/24] total train loss: 0.0085; total val loss: 0.4711 val r: 0.7822; time: 0.94sec
[373/800][24/24] total train loss: 0.0081; total val loss: 0.4427 val r: 0.7811; time: 0.94sec
[374/800][24/24] total train loss: 0.0078; total val loss: 0.4587 val r: 0.7820; time: 0.94sec
[375/800][24/24] total train loss: 0.0079; total val loss: 0.4537 val r: 0.7726; time: 0.94sec
[376/800][24/24] total train loss: 0.0079; total val loss: 0.4498 val r: 0.7716; time: 0.95sec
[377/800][24/24] total train loss: 0.0081; total val loss: 0.4753 val r: 0.7856; time: 0.94sec
[378/800][24/24] total train loss: 0.0081; total val loss: 0.4818 val r: 0.7822; time: 0.94sec
[379/800][24/24] total train loss: 0.0079; total val loss: 0.4699 val r: 0.7816; time: 0.95sec
[380/800][24/24] total train loss: 0.0079; total val loss: 0.4482 val r: 0.7736; time: 0.95sec
[381/800][24/24] total train loss: 0.0076; total val loss: 0.4599 val r: 0.7775; time: 0.95sec
[382/800][24/24] total train loss: 0.0076; total val loss: 0.4452 val r: 0.7815; time: 0.95sec
[383/800][24/24] total train loss: 0.0077; total val loss: 0.4549 val r: 0.7815; time: 0.95sec
[384/800][24/24] total train loss: 0.0077; total val loss: 0.4634 val r: 0.7783; time: 0.94sec
[385/800][24/24] total train loss: 0.0077; total val loss: 0.4508 val r: 0.7799; time: 0.95sec
[386/800][24/24] total train loss: 0.0079; total val loss: 0.4533 val r: 0.7798; time: 0.95sec
[387/800][24/24] total train loss: 0.0076; total val loss: 0.4581 val r: 0.7811; time: 0.95sec
[388/800][24/24] total train loss: 0.0079; total val loss: 0.4618 val r: 0.7795; time: 0.95sec
[389/800][24/24] total train loss: 0.0078; total val loss: 0.4501 val r: 0.7789; time: 0.94sec
[390/800][24/24] total train loss: 0.0076; total val loss: 0.4642 val r: 0.7813; time: 0.94sec
[391/800][24/24] total train loss: 0.0080; total val loss: 0.4548 val r: 0.7753; time: 0.94sec
[392/800][24/24] total train loss: 0.0079; total val loss: 0.4610 val r: 0.7851; time: 0.94sec
[393/800][24/24] total train loss: 0.0078; total val loss: 0.4612 val r: 0.7799; time: 0.94sec
[394/800][24/24] total train loss: 0.0078; total val loss: 0.4660 val r: 0.7766; time: 0.94sec
[395/800][24/24] total train loss: 0.0078; total val loss: 0.4474 val r: 0.7823; time: 0.94sec
[396/800][24/24] total train loss: 0.0079; total val loss: 0.4667 val r: 0.7792; time: 0.94sec
[397/800][24/24] total train loss: 0.0086; total val loss: 0.4518 val r: 0.7822; time: 0.94sec
[398/800][24/24] total train loss: 0.0080; total val loss: 0.4683 val r: 0.7856; time: 0.94sec
[399/800][24/24] total train loss: 0.0079; total val loss: 0.4713 val r: 0.7804; time: 0.95sec
learning rate updated: 0.001
[400/800][24/24] total train loss: 0.0078; total val loss: 0.4575 val r: 0.7802; time: 0.94sec
[401/800][24/24] total train loss: 0.0076; total val loss: 0.4666 val r: 0.7833; time: 0.95sec
[402/800][24/24] total train loss: 0.0078; total val loss: 0.4724 val r: 0.7780; time: 0.94sec
[403/800][24/24] total train loss: 0.0077; total val loss: 0.4641 val r: 0.7816; time: 0.95sec
[404/800][24/24] total train loss: 0.0078; total val loss: 0.4501 val r: 0.7799; time: 0.94sec
[405/800][24/24] total train loss: 0.0076; total val loss: 0.4589 val r: 0.7842; time: 0.95sec
[406/800][24/24] total train loss: 0.0080; total val loss: 0.4626 val r: 0.7813; time: 0.95sec
[407/800][24/24] total train loss: 0.0078; total val loss: 0.4706 val r: 0.7809; time: 0.94sec
[408/800][24/24] total train loss: 0.0076; total val loss: 0.4559 val r: 0.7762; time: 0.94sec
[409/800][24/24] total train loss: 0.0075; total val loss: 0.4620 val r: 0.7810; time: 0.95sec
[410/800][24/24] total train loss: 0.0078; total val loss: 0.4597 val r: 0.7745; time: 0.94sec
[411/800][24/24] total train loss: 0.0076; total val loss: 0.4696 val r: 0.7854; time: 0.94sec
[412/800][24/24] total train loss: 0.0077; total val loss: 0.4698 val r: 0.7823; time: 0.94sec
[413/800][24/24] total train loss: 0.0076; total val loss: 0.4638 val r: 0.7833; time: 0.94sec
[414/800][24/24] total train loss: 0.0078; total val loss: 0.4507 val r: 0.7701; time: 0.94sec
[415/800][24/24] total train loss: 0.0080; total val loss: 0.4665 val r: 0.7817; time: 0.95sec
[416/800][24/24] total train loss: 0.0079; total val loss: 0.4751 val r: 0.7826; time: 0.94sec
[417/800][24/24] total train loss: 0.0078; total val loss: 0.4528 val r: 0.7823; time: 0.95sec
[418/800][24/24] total train loss: 0.0081; total val loss: 0.4654 val r: 0.7807; time: 0.94sec
[419/800][24/24] total train loss: 0.0074; total val loss: 0.4643 val r: 0.7755; time: 0.94sec
[420/800][24/24] total train loss: 0.0074; total val loss: 0.4578 val r: 0.7724; time: 0.94sec
[421/800][24/24] total train loss: 0.0078; total val loss: 0.4623 val r: 0.7772; time: 0.94sec
[422/800][24/24] total train loss: 0.0080; total val loss: 0.4697 val r: 0.7809; time: 0.95sec
[423/800][24/24] total train loss: 0.0076; total val loss: 0.4706 val r: 0.7818; time: 0.95sec
[424/800][24/24] total train loss: 0.0077; total val loss: 0.4650 val r: 0.7827; time: 0.95sec
[425/800][24/24] total train loss: 0.0076; total val loss: 0.4616 val r: 0.7839; time: 0.94sec
[426/800][24/24] total train loss: 0.0074; total val loss: 0.4709 val r: 0.7833; time: 0.95sec
[427/800][24/24] total train loss: 0.0081; total val loss: 0.4640 val r: 0.7815; time: 0.94sec
[428/800][24/24] total train loss: 0.0082; total val loss: 0.4672 val r: 0.7828; time: 0.95sec
[429/800][24/24] total train loss: 0.0085; total val loss: 0.4616 val r: 0.7740; time: 0.95sec
[430/800][24/24] total train loss: 0.0083; total val loss: 0.4786 val r: 0.7803; time: 0.94sec
[431/800][24/24] total train loss: 0.0080; total val loss: 0.4607 val r: 0.7796; time: 0.94sec
[432/800][24/24] total train loss: 0.0077; total val loss: 0.4625 val r: 0.7754; time: 0.94sec
[433/800][24/24] total train loss: 0.0076; total val loss: 0.4617 val r: 0.7729; time: 0.95sec
[434/800][24/24] total train loss: 0.0078; total val loss: 0.4445 val r: 0.7839; time: 0.94sec
[435/800][24/24] total train loss: 0.0076; total val loss: 0.4651 val r: 0.7797; time: 0.94sec
[436/800][24/24] total train loss: 0.0076; total val loss: 0.4622 val r: 0.7845; time: 0.94sec
[437/800][24/24] total train loss: 0.0078; total val loss: 0.4684 val r: 0.7807; time: 0.94sec
[438/800][24/24] total train loss: 0.0076; total val loss: 0.4603 val r: 0.7829; time: 0.94sec
[439/800][24/24] total train loss: 0.0078; total val loss: 0.4492 val r: 0.7728; time: 0.94sec
[440/800][24/24] total train loss: 0.0076; total val loss: 0.4673 val r: 0.7804; time: 0.94sec
[441/800][24/24] total train loss: 0.0075; total val loss: 0.4695 val r: 0.7827; time: 0.94sec
[442/800][24/24] total train loss: 0.0075; total val loss: 0.4649 val r: 0.7783; time: 0.95sec
[443/800][24/24] total train loss: 0.0075; total val loss: 0.4711 val r: 0.7801; time: 0.95sec
[444/800][24/24] total train loss: 0.0076; total val loss: 0.4663 val r: 0.7764; time: 0.94sec
[445/800][24/24] total train loss: 0.0076; total val loss: 0.4906 val r: 0.7866; time: 0.95sec
[446/800][24/24] total train loss: 0.0082; total val loss: 0.4617 val r: 0.7797; time: 0.94sec
[447/800][24/24] total train loss: 0.0077; total val loss: 0.4600 val r: 0.7768; time: 0.94sec
[448/800][24/24] total train loss: 0.0079; total val loss: 0.4524 val r: 0.7766; time: 0.94sec
[449/800][24/24] total train loss: 0.0076; total val loss: 0.4595 val r: 0.7802; time: 0.95sec
[450/800][24/24] total train loss: 0.0077; total val loss: 0.4539 val r: 0.7820; time: 0.94sec
[451/800][24/24] total train loss: 0.0075; total val loss: 0.4608 val r: 0.7768; time: 0.94sec
[452/800][24/24] total train loss: 0.0076; total val loss: 0.4643 val r: 0.7846; time: 0.95sec
[453/800][24/24] total train loss: 0.0077; total val loss: 0.4637 val r: 0.7731; time: 0.94sec
[454/800][24/24] total train loss: 0.0077; total val loss: 0.4732 val r: 0.7817; time: 0.95sec
[455/800][24/24] total train loss: 0.0078; total val loss: 0.4637 val r: 0.7791; time: 0.94sec
[456/800][24/24] total train loss: 0.0076; total val loss: 0.4820 val r: 0.7862; time: 0.95sec
[457/800][24/24] total train loss: 0.0076; total val loss: 0.4672 val r: 0.7810; time: 0.95sec
[458/800][24/24] total train loss: 0.0076; total val loss: 0.4724 val r: 0.7819; time: 0.95sec
[459/800][24/24] total train loss: 0.0076; total val loss: 0.4602 val r: 0.7808; time: 0.95sec
[460/800][24/24] total train loss: 0.0077; total val loss: 0.4429 val r: 0.7777; time: 0.95sec
[461/800][24/24] total train loss: 0.0075; total val loss: 0.4560 val r: 0.7857; time: 0.94sec
[462/800][24/24] total train loss: 0.0075; total val loss: 0.4566 val r: 0.7759; time: 0.94sec
[463/800][24/24] total train loss: 0.0077; total val loss: 0.4514 val r: 0.7772; time: 0.95sec
[464/800][24/24] total train loss: 0.0076; total val loss: 0.4668 val r: 0.7822; time: 0.94sec
[465/800][24/24] total train loss: 0.0076; total val loss: 0.4564 val r: 0.7778; time: 0.95sec
[466/800][24/24] total train loss: 0.0076; total val loss: 0.4738 val r: 0.7785; time: 0.95sec
[467/800][24/24] total train loss: 0.0077; total val loss: 0.4781 val r: 0.7845; time: 0.94sec
[468/800][24/24] total train loss: 0.0076; total val loss: 0.4557 val r: 0.7781; time: 0.95sec
[469/800][24/24] total train loss: 0.0076; total val loss: 0.4652 val r: 0.7781; time: 0.95sec
[470/800][24/24] total train loss: 0.0076; total val loss: 0.4669 val r: 0.7858; time: 0.94sec
[471/800][24/24] total train loss: 0.0077; total val loss: 0.4747 val r: 0.7794; time: 0.95sec
[472/800][24/24] total train loss: 0.0077; total val loss: 0.4670 val r: 0.7777; time: 0.94sec
[473/800][24/24] total train loss: 0.0075; total val loss: 0.4684 val r: 0.7854; time: 0.95sec
[474/800][24/24] total train loss: 0.0076; total val loss: 0.4665 val r: 0.7839; time: 0.94sec
[475/800][24/24] total train loss: 0.0074; total val loss: 0.4541 val r: 0.7799; time: 0.95sec
[476/800][24/24] total train loss: 0.0076; total val loss: 0.4587 val r: 0.7821; time: 0.94sec
[477/800][24/24] total train loss: 0.0074; total val loss: 0.4634 val r: 0.7795; time: 0.94sec
[478/800][24/24] total train loss: 0.0077; total val loss: 0.4713 val r: 0.7852; time: 0.94sec
[479/800][24/24] total train loss: 0.0078; total val loss: 0.4575 val r: 0.7778; time: 0.94sec
[480/800][24/24] total train loss: 0.0077; total val loss: 0.4568 val r: 0.7798; time: 0.94sec
[481/800][24/24] total train loss: 0.0077; total val loss: 0.4780 val r: 0.7867; time: 0.95sec
[482/800][24/24] total train loss: 0.0074; total val loss: 0.4625 val r: 0.7771; time: 0.94sec
[483/800][24/24] total train loss: 0.0078; total val loss: 0.4640 val r: 0.7848; time: 0.94sec
[484/800][24/24] total train loss: 0.0075; total val loss: 0.4755 val r: 0.7858; time: 0.94sec
[485/800][24/24] total train loss: 0.0075; total val loss: 0.4428 val r: 0.7798; time: 0.94sec
[486/800][24/24] total train loss: 0.0075; total val loss: 0.4725 val r: 0.7792; time: 0.94sec
[487/800][24/24] total train loss: 0.0077; total val loss: 0.4670 val r: 0.7783; time: 0.94sec
[488/800][24/24] total train loss: 0.0078; total val loss: 0.4669 val r: 0.7824; time: 0.95sec
[489/800][24/24] total train loss: 0.0075; total val loss: 0.4625 val r: 0.7801; time: 0.94sec
[490/800][24/24] total train loss: 0.0075; total val loss: 0.4637 val r: 0.7828; time: 0.94sec
[491/800][24/24] total train loss: 0.0077; total val loss: 0.4900 val r: 0.7895; time: 0.94sec
[492/800][24/24] total train loss: 0.0078; total val loss: 0.4709 val r: 0.7826; time: 0.93sec
[493/800][24/24] total train loss: 0.0080; total val loss: 0.4488 val r: 0.7740; time: 0.94sec
[494/800][24/24] total train loss: 0.0080; total val loss: 0.4791 val r: 0.7857; time: 0.94sec
[495/800][24/24] total train loss: 0.0079; total val loss: 0.4578 val r: 0.7863; time: 0.94sec
[496/800][24/24] total train loss: 0.0078; total val loss: 0.4746 val r: 0.7865; time: 0.95sec
[497/800][24/24] total train loss: 0.0077; total val loss: 0.4355 val r: 0.7703; time: 0.95sec
[498/800][24/24] total train loss: 0.0077; total val loss: 0.4584 val r: 0.7836; time: 0.94sec
[499/800][24/24] total train loss: 0.0080; total val loss: 0.4779 val r: 0.7828; time: 0.94sec
learning rate updated: 0.001
[500/800][24/24] total train loss: 0.0077; total val loss: 0.4603 val r: 0.7805; time: 0.95sec
[501/800][24/24] total train loss: 0.0081; total val loss: 0.4570 val r: 0.7819; time: 0.94sec
[502/800][24/24] total train loss: 0.0077; total val loss: 0.4756 val r: 0.7833; time: 0.94sec
[503/800][24/24] total train loss: 0.0074; total val loss: 0.4540 val r: 0.7831; time: 0.95sec
[504/800][24/24] total train loss: 0.0076; total val loss: 0.4632 val r: 0.7840; time: 0.93sec
[505/800][24/24] total train loss: 0.0077; total val loss: 0.4603 val r: 0.7784; time: 0.95sec
[506/800][24/24] total train loss: 0.0078; total val loss: 0.4721 val r: 0.7873; time: 0.95sec
[507/800][24/24] total train loss: 0.0078; total val loss: 0.4647 val r: 0.7760; time: 0.94sec
[508/800][24/24] total train loss: 0.0077; total val loss: 0.4816 val r: 0.7883; time: 0.95sec
[509/800][24/24] total train loss: 0.0086; total val loss: 0.4696 val r: 0.7815; time: 0.95sec
[510/800][24/24] total train loss: 0.0083; total val loss: 0.4674 val r: 0.7777; time: 0.95sec
[511/800][24/24] total train loss: 0.0105; total val loss: 0.4688 val r: 0.7712; time: 0.94sec
[512/800][24/24] total train loss: 0.0111; total val loss: 0.4603 val r: 0.7524; time: 0.95sec
[513/800][24/24] total train loss: 0.0163; total val loss: 0.4668 val r: 0.7558; time: 0.95sec
[514/800][24/24] total train loss: 0.0172; total val loss: 0.4486 val r: 0.7690; time: 0.94sec
[515/800][24/24] total train loss: 0.0168; total val loss: 0.4590 val r: 0.7689; time: 0.95sec
[516/800][24/24] total train loss: 0.0172; total val loss: 0.4811 val r: 0.7632; time: 0.95sec
[517/800][24/24] total train loss: 0.0121; total val loss: 0.4754 val r: 0.7782; time: 0.95sec
[518/800][24/24] total train loss: 0.0108; total val loss: 0.4720 val r: 0.7707; time: 0.95sec
[519/800][24/24] total train loss: 0.0098; total val loss: 0.4634 val r: 0.7688; time: 0.95sec
[520/800][24/24] total train loss: 0.0087; total val loss: 0.4669 val r: 0.7834; time: 0.95sec
[521/800][24/24] total train loss: 0.0084; total val loss: 0.4826 val r: 0.7829; time: 0.95sec
[522/800][24/24] total train loss: 0.0084; total val loss: 0.4596 val r: 0.7711; time: 0.95sec
[523/800][24/24] total train loss: 0.0081; total val loss: 0.4599 val r: 0.7860; time: 0.94sec
[524/800][24/24] total train loss: 0.0079; total val loss: 0.4575 val r: 0.7779; time: 0.95sec
[525/800][24/24] total train loss: 0.0078; total val loss: 0.4635 val r: 0.7806; time: 0.95sec
[526/800][24/24] total train loss: 0.0076; total val loss: 0.4690 val r: 0.7813; time: 0.94sec
[527/800][24/24] total train loss: 0.0073; total val loss: 0.4474 val r: 0.7781; time: 0.94sec
[528/800][24/24] total train loss: 0.0078; total val loss: 0.4649 val r: 0.7837; time: 0.94sec
[529/800][24/24] total train loss: 0.0076; total val loss: 0.4589 val r: 0.7789; time: 0.95sec
[530/800][24/24] total train loss: 0.0076; total val loss: 0.4620 val r: 0.7799; time: 0.96sec
[531/800][24/24] total train loss: 0.0075; total val loss: 0.4470 val r: 0.7780; time: 0.94sec
[532/800][24/24] total train loss: 0.0077; total val loss: 0.4578 val r: 0.7813; time: 0.93sec
[533/800][24/24] total train loss: 0.0074; total val loss: 0.4610 val r: 0.7775; time: 0.94sec
[534/800][24/24] total train loss: 0.0077; total val loss: 0.4765 val r: 0.7760; time: 0.94sec
[535/800][24/24] total train loss: 0.0077; total val loss: 0.4634 val r: 0.7768; time: 0.93sec
[536/800][24/24] total train loss: 0.0077; total val loss: 0.4647 val r: 0.7802; time: 0.94sec
[537/800][24/24] total train loss: 0.0075; total val loss: 0.4564 val r: 0.7821; time: 0.93sec
[538/800][24/24] total train loss: 0.0076; total val loss: 0.4497 val r: 0.7755; time: 0.93sec
[539/800][24/24] total train loss: 0.0076; total val loss: 0.4632 val r: 0.7827; time: 0.94sec
[540/800][24/24] total train loss: 0.0075; total val loss: 0.4588 val r: 0.7792; time: 0.94sec
[541/800][24/24] total train loss: 0.0075; total val loss: 0.4684 val r: 0.7774; time: 0.95sec
[542/800][24/24] total train loss: 0.0074; total val loss: 0.4665 val r: 0.7773; time: 0.95sec
[543/800][24/24] total train loss: 0.0075; total val loss: 0.4713 val r: 0.7836; time: 0.95sec
[544/800][24/24] total train loss: 0.0073; total val loss: 0.4648 val r: 0.7783; time: 0.94sec
[545/800][24/24] total train loss: 0.0076; total val loss: 0.4685 val r: 0.7820; time: 0.95sec
[546/800][24/24] total train loss: 0.0075; total val loss: 0.4586 val r: 0.7829; time: 0.95sec
[547/800][24/24] total train loss: 0.0076; total val loss: 0.4620 val r: 0.7792; time: 0.95sec
[548/800][24/24] total train loss: 0.0076; total val loss: 0.4715 val r: 0.7792; time: 0.94sec
[549/800][24/24] total train loss: 0.0076; total val loss: 0.4566 val r: 0.7819; time: 0.95sec
[550/800][24/24] total train loss: 0.0080; total val loss: 0.4686 val r: 0.7822; time: 0.94sec
[551/800][24/24] total train loss: 0.0075; total val loss: 0.4756 val r: 0.7773; time: 0.95sec
[552/800][24/24] total train loss: 0.0076; total val loss: 0.4730 val r: 0.7872; time: 0.95sec
[553/800][24/24] total train loss: 0.0077; total val loss: 0.4563 val r: 0.7739; time: 0.94sec
[554/800][24/24] total train loss: 0.0076; total val loss: 0.4647 val r: 0.7800; time: 0.94sec
[555/800][24/24] total train loss: 0.0074; total val loss: 0.4331 val r: 0.7776; time: 0.94sec
[556/800][24/24] total train loss: 0.0077; total val loss: 0.4675 val r: 0.7806; time: 0.95sec
[557/800][24/24] total train loss: 0.0076; total val loss: 0.4679 val r: 0.7832; time: 0.94sec
[558/800][24/24] total train loss: 0.0076; total val loss: 0.4630 val r: 0.7839; time: 0.95sec
[559/800][24/24] total train loss: 0.0074; total val loss: 0.4685 val r: 0.7779; time: 0.94sec
[560/800][24/24] total train loss: 0.0075; total val loss: 0.4753 val r: 0.7816; time: 0.94sec
[561/800][24/24] total train loss: 0.0073; total val loss: 0.4413 val r: 0.7769; time: 0.95sec
[562/800][24/24] total train loss: 0.0076; total val loss: 0.4610 val r: 0.7789; time: 0.95sec
[563/800][24/24] total train loss: 0.0075; total val loss: 0.4685 val r: 0.7822; time: 0.94sec
[564/800][24/24] total train loss: 0.0074; total val loss: 0.4342 val r: 0.7818; time: 0.94sec
[565/800][24/24] total train loss: 0.0074; total val loss: 0.4722 val r: 0.7762; time: 0.95sec
[566/800][24/24] total train loss: 0.0075; total val loss: 0.4649 val r: 0.7801; time: 0.95sec
[567/800][24/24] total train loss: 0.0078; total val loss: 0.4680 val r: 0.7811; time: 0.94sec
[568/800][24/24] total train loss: 0.0074; total val loss: 0.4598 val r: 0.7838; time: 0.94sec
[569/800][24/24] total train loss: 0.0079; total val loss: 0.4328 val r: 0.7797; time: 0.95sec
[570/800][24/24] total train loss: 0.0077; total val loss: 0.4652 val r: 0.7818; time: 0.94sec
[571/800][24/24] total train loss: 0.0073; total val loss: 0.4487 val r: 0.7795; time: 0.95sec
[572/800][24/24] total train loss: 0.0074; total val loss: 0.4743 val r: 0.7834; time: 0.94sec
[573/800][24/24] total train loss: 0.0075; total val loss: 0.4659 val r: 0.7778; time: 0.95sec
[574/800][24/24] total train loss: 0.0078; total val loss: 0.4701 val r: 0.7851; time: 0.95sec
[575/800][24/24] total train loss: 0.0077; total val loss: 0.4511 val r: 0.7732; time: 0.95sec
[576/800][24/24] total train loss: 0.0079; total val loss: 0.4721 val r: 0.7833; time: 0.95sec
[577/800][24/24] total train loss: 0.0076; total val loss: 0.4587 val r: 0.7804; time: 0.95sec
[578/800][24/24] total train loss: 0.0074; total val loss: 0.4698 val r: 0.7822; time: 0.93sec
[579/800][24/24] total train loss: 0.0075; total val loss: 0.4653 val r: 0.7837; time: 0.95sec
[580/800][24/24] total train loss: 0.0076; total val loss: 0.4709 val r: 0.7772; time: 0.95sec
[581/800][24/24] total train loss: 0.0076; total val loss: 0.4630 val r: 0.7825; time: 0.94sec
[582/800][24/24] total train loss: 0.0074; total val loss: 0.4524 val r: 0.7814; time: 0.94sec
[583/800][24/24] total train loss: 0.0072; total val loss: 0.4638 val r: 0.7800; time: 0.95sec
[584/800][24/24] total train loss: 0.0075; total val loss: 0.4702 val r: 0.7820; time: 0.94sec
[585/800][24/24] total train loss: 0.0075; total val loss: 0.4702 val r: 0.7805; time: 0.95sec
[586/800][24/24] total train loss: 0.0074; total val loss: 0.4608 val r: 0.7809; time: 0.94sec
[587/800][24/24] total train loss: 0.0074; total val loss: 0.4697 val r: 0.7804; time: 0.95sec
[588/800][24/24] total train loss: 0.0074; total val loss: 0.4712 val r: 0.7831; time: 0.94sec
[589/800][24/24] total train loss: 0.0074; total val loss: 0.4671 val r: 0.7779; time: 0.94sec
[590/800][24/24] total train loss: 0.0073; total val loss: 0.4648 val r: 0.7798; time: 0.95sec
[591/800][24/24] total train loss: 0.0075; total val loss: 0.4646 val r: 0.7805; time: 0.94sec
[592/800][24/24] total train loss: 0.0074; total val loss: 0.4439 val r: 0.7784; time: 0.94sec
[593/800][24/24] total train loss: 0.0075; total val loss: 0.4641 val r: 0.7806; time: 0.95sec
[594/800][24/24] total train loss: 0.0074; total val loss: 0.4613 val r: 0.7795; time: 0.95sec
[595/800][24/24] total train loss: 0.0073; total val loss: 0.4700 val r: 0.7805; time: 0.95sec
[596/800][24/24] total train loss: 0.0077; total val loss: 0.4620 val r: 0.7818; time: 0.94sec
[597/800][24/24] total train loss: 0.0075; total val loss: 0.4631 val r: 0.7819; time: 0.95sec
[598/800][24/24] total train loss: 0.0076; total val loss: 0.4705 val r: 0.7797; time: 0.94sec
[599/800][24/24] total train loss: 0.0075; total val loss: 0.4699 val r: 0.7825; time: 0.94sec
learning rate updated: 0.001
[600/800][24/24] total train loss: 0.0075; total val loss: 0.4649 val r: 0.7783; time: 0.95sec
[601/800][24/24] total train loss: 0.0075; total val loss: 0.4531 val r: 0.7832; time: 0.94sec
[602/800][24/24] total train loss: 0.0073; total val loss: 0.4613 val r: 0.7831; time: 0.95sec
[603/800][24/24] total train loss: 0.0074; total val loss: 0.4629 val r: 0.7834; time: 0.94sec
[604/800][24/24] total train loss: 0.0079; total val loss: 0.4821 val r: 0.7843; time: 0.95sec
[605/800][24/24] total train loss: 0.0074; total val loss: 0.4739 val r: 0.7817; time: 0.94sec
[606/800][24/24] total train loss: 0.0077; total val loss: 0.4695 val r: 0.7795; time: 0.94sec
[607/800][24/24] total train loss: 0.0077; total val loss: 0.4711 val r: 0.7797; time: 0.94sec
[608/800][24/24] total train loss: 0.0072; total val loss: 0.4642 val r: 0.7817; time: 0.95sec
[609/800][24/24] total train loss: 0.0076; total val loss: 0.4595 val r: 0.7751; time: 0.95sec
[610/800][24/24] total train loss: 0.0074; total val loss: 0.4645 val r: 0.7762; time: 0.94sec
[611/800][24/24] total train loss: 0.0074; total val loss: 0.4723 val r: 0.7821; time: 0.95sec
[612/800][24/24] total train loss: 0.0075; total val loss: 0.4711 val r: 0.7831; time: 0.95sec
[613/800][24/24] total train loss: 0.0079; total val loss: 0.4689 val r: 0.7738; time: 0.94sec
[614/800][24/24] total train loss: 0.0077; total val loss: 0.4644 val r: 0.7787; time: 0.95sec
[615/800][24/24] total train loss: 0.0077; total val loss: 0.4662 val r: 0.7830; time: 0.95sec
[616/800][24/24] total train loss: 0.0074; total val loss: 0.4543 val r: 0.7796; time: 0.94sec
[617/800][24/24] total train loss: 0.0075; total val loss: 0.4460 val r: 0.7828; time: 0.94sec
[618/800][24/24] total train loss: 0.0076; total val loss: 0.4652 val r: 0.7776; time: 0.94sec
[619/800][24/24] total train loss: 0.0075; total val loss: 0.4670 val r: 0.7788; time: 0.94sec
[620/800][24/24] total train loss: 0.0073; total val loss: 0.4545 val r: 0.7769; time: 0.95sec
[621/800][24/24] total train loss: 0.0075; total val loss: 0.4775 val r: 0.7842; time: 0.95sec
[622/800][24/24] total train loss: 0.0078; total val loss: 0.4712 val r: 0.7780; time: 0.94sec
[623/800][24/24] total train loss: 0.0079; total val loss: 0.4461 val r: 0.7770; time: 0.95sec
[624/800][24/24] total train loss: 0.0075; total val loss: 0.4718 val r: 0.7835; time: 0.95sec
[625/800][24/24] total train loss: 0.0076; total val loss: 0.4688 val r: 0.7814; time: 0.95sec
[626/800][24/24] total train loss: 0.0074; total val loss: 0.4677 val r: 0.7811; time: 0.95sec
[627/800][24/24] total train loss: 0.0076; total val loss: 0.4558 val r: 0.7773; time: 0.95sec
[628/800][24/24] total train loss: 0.0075; total val loss: 0.4577 val r: 0.7773; time: 0.94sec
[629/800][24/24] total train loss: 0.0072; total val loss: 0.4683 val r: 0.7837; time: 0.95sec
[630/800][24/24] total train loss: 0.0074; total val loss: 0.4754 val r: 0.7751; time: 0.94sec
[631/800][24/24] total train loss: 0.0075; total val loss: 0.4646 val r: 0.7816; time: 0.94sec
[632/800][24/24] total train loss: 0.0073; total val loss: 0.4723 val r: 0.7786; time: 0.95sec
[633/800][24/24] total train loss: 0.0075; total val loss: 0.4539 val r: 0.7789; time: 0.95sec
[634/800][24/24] total train loss: 0.0075; total val loss: 0.4597 val r: 0.7808; time: 0.94sec
[635/800][24/24] total train loss: 0.0074; total val loss: 0.4619 val r: 0.7803; time: 0.95sec
[636/800][24/24] total train loss: 0.0074; total val loss: 0.4662 val r: 0.7786; time: 0.95sec
[637/800][24/24] total train loss: 0.0075; total val loss: 0.4598 val r: 0.7761; time: 0.94sec
[638/800][24/24] total train loss: 0.0075; total val loss: 0.4635 val r: 0.7855; time: 0.95sec
[639/800][24/24] total train loss: 0.0072; total val loss: 0.4704 val r: 0.7745; time: 0.94sec
[640/800][24/24] total train loss: 0.0074; total val loss: 0.4744 val r: 0.7807; time: 0.95sec
[641/800][24/24] total train loss: 0.0078; total val loss: 0.4535 val r: 0.7807; time: 0.94sec
[642/800][24/24] total train loss: 0.0079; total val loss: 0.4679 val r: 0.7802; time: 0.94sec
[643/800][24/24] total train loss: 0.0075; total val loss: 0.4663 val r: 0.7829; time: 0.94sec
[644/800][24/24] total train loss: 0.0073; total val loss: 0.4519 val r: 0.7774; time: 0.94sec
[645/800][24/24] total train loss: 0.0072; total val loss: 0.4554 val r: 0.7797; time: 0.95sec
[646/800][24/24] total train loss: 0.0076; total val loss: 0.4505 val r: 0.7745; time: 0.94sec
[647/800][24/24] total train loss: 0.0078; total val loss: 0.4589 val r: 0.7787; time: 0.95sec
[648/800][24/24] total train loss: 0.0077; total val loss: 0.4707 val r: 0.7791; time: 0.94sec
[649/800][24/24] total train loss: 0.0076; total val loss: 0.4718 val r: 0.7778; time: 0.94sec
[650/800][24/24] total train loss: 0.0072; total val loss: 0.4729 val r: 0.7807; time: 0.94sec
[651/800][24/24] total train loss: 0.0074; total val loss: 0.4702 val r: 0.7786; time: 0.94sec
[652/800][24/24] total train loss: 0.0074; total val loss: 0.4728 val r: 0.7798; time: 0.95sec
[653/800][24/24] total train loss: 0.0075; total val loss: 0.4365 val r: 0.7783; time: 0.94sec
[654/800][24/24] total train loss: 0.0074; total val loss: 0.4572 val r: 0.7796; time: 0.94sec
[655/800][24/24] total train loss: 0.0078; total val loss: 0.4721 val r: 0.7779; time: 0.95sec
[656/800][24/24] total train loss: 0.0078; total val loss: 0.4674 val r: 0.7798; time: 0.94sec
[657/800][24/24] total train loss: 0.0076; total val loss: 0.4483 val r: 0.7823; time: 0.94sec
[658/800][24/24] total train loss: 0.0077; total val loss: 0.4657 val r: 0.7804; time: 0.94sec
[659/800][24/24] total train loss: 0.0074; total val loss: 0.4635 val r: 0.7753; time: 0.94sec
[660/800][24/24] total train loss: 0.0079; total val loss: 0.4555 val r: 0.7792; time: 0.94sec
[661/800][24/24] total train loss: 0.0075; total val loss: 0.4777 val r: 0.7819; time: 0.93sec
[662/800][24/24] total train loss: 0.0073; total val loss: 0.4690 val r: 0.7824; time: 0.95sec
[663/800][24/24] total train loss: 0.0074; total val loss: 0.4630 val r: 0.7814; time: 0.95sec
[664/800][24/24] total train loss: 0.0073; total val loss: 0.4572 val r: 0.7766; time: 0.94sec
[665/800][24/24] total train loss: 0.0076; total val loss: 0.4766 val r: 0.7862; time: 0.94sec
[666/800][24/24] total train loss: 0.0073; total val loss: 0.4575 val r: 0.7750; time: 0.95sec
[667/800][24/24] total train loss: 0.0073; total val loss: 0.4748 val r: 0.7828; time: 0.95sec
[668/800][24/24] total train loss: 0.0074; total val loss: 0.4592 val r: 0.7766; time: 0.94sec
[669/800][24/24] total train loss: 0.0073; total val loss: 0.4656 val r: 0.7791; time: 0.94sec
[670/800][24/24] total train loss: 0.0075; total val loss: 0.4802 val r: 0.7791; time: 0.95sec
[671/800][24/24] total train loss: 0.0074; total val loss: 0.4672 val r: 0.7801; time: 0.94sec
[672/800][24/24] total train loss: 0.0076; total val loss: 0.4622 val r: 0.7791; time: 0.94sec
[673/800][24/24] total train loss: 0.0074; total val loss: 0.4618 val r: 0.7797; time: 0.94sec
[674/800][24/24] total train loss: 0.0075; total val loss: 0.4774 val r: 0.7795; time: 0.94sec
[675/800][24/24] total train loss: 0.0076; total val loss: 0.4685 val r: 0.7801; time: 0.94sec
[676/800][24/24] total train loss: 0.0074; total val loss: 0.4703 val r: 0.7791; time: 0.94sec
[677/800][24/24] total train loss: 0.0072; total val loss: 0.4898 val r: 0.7799; time: 0.95sec
[678/800][24/24] total train loss: 0.0073; total val loss: 0.4758 val r: 0.7805; time: 0.94sec
[679/800][24/24] total train loss: 0.0075; total val loss: 0.4722 val r: 0.7836; time: 0.94sec
[680/800][24/24] total train loss: 0.0076; total val loss: 0.4787 val r: 0.7808; time: 0.94sec
[681/800][24/24] total train loss: 0.0075; total val loss: 0.4648 val r: 0.7823; time: 0.95sec
[682/800][24/24] total train loss: 0.0072; total val loss: 0.4645 val r: 0.7778; time: 0.94sec
[683/800][24/24] total train loss: 0.0076; total val loss: 0.4627 val r: 0.7802; time: 0.94sec
[684/800][24/24] total train loss: 0.0074; total val loss: 0.4316 val r: 0.7785; time: 0.95sec
[685/800][24/24] total train loss: 0.0073; total val loss: 0.4703 val r: 0.7784; time: 0.95sec
[686/800][24/24] total train loss: 0.0073; total val loss: 0.4648 val r: 0.7803; time: 0.94sec
[687/800][24/24] total train loss: 0.0075; total val loss: 0.4813 val r: 0.7816; time: 0.95sec
[688/800][24/24] total train loss: 0.0077; total val loss: 0.4588 val r: 0.7765; time: 0.96sec
[689/800][24/24] total train loss: 0.0080; total val loss: 0.4707 val r: 0.7785; time: 0.95sec
[690/800][24/24] total train loss: 0.0076; total val loss: 0.4447 val r: 0.7741; time: 0.95sec
[691/800][24/24] total train loss: 0.0073; total val loss: 0.4687 val r: 0.7792; time: 0.94sec
[692/800][24/24] total train loss: 0.0072; total val loss: 0.4710 val r: 0.7800; time: 0.94sec
[693/800][24/24] total train loss: 0.0072; total val loss: 0.4407 val r: 0.7766; time: 0.94sec
[694/800][24/24] total train loss: 0.0073; total val loss: 0.4582 val r: 0.7776; time: 0.95sec
[695/800][24/24] total train loss: 0.0075; total val loss: 0.4716 val r: 0.7793; time: 0.94sec
[696/800][24/24] total train loss: 0.0077; total val loss: 0.4679 val r: 0.7786; time: 0.94sec
[697/800][24/24] total train loss: 0.0073; total val loss: 0.4558 val r: 0.7792; time: 0.94sec
[698/800][24/24] total train loss: 0.0077; total val loss: 0.4694 val r: 0.7797; time: 0.94sec
[699/800][24/24] total train loss: 0.0074; total val loss: 0.4683 val r: 0.7769; time: 0.94sec
learning rate updated: 0.001
[700/800][24/24] total train loss: 0.0073; total val loss: 0.4650 val r: 0.7780; time: 0.94sec
[701/800][24/24] total train loss: 0.0073; total val loss: 0.4771 val r: 0.7778; time: 0.94sec
[702/800][24/24] total train loss: 0.0073; total val loss: 0.4629 val r: 0.7787; time: 0.95sec
[703/800][24/24] total train loss: 0.0072; total val loss: 0.4802 val r: 0.7835; time: 0.94sec
[704/800][24/24] total train loss: 0.0074; total val loss: 0.4618 val r: 0.7807; time: 0.94sec
[705/800][24/24] total train loss: 0.0074; total val loss: 0.4575 val r: 0.7797; time: 0.95sec
[706/800][24/24] total train loss: 0.0072; total val loss: 0.4683 val r: 0.7796; time: 0.94sec
[707/800][24/24] total train loss: 0.0073; total val loss: 0.4550 val r: 0.7798; time: 0.94sec
[708/800][24/24] total train loss: 0.0075; total val loss: 0.4618 val r: 0.7764; time: 0.94sec
[709/800][24/24] total train loss: 0.0074; total val loss: 0.4702 val r: 0.7784; time: 0.94sec
[710/800][24/24] total train loss: 0.0075; total val loss: 0.4761 val r: 0.7793; time: 0.95sec
[711/800][24/24] total train loss: 0.0074; total val loss: 0.4576 val r: 0.7782; time: 0.95sec
[712/800][24/24] total train loss: 0.0076; total val loss: 0.4614 val r: 0.7752; time: 0.94sec
[713/800][24/24] total train loss: 0.0073; total val loss: 0.4708 val r: 0.7805; time: 0.94sec
[714/800][24/24] total train loss: 0.0072; total val loss: 0.4490 val r: 0.7763; time: 0.95sec
[715/800][24/24] total train loss: 0.0072; total val loss: 0.4594 val r: 0.7833; time: 0.95sec
[716/800][24/24] total train loss: 0.0074; total val loss: 0.4752 val r: 0.7733; time: 0.94sec
[717/800][24/24] total train loss: 0.0073; total val loss: 0.4845 val r: 0.7833; time: 0.95sec
[718/800][24/24] total train loss: 0.0074; total val loss: 0.4622 val r: 0.7824; time: 0.94sec
[719/800][24/24] total train loss: 0.0073; total val loss: 0.4659 val r: 0.7791; time: 0.94sec
[720/800][24/24] total train loss: 0.0074; total val loss: 0.4864 val r: 0.7816; time: 0.95sec
[721/800][24/24] total train loss: 0.0077; total val loss: 0.4733 val r: 0.7788; time: 0.95sec
[722/800][24/24] total train loss: 0.0076; total val loss: 0.4696 val r: 0.7805; time: 0.95sec
[723/800][24/24] total train loss: 0.0076; total val loss: 0.4679 val r: 0.7801; time: 0.94sec
[724/800][24/24] total train loss: 0.0078; total val loss: 0.4656 val r: 0.7809; time: 0.94sec
[725/800][24/24] total train loss: 0.0072; total val loss: 0.4681 val r: 0.7790; time: 0.94sec
[726/800][24/24] total train loss: 0.0072; total val loss: 0.4727 val r: 0.7829; time: 0.94sec
[727/800][24/24] total train loss: 0.0074; total val loss: 0.4716 val r: 0.7834; time: 0.95sec
[728/800][24/24] total train loss: 0.0073; total val loss: 0.4747 val r: 0.7787; time: 0.94sec
[729/800][24/24] total train loss: 0.0073; total val loss: 0.4728 val r: 0.7760; time: 0.94sec
[730/800][24/24] total train loss: 0.0073; total val loss: 0.4607 val r: 0.7793; time: 0.95sec
[731/800][24/24] total train loss: 0.0074; total val loss: 0.4718 val r: 0.7826; time: 0.94sec
[732/800][24/24] total train loss: 0.0075; total val loss: 0.4767 val r: 0.7783; time: 0.95sec
[733/800][24/24] total train loss: 0.0075; total val loss: 0.4712 val r: 0.7783; time: 0.94sec
[734/800][24/24] total train loss: 0.0074; total val loss: 0.4555 val r: 0.7807; time: 0.95sec
[735/800][24/24] total train loss: 0.0076; total val loss: 0.4594 val r: 0.7797; time: 0.95sec
[736/800][24/24] total train loss: 0.0074; total val loss: 0.4580 val r: 0.7798; time: 0.94sec
[737/800][24/24] total train loss: 0.0075; total val loss: 0.4631 val r: 0.7823; time: 0.95sec
[738/800][24/24] total train loss: 0.0075; total val loss: 0.4640 val r: 0.7775; time: 0.95sec
[739/800][24/24] total train loss: 0.0074; total val loss: 0.4673 val r: 0.7815; time: 0.94sec
[740/800][24/24] total train loss: 0.0075; total val loss: 0.4681 val r: 0.7830; time: 0.94sec
[741/800][24/24] total train loss: 0.0073; total val loss: 0.4649 val r: 0.7755; time: 0.94sec
[742/800][24/24] total train loss: 0.0072; total val loss: 0.4693 val r: 0.7763; time: 0.95sec
[743/800][24/24] total train loss: 0.0073; total val loss: 0.4496 val r: 0.7764; time: 0.95sec
[744/800][24/24] total train loss: 0.0075; total val loss: 0.4837 val r: 0.7814; time: 0.94sec
[745/800][24/24] total train loss: 0.0073; total val loss: 0.4628 val r: 0.7799; time: 0.94sec
[746/800][24/24] total train loss: 0.0075; total val loss: 0.4530 val r: 0.7725; time: 0.94sec
[747/800][24/24] total train loss: 0.0073; total val loss: 0.4615 val r: 0.7790; time: 0.95sec
[748/800][24/24] total train loss: 0.0073; total val loss: 0.4804 val r: 0.7790; time: 0.95sec
[749/800][24/24] total train loss: 0.0073; total val loss: 0.4645 val r: 0.7833; time: 0.94sec
[750/800][24/24] total train loss: 0.0075; total val loss: 0.4741 val r: 0.7823; time: 0.95sec
[751/800][24/24] total train loss: 0.0075; total val loss: 0.4711 val r: 0.7768; time: 0.94sec
[752/800][24/24] total train loss: 0.0072; total val loss: 0.4690 val r: 0.7766; time: 0.94sec
[753/800][24/24] total train loss: 0.0074; total val loss: 0.4651 val r: 0.7781; time: 0.94sec
[754/800][24/24] total train loss: 0.0071; total val loss: 0.4741 val r: 0.7791; time: 0.95sec
[755/800][24/24] total train loss: 0.0073; total val loss: 0.4622 val r: 0.7806; time: 0.95sec
[756/800][24/24] total train loss: 0.0072; total val loss: 0.4788 val r: 0.7842; time: 0.94sec
[757/800][24/24] total train loss: 0.0071; total val loss: 0.4644 val r: 0.7834; time: 0.94sec
[758/800][24/24] total train loss: 0.0070; total val loss: 0.4629 val r: 0.7809; time: 0.95sec
[759/800][24/24] total train loss: 0.0074; total val loss: 0.4746 val r: 0.7809; time: 0.95sec
[760/800][24/24] total train loss: 0.0072; total val loss: 0.4732 val r: 0.7801; time: 0.93sec
[761/800][24/24] total train loss: 0.0071; total val loss: 0.4520 val r: 0.7806; time: 0.94sec
[762/800][24/24] total train loss: 0.0075; total val loss: 0.4677 val r: 0.7747; time: 0.94sec
[763/800][24/24] total train loss: 0.0074; total val loss: 0.4680 val r: 0.7846; time: 0.94sec
[764/800][24/24] total train loss: 0.0075; total val loss: 0.4649 val r: 0.7805; time: 0.93sec
[765/800][24/24] total train loss: 0.0075; total val loss: 0.4626 val r: 0.7827; time: 0.94sec
[766/800][24/24] total train loss: 0.0075; total val loss: 0.4728 val r: 0.7834; time: 0.95sec
[767/800][24/24] total train loss: 0.0076; total val loss: 0.4504 val r: 0.7833; time: 0.94sec
[768/800][24/24] total train loss: 0.0072; total val loss: 0.4574 val r: 0.7830; time: 0.94sec
[769/800][24/24] total train loss: 0.0074; total val loss: 0.4781 val r: 0.7839; time: 0.95sec
[770/800][24/24] total train loss: 0.0074; total val loss: 0.4598 val r: 0.7787; time: 0.94sec
[771/800][24/24] total train loss: 0.0071; total val loss: 0.4638 val r: 0.7802; time: 0.95sec
[772/800][24/24] total train loss: 0.0076; total val loss: 0.4736 val r: 0.7760; time: 0.94sec
[773/800][24/24] total train loss: 0.0072; total val loss: 0.4476 val r: 0.7807; time: 0.95sec
[774/800][24/24] total train loss: 0.0072; total val loss: 0.4809 val r: 0.7793; time: 0.94sec
[775/800][24/24] total train loss: 0.0071; total val loss: 0.4703 val r: 0.7787; time: 0.95sec
[776/800][24/24] total train loss: 0.0071; total val loss: 0.4807 val r: 0.7844; time: 0.95sec
[777/800][24/24] total train loss: 0.0075; total val loss: 0.4756 val r: 0.7781; time: 0.95sec
[778/800][24/24] total train loss: 0.0072; total val loss: 0.4702 val r: 0.7783; time: 0.95sec
[779/800][24/24] total train loss: 0.0075; total val loss: 0.4641 val r: 0.7786; time: 0.95sec
[780/800][24/24] total train loss: 0.0070; total val loss: 0.4663 val r: 0.7773; time: 0.94sec
[781/800][24/24] total train loss: 0.0072; total val loss: 0.4832 val r: 0.7798; time: 0.94sec
[782/800][24/24] total train loss: 0.0073; total val loss: 0.4658 val r: 0.7801; time: 0.94sec
[783/800][24/24] total train loss: 0.0071; total val loss: 0.4606 val r: 0.7760; time: 0.95sec
[784/800][24/24] total train loss: 0.0073; total val loss: 0.4622 val r: 0.7797; time: 0.95sec
[785/800][24/24] total train loss: 0.0073; total val loss: 0.4675 val r: 0.7803; time: 0.94sec
[786/800][24/24] total train loss: 0.0072; total val loss: 0.4780 val r: 0.7808; time: 0.94sec
[787/800][24/24] total train loss: 0.0072; total val loss: 0.4692 val r: 0.7830; time: 0.94sec
[788/800][24/24] total train loss: 0.0074; total val loss: 0.4780 val r: 0.7798; time: 0.94sec
[789/800][24/24] total train loss: 0.0070; total val loss: 0.4664 val r: 0.7817; time: 0.94sec
[790/800][24/24] total train loss: 0.0073; total val loss: 0.4716 val r: 0.7826; time: 0.95sec
[791/800][24/24] total train loss: 0.0074; total val loss: 0.4633 val r: 0.7762; time: 0.94sec
[792/800][24/24] total train loss: 0.0076; total val loss: 0.4578 val r: 0.7768; time: 0.94sec
[793/800][24/24] total train loss: 0.0075; total val loss: 0.4761 val r: 0.7841; time: 0.94sec
[794/800][24/24] total train loss: 0.0072; total val loss: 0.4678 val r: 0.7801; time: 0.96sec
[795/800][24/24] total train loss: 0.0074; total val loss: 0.4830 val r: 0.7833; time: 0.94sec
[796/800][24/24] total train loss: 0.0076; total val loss: 0.4634 val r: 0.7808; time: 0.95sec
[797/800][24/24] total train loss: 0.0076; total val loss: 0.4611 val r: 0.7781; time: 0.94sec
[798/800][24/24] total train loss: 0.0073; total val loss: 0.4798 val r: 0.7835; time: 0.94sec
[799/800][24/24] total train loss: 0.0072; total val loss: 0.4604 val r: 0.7815; time: 0.95sec
learning rate updated: 0.001
[800/800][24/24] total train loss: 0.0073; total val loss: 0.4647 val r: 0.7737; time: 0.94sec
Best epoch 491 with val_r = 0.7895.
Fold #3
- - - - - - - - - - - - -
initializing neural net
[1/800][24/24] total train loss: 1.2022; total val loss: 0.4361 val r: 0.6449; time: 0.98sec
[2/800][24/24] total train loss: 0.6624; total val loss: 0.4306 val r: 0.7361; time: 0.94sec
[3/800][24/24] total train loss: 0.4559; total val loss: 0.4670 val r: 0.7450; time: 0.94sec
[4/800][24/24] total train loss: 0.3381; total val loss: 0.4807 val r: 0.7311; time: 0.94sec
[5/800][24/24] total train loss: 0.2391; total val loss: 0.5579 val r: 0.7256; time: 0.94sec
[6/800][24/24] total train loss: 0.1453; total val loss: 0.5345 val r: 0.7147; time: 0.95sec
[7/800][24/24] total train loss: 0.1062; total val loss: 0.4592 val r: 0.7197; time: 0.95sec
[8/800][24/24] total train loss: 0.1008; total val loss: 0.4949 val r: 0.7260; time: 0.95sec
[9/800][24/24] total train loss: 0.0692; total val loss: 0.5021 val r: 0.7350; time: 0.93sec
[10/800][24/24] total train loss: 0.0486; total val loss: 0.4960 val r: 0.7413; time: 0.95sec
[11/800][24/24] total train loss: 0.0442; total val loss: 0.5083 val r: 0.7433; time: 0.95sec
[12/800][24/24] total train loss: 0.0301; total val loss: 0.5052 val r: 0.7340; time: 0.95sec
[13/800][24/24] total train loss: 0.0246; total val loss: 0.4920 val r: 0.7376; time: 0.95sec
[14/800][24/24] total train loss: 0.0234; total val loss: 0.5027 val r: 0.7370; time: 0.95sec
[15/800][24/24] total train loss: 0.0229; total val loss: 0.5238 val r: 0.7505; time: 0.94sec
[16/800][24/24] total train loss: 0.0206; total val loss: 0.4851 val r: 0.7318; time: 0.95sec
[17/800][24/24] total train loss: 0.0192; total val loss: 0.5150 val r: 0.7337; time: 0.95sec
[18/800][24/24] total train loss: 0.0188; total val loss: 0.5234 val r: 0.7309; time: 0.95sec
[19/800][24/24] total train loss: 0.0222; total val loss: 0.5429 val r: 0.7418; time: 0.95sec
[20/800][24/24] total train loss: 0.0199; total val loss: 0.5071 val r: 0.7352; time: 0.94sec
[21/800][24/24] total train loss: 0.0167; total val loss: 0.5106 val r: 0.7333; time: 0.94sec
[22/800][24/24] total train loss: 0.0173; total val loss: 0.5257 val r: 0.7382; time: 0.95sec
[23/800][24/24] total train loss: 0.0160; total val loss: 0.5296 val r: 0.7358; time: 0.96sec
[24/800][24/24] total train loss: 0.0172; total val loss: 0.5054 val r: 0.7433; time: 0.95sec
[25/800][24/24] total train loss: 0.0170; total val loss: 0.4708 val r: 0.7412; time: 0.95sec
[26/800][24/24] total train loss: 0.0191; total val loss: 0.5094 val r: 0.7448; time: 0.95sec
[27/800][24/24] total train loss: 0.0193; total val loss: 0.5267 val r: 0.7470; time: 0.94sec
[28/800][24/24] total train loss: 0.0167; total val loss: 0.4952 val r: 0.7387; time: 0.95sec
[29/800][24/24] total train loss: 0.0175; total val loss: 0.4876 val r: 0.7357; time: 0.94sec
[30/800][24/24] total train loss: 0.0169; total val loss: 0.4944 val r: 0.7446; time: 0.95sec
[31/800][24/24] total train loss: 0.0166; total val loss: 0.5000 val r: 0.7401; time: 0.95sec
[32/800][24/24] total train loss: 0.0154; total val loss: 0.5088 val r: 0.7433; time: 0.95sec
[33/800][24/24] total train loss: 0.0138; total val loss: 0.4993 val r: 0.7438; time: 0.95sec
[34/800][24/24] total train loss: 0.0142; total val loss: 0.5223 val r: 0.7471; time: 0.95sec
[35/800][24/24] total train loss: 0.0160; total val loss: 0.4886 val r: 0.7422; time: 0.94sec
[36/800][24/24] total train loss: 0.0151; total val loss: 0.5015 val r: 0.7338; time: 0.95sec
[37/800][24/24] total train loss: 0.0157; total val loss: 0.4943 val r: 0.7443; time: 0.95sec
[38/800][24/24] total train loss: 0.0148; total val loss: 0.4994 val r: 0.7414; time: 0.95sec
[39/800][24/24] total train loss: 0.0148; total val loss: 0.5208 val r: 0.7496; time: 0.95sec
[40/800][24/24] total train loss: 0.0145; total val loss: 0.4988 val r: 0.7476; time: 0.95sec
[41/800][24/24] total train loss: 0.0131; total val loss: 0.5047 val r: 0.7461; time: 0.95sec
[42/800][24/24] total train loss: 0.0145; total val loss: 0.5087 val r: 0.7485; time: 0.94sec
[43/800][24/24] total train loss: 0.0160; total val loss: 0.5023 val r: 0.7414; time: 0.95sec
[44/800][24/24] total train loss: 0.0167; total val loss: 0.5042 val r: 0.7447; time: 0.95sec
[45/800][24/24] total train loss: 0.0146; total val loss: 0.4952 val r: 0.7471; time: 0.94sec
[46/800][24/24] total train loss: 0.0156; total val loss: 0.5172 val r: 0.7514; time: 0.95sec
[47/800][24/24] total train loss: 0.0144; total val loss: 0.4961 val r: 0.7450; time: 0.94sec
[48/800][24/24] total train loss: 0.0152; total val loss: 0.5320 val r: 0.7448; time: 0.95sec
[49/800][24/24] total train loss: 0.0158; total val loss: 0.5069 val r: 0.7429; time: 0.94sec
[50/800][24/24] total train loss: 0.0141; total val loss: 0.4944 val r: 0.7516; time: 0.94sec
[51/800][24/24] total train loss: 0.0141; total val loss: 0.5158 val r: 0.7459; time: 0.94sec
[52/800][24/24] total train loss: 0.0139; total val loss: 0.4949 val r: 0.7464; time: 0.94sec
[53/800][24/24] total train loss: 0.0160; total val loss: 0.5106 val r: 0.7462; time: 0.94sec
[54/800][24/24] total train loss: 0.0160; total val loss: 0.4755 val r: 0.7430; time: 0.93sec
[55/800][24/24] total train loss: 0.0137; total val loss: 0.4998 val r: 0.7516; time: 0.93sec
[56/800][24/24] total train loss: 0.0134; total val loss: 0.5029 val r: 0.7466; time: 0.94sec
[57/800][24/24] total train loss: 0.0121; total val loss: 0.5167 val r: 0.7492; time: 0.95sec
[58/800][24/24] total train loss: 0.0125; total val loss: 0.4958 val r: 0.7463; time: 0.95sec
[59/800][24/24] total train loss: 0.0127; total val loss: 0.4932 val r: 0.7422; time: 0.95sec
[60/800][24/24] total train loss: 0.0131; total val loss: 0.5063 val r: 0.7509; time: 0.96sec
[61/800][24/24] total train loss: 0.0141; total val loss: 0.4950 val r: 0.7511; time: 0.95sec
[62/800][24/24] total train loss: 0.0131; total val loss: 0.4979 val r: 0.7454; time: 0.95sec
[63/800][24/24] total train loss: 0.0132; total val loss: 0.5007 val r: 0.7466; time: 0.95sec
[64/800][24/24] total train loss: 0.0138; total val loss: 0.5036 val r: 0.7442; time: 0.94sec
[65/800][24/24] total train loss: 0.0139; total val loss: 0.5059 val r: 0.7532; time: 0.95sec
[66/800][24/24] total train loss: 0.0131; total val loss: 0.5039 val r: 0.7519; time: 0.95sec
[67/800][24/24] total train loss: 0.0131; total val loss: 0.4931 val r: 0.7442; time: 0.95sec
[68/800][24/24] total train loss: 0.0154; total val loss: 0.5233 val r: 0.7466; time: 0.95sec
[69/800][24/24] total train loss: 0.0151; total val loss: 0.4939 val r: 0.7527; time: 0.94sec
[70/800][24/24] total train loss: 0.0155; total val loss: 0.5042 val r: 0.7529; time: 0.94sec
[71/800][24/24] total train loss: 0.0150; total val loss: 0.5062 val r: 0.7539; time: 0.95sec
[72/800][24/24] total train loss: 0.0135; total val loss: 0.4839 val r: 0.7484; time: 0.96sec
[73/800][24/24] total train loss: 0.0126; total val loss: 0.4958 val r: 0.7405; time: 0.94sec
[74/800][24/24] total train loss: 0.0126; total val loss: 0.5269 val r: 0.7532; time: 0.94sec
[75/800][24/24] total train loss: 0.0150; total val loss: 0.4965 val r: 0.7512; time: 0.94sec
[76/800][24/24] total train loss: 0.0143; total val loss: 0.5104 val r: 0.7489; time: 0.94sec
[77/800][24/24] total train loss: 0.0138; total val loss: 0.4987 val r: 0.7513; time: 0.95sec
[78/800][24/24] total train loss: 0.0123; total val loss: 0.5098 val r: 0.7495; time: 0.95sec
[79/800][24/24] total train loss: 0.0148; total val loss: 0.4938 val r: 0.7505; time: 0.95sec
[80/800][24/24] total train loss: 0.0158; total val loss: 0.5286 val r: 0.7506; time: 0.95sec
[81/800][24/24] total train loss: 0.0148; total val loss: 0.4936 val r: 0.7514; time: 0.94sec
[82/800][24/24] total train loss: 0.0133; total val loss: 0.5041 val r: 0.7511; time: 0.95sec
[83/800][24/24] total train loss: 0.0134; total val loss: 0.4834 val r: 0.7554; time: 0.95sec
[84/800][24/24] total train loss: 0.0132; total val loss: 0.4717 val r: 0.7502; time: 0.94sec
[85/800][24/24] total train loss: 0.0138; total val loss: 0.4972 val r: 0.7528; time: 0.94sec
[86/800][24/24] total train loss: 0.0131; total val loss: 0.5009 val r: 0.7515; time: 0.94sec
[87/800][24/24] total train loss: 0.0119; total val loss: 0.4946 val r: 0.7514; time: 0.94sec
[88/800][24/24] total train loss: 0.0121; total val loss: 0.4997 val r: 0.7497; time: 0.94sec
[89/800][24/24] total train loss: 0.0116; total val loss: 0.5059 val r: 0.7492; time: 0.95sec
[90/800][24/24] total train loss: 0.0117; total val loss: 0.4995 val r: 0.7519; time: 0.96sec
[91/800][24/24] total train loss: 0.0121; total val loss: 0.5079 val r: 0.7557; time: 0.95sec
[92/800][24/24] total train loss: 0.0120; total val loss: 0.5088 val r: 0.7500; time: 0.95sec
[93/800][24/24] total train loss: 0.0122; total val loss: 0.4911 val r: 0.7559; time: 0.95sec
[94/800][24/24] total train loss: 0.0116; total val loss: 0.5065 val r: 0.7502; time: 0.94sec
[95/800][24/24] total train loss: 0.0117; total val loss: 0.5169 val r: 0.7566; time: 0.95sec
[96/800][24/24] total train loss: 0.0119; total val loss: 0.4920 val r: 0.7523; time: 0.94sec
[97/800][24/24] total train loss: 0.0126; total val loss: 0.5266 val r: 0.7539; time: 0.94sec
[98/800][24/24] total train loss: 0.0136; total val loss: 0.5179 val r: 0.7512; time: 0.94sec
[99/800][24/24] total train loss: 0.0131; total val loss: 0.4577 val r: 0.7501; time: 0.94sec
learning rate updated: 0.001
[100/800][24/24] total train loss: 0.0124; total val loss: 0.5045 val r: 0.7519; time: 0.95sec
[101/800][24/24] total train loss: 0.0122; total val loss: 0.5102 val r: 0.7491; time: 0.95sec
[102/800][24/24] total train loss: 0.0120; total val loss: 0.5093 val r: 0.7541; time: 0.95sec
[103/800][24/24] total train loss: 0.0121; total val loss: 0.5040 val r: 0.7556; time: 0.95sec
[104/800][24/24] total train loss: 0.0121; total val loss: 0.4950 val r: 0.7536; time: 0.95sec
[105/800][24/24] total train loss: 0.0121; total val loss: 0.4815 val r: 0.7527; time: 0.94sec
[106/800][24/24] total train loss: 0.0116; total val loss: 0.5001 val r: 0.7490; time: 0.95sec
[107/800][24/24] total train loss: 0.0123; total val loss: 0.5057 val r: 0.7512; time: 0.95sec
[108/800][24/24] total train loss: 0.0118; total val loss: 0.4892 val r: 0.7516; time: 0.94sec
[109/800][24/24] total train loss: 0.0116; total val loss: 0.5199 val r: 0.7533; time: 0.95sec
[110/800][24/24] total train loss: 0.0116; total val loss: 0.5024 val r: 0.7513; time: 0.95sec
[111/800][24/24] total train loss: 0.0106; total val loss: 0.4998 val r: 0.7554; time: 0.95sec
[112/800][24/24] total train loss: 0.0112; total val loss: 0.4898 val r: 0.7497; time: 0.95sec
[113/800][24/24] total train loss: 0.0122; total val loss: 0.5048 val r: 0.7529; time: 0.95sec
[114/800][24/24] total train loss: 0.0114; total val loss: 0.5009 val r: 0.7553; time: 0.95sec
[115/800][24/24] total train loss: 0.0111; total val loss: 0.4729 val r: 0.7551; time: 0.94sec
[116/800][24/24] total train loss: 0.0109; total val loss: 0.4757 val r: 0.7506; time: 0.94sec
[117/800][24/24] total train loss: 0.0111; total val loss: 0.5097 val r: 0.7530; time: 0.94sec
[118/800][24/24] total train loss: 0.0117; total val loss: 0.4858 val r: 0.7569; time: 0.95sec
[119/800][24/24] total train loss: 0.0120; total val loss: 0.4916 val r: 0.7492; time: 0.94sec
[120/800][24/24] total train loss: 0.0119; total val loss: 0.5212 val r: 0.7539; time: 0.96sec
[121/800][24/24] total train loss: 0.0115; total val loss: 0.5049 val r: 0.7512; time: 0.95sec
[122/800][24/24] total train loss: 0.0110; total val loss: 0.5131 val r: 0.7534; time: 0.95sec
[123/800][24/24] total train loss: 0.0110; total val loss: 0.5028 val r: 0.7506; time: 0.94sec
[124/800][24/24] total train loss: 0.0120; total val loss: 0.5157 val r: 0.7526; time: 0.95sec
[125/800][24/24] total train loss: 0.0121; total val loss: 0.5124 val r: 0.7528; time: 0.95sec
[126/800][24/24] total train loss: 0.0127; total val loss: 0.5114 val r: 0.7546; time: 0.95sec
[127/800][24/24] total train loss: 0.0125; total val loss: 0.5014 val r: 0.7567; time: 0.95sec
[128/800][24/24] total train loss: 0.0114; total val loss: 0.5011 val r: 0.7511; time: 0.95sec
[129/800][24/24] total train loss: 0.0118; total val loss: 0.5154 val r: 0.7523; time: 0.95sec
[130/800][24/24] total train loss: 0.0121; total val loss: 0.4932 val r: 0.7522; time: 0.95sec
[131/800][24/24] total train loss: 0.0117; total val loss: 0.4939 val r: 0.7532; time: 0.94sec
[132/800][24/24] total train loss: 0.0107; total val loss: 0.4994 val r: 0.7515; time: 0.94sec
[133/800][24/24] total train loss: 0.0109; total val loss: 0.4954 val r: 0.7492; time: 0.93sec
[134/800][24/24] total train loss: 0.0115; total val loss: 0.5008 val r: 0.7520; time: 0.94sec
[135/800][24/24] total train loss: 0.0110; total val loss: 0.4931 val r: 0.7476; time: 0.94sec
[136/800][24/24] total train loss: 0.0115; total val loss: 0.5059 val r: 0.7502; time: 0.94sec
[137/800][24/24] total train loss: 0.0109; total val loss: 0.4993 val r: 0.7540; time: 0.95sec
[138/800][24/24] total train loss: 0.0104; total val loss: 0.5160 val r: 0.7584; time: 0.95sec
[139/800][24/24] total train loss: 0.0108; total val loss: 0.5153 val r: 0.7556; time: 0.95sec
[140/800][24/24] total train loss: 0.0109; total val loss: 0.5128 val r: 0.7590; time: 0.95sec
[141/800][24/24] total train loss: 0.0111; total val loss: 0.5080 val r: 0.7528; time: 0.95sec
[142/800][24/24] total train loss: 0.0120; total val loss: 0.5227 val r: 0.7465; time: 0.95sec
[143/800][24/24] total train loss: 0.0125; total val loss: 0.5006 val r: 0.7560; time: 0.94sec
[144/800][24/24] total train loss: 0.0123; total val loss: 0.4895 val r: 0.7588; time: 0.94sec
[145/800][24/24] total train loss: 0.0115; total val loss: 0.5079 val r: 0.7537; time: 0.95sec
[146/800][24/24] total train loss: 0.0123; total val loss: 0.4931 val r: 0.7571; time: 0.94sec
[147/800][24/24] total train loss: 0.0119; total val loss: 0.4953 val r: 0.7575; time: 0.95sec
[148/800][24/24] total train loss: 0.0120; total val loss: 0.4909 val r: 0.7540; time: 0.94sec
[149/800][24/24] total train loss: 0.0119; total val loss: 0.4758 val r: 0.7501; time: 0.95sec
[150/800][24/24] total train loss: 0.0117; total val loss: 0.5040 val r: 0.7548; time: 0.95sec
[151/800][24/24] total train loss: 0.0119; total val loss: 0.5118 val r: 0.7604; time: 0.94sec
[152/800][24/24] total train loss: 0.0117; total val loss: 0.5131 val r: 0.7532; time: 0.94sec
[153/800][24/24] total train loss: 0.0111; total val loss: 0.4976 val r: 0.7543; time: 0.95sec
[154/800][24/24] total train loss: 0.0112; total val loss: 0.4913 val r: 0.7582; time: 0.94sec
[155/800][24/24] total train loss: 0.0113; total val loss: 0.5351 val r: 0.7559; time: 0.95sec
[156/800][24/24] total train loss: 0.0125; total val loss: 0.4762 val r: 0.7489; time: 0.96sec
[157/800][24/24] total train loss: 0.0142; total val loss: 0.4982 val r: 0.7502; time: 0.95sec
[158/800][24/24] total train loss: 0.0123; total val loss: 0.5015 val r: 0.7540; time: 0.96sec
[159/800][24/24] total train loss: 0.0113; total val loss: 0.5074 val r: 0.7556; time: 0.95sec
[160/800][24/24] total train loss: 0.0103; total val loss: 0.5007 val r: 0.7525; time: 0.96sec
[161/800][24/24] total train loss: 0.0106; total val loss: 0.5085 val r: 0.7527; time: 0.95sec
[162/800][24/24] total train loss: 0.0104; total val loss: 0.4961 val r: 0.7568; time: 0.94sec
[163/800][24/24] total train loss: 0.0106; total val loss: 0.5018 val r: 0.7550; time: 0.94sec
[164/800][24/24] total train loss: 0.0106; total val loss: 0.5108 val r: 0.7500; time: 0.95sec
[165/800][24/24] total train loss: 0.0109; total val loss: 0.5033 val r: 0.7519; time: 0.95sec
[166/800][24/24] total train loss: 0.0115; total val loss: 0.4946 val r: 0.7548; time: 0.94sec
[167/800][24/24] total train loss: 0.0111; total val loss: 0.4863 val r: 0.7545; time: 0.95sec
[168/800][24/24] total train loss: 0.0112; total val loss: 0.4895 val r: 0.7545; time: 0.95sec
[169/800][24/24] total train loss: 0.0114; total val loss: 0.4906 val r: 0.7550; time: 0.95sec
[170/800][24/24] total train loss: 0.0113; total val loss: 0.5258 val r: 0.7599; time: 0.95sec
[171/800][24/24] total train loss: 0.0109; total val loss: 0.4938 val r: 0.7528; time: 0.95sec
[172/800][24/24] total train loss: 0.0109; total val loss: 0.5043 val r: 0.7587; time: 0.95sec
[173/800][24/24] total train loss: 0.0106; total val loss: 0.4996 val r: 0.7548; time: 0.95sec
[174/800][24/24] total train loss: 0.0101; total val loss: 0.4997 val r: 0.7528; time: 0.95sec
[175/800][24/24] total train loss: 0.0103; total val loss: 0.5175 val r: 0.7566; time: 0.95sec
[176/800][24/24] total train loss: 0.0106; total val loss: 0.4908 val r: 0.7518; time: 0.94sec
[177/800][24/24] total train loss: 0.0107; total val loss: 0.5092 val r: 0.7569; time: 0.95sec
[178/800][24/24] total train loss: 0.0101; total val loss: 0.4992 val r: 0.7568; time: 0.96sec
[179/800][24/24] total train loss: 0.0106; total val loss: 0.5071 val r: 0.7525; time: 0.95sec
[180/800][24/24] total train loss: 0.0101; total val loss: 0.5099 val r: 0.7558; time: 0.96sec
[181/800][24/24] total train loss: 0.0103; total val loss: 0.5057 val r: 0.7566; time: 0.94sec
[182/800][24/24] total train loss: 0.0110; total val loss: 0.4675 val r: 0.7569; time: 0.94sec
[183/800][24/24] total train loss: 0.0111; total val loss: 0.4815 val r: 0.7544; time: 0.95sec
[184/800][24/24] total train loss: 0.0117; total val loss: 0.5298 val r: 0.7596; time: 0.95sec
[185/800][24/24] total train loss: 0.0121; total val loss: 0.5267 val r: 0.7569; time: 0.94sec
[186/800][24/24] total train loss: 0.0118; total val loss: 0.5110 val r: 0.7577; time: 0.94sec
[187/800][24/24] total train loss: 0.0111; total val loss: 0.4982 val r: 0.7574; time: 0.95sec
[188/800][24/24] total train loss: 0.0105; total val loss: 0.5107 val r: 0.7573; time: 0.93sec
[189/800][24/24] total train loss: 0.0102; total val loss: 0.5052 val r: 0.7594; time: 0.95sec
[190/800][24/24] total train loss: 0.0101; total val loss: 0.5219 val r: 0.7609; time: 0.94sec
[191/800][24/24] total train loss: 0.0102; total val loss: 0.4769 val r: 0.7602; time: 0.95sec
[192/800][24/24] total train loss: 0.0102; total val loss: 0.5037 val r: 0.7598; time: 0.94sec
[193/800][24/24] total train loss: 0.0103; total val loss: 0.4976 val r: 0.7569; time: 0.94sec
[194/800][24/24] total train loss: 0.0105; total val loss: 0.4996 val r: 0.7552; time: 0.94sec
[195/800][24/24] total train loss: 0.0103; total val loss: 0.5104 val r: 0.7586; time: 0.95sec
[196/800][24/24] total train loss: 0.0106; total val loss: 0.4869 val r: 0.7545; time: 0.95sec
[197/800][24/24] total train loss: 0.0101; total val loss: 0.5035 val r: 0.7532; time: 0.94sec
[198/800][24/24] total train loss: 0.0107; total val loss: 0.5009 val r: 0.7595; time: 0.94sec
[199/800][24/24] total train loss: 0.0104; total val loss: 0.5146 val r: 0.7587; time: 0.96sec
learning rate updated: 0.001
[200/800][24/24] total train loss: 0.0105; total val loss: 0.4886 val r: 0.7576; time: 0.95sec
[201/800][24/24] total train loss: 0.0107; total val loss: 0.4982 val r: 0.7567; time: 0.94sec
[202/800][24/24] total train loss: 0.0104; total val loss: 0.4863 val r: 0.7590; time: 0.95sec
[203/800][24/24] total train loss: 0.0102; total val loss: 0.4955 val r: 0.7558; time: 0.95sec
[204/800][24/24] total train loss: 0.0105; total val loss: 0.5026 val r: 0.7582; time: 0.95sec
[205/800][24/24] total train loss: 0.0108; total val loss: 0.5286 val r: 0.7558; time: 0.95sec
[206/800][24/24] total train loss: 0.0105; total val loss: 0.4985 val r: 0.7536; time: 0.95sec
[207/800][24/24] total train loss: 0.0106; total val loss: 0.5093 val r: 0.7606; time: 0.96sec
[208/800][24/24] total train loss: 0.0102; total val loss: 0.4918 val r: 0.7567; time: 0.95sec
[209/800][24/24] total train loss: 0.0103; total val loss: 0.5013 val r: 0.7573; time: 0.94sec
[210/800][24/24] total train loss: 0.0105; total val loss: 0.5167 val r: 0.7594; time: 0.95sec
[211/800][24/24] total train loss: 0.0107; total val loss: 0.5018 val r: 0.7589; time: 0.95sec
[212/800][24/24] total train loss: 0.0104; total val loss: 0.5063 val r: 0.7590; time: 0.95sec
[213/800][24/24] total train loss: 0.0101; total val loss: 0.5015 val r: 0.7568; time: 0.94sec
[214/800][24/24] total train loss: 0.0101; total val loss: 0.5129 val r: 0.7587; time: 0.96sec
[215/800][24/24] total train loss: 0.0098; total val loss: 0.5099 val r: 0.7586; time: 0.94sec
[216/800][24/24] total train loss: 0.0097; total val loss: 0.5073 val r: 0.7571; time: 0.95sec
[217/800][24/24] total train loss: 0.0101; total val loss: 0.5107 val r: 0.7515; time: 0.95sec
[218/800][24/24] total train loss: 0.0102; total val loss: 0.4937 val r: 0.7537; time: 0.95sec
[219/800][24/24] total train loss: 0.0104; total val loss: 0.4941 val r: 0.7557; time: 0.94sec
[220/800][24/24] total train loss: 0.0102; total val loss: 0.5084 val r: 0.7563; time: 0.95sec
[221/800][24/24] total train loss: 0.0107; total val loss: 0.5111 val r: 0.7586; time: 0.95sec
[222/800][24/24] total train loss: 0.0108; total val loss: 0.5103 val r: 0.7587; time: 0.95sec
[223/800][24/24] total train loss: 0.0101; total val loss: 0.5005 val r: 0.7576; time: 0.95sec
[224/800][24/24] total train loss: 0.0113; total val loss: 0.5046 val r: 0.7571; time: 0.95sec
[225/800][24/24] total train loss: 0.0101; total val loss: 0.4959 val r: 0.7555; time: 0.95sec
[226/800][24/24] total train loss: 0.0098; total val loss: 0.5232 val r: 0.7549; time: 0.95sec
[227/800][24/24] total train loss: 0.0098; total val loss: 0.5029 val r: 0.7562; time: 0.94sec
[228/800][24/24] total train loss: 0.0100; total val loss: 0.4912 val r: 0.7578; time: 0.94sec
[229/800][24/24] total train loss: 0.0098; total val loss: 0.5157 val r: 0.7583; time: 0.95sec
[230/800][24/24] total train loss: 0.0099; total val loss: 0.5057 val r: 0.7617; time: 0.95sec
[231/800][24/24] total train loss: 0.0102; total val loss: 0.4892 val r: 0.7553; time: 0.94sec
[232/800][24/24] total train loss: 0.0101; total val loss: 0.5060 val r: 0.7593; time: 0.95sec
[233/800][24/24] total train loss: 0.0100; total val loss: 0.5159 val r: 0.7541; time: 0.94sec
[234/800][24/24] total train loss: 0.0104; total val loss: 0.4915 val r: 0.7602; time: 0.94sec
[235/800][24/24] total train loss: 0.0111; total val loss: 0.5068 val r: 0.7562; time: 0.95sec
[236/800][24/24] total train loss: 0.0100; total val loss: 0.4901 val r: 0.7541; time: 0.95sec
[237/800][24/24] total train loss: 0.0101; total val loss: 0.5015 val r: 0.7563; time: 0.95sec
[238/800][24/24] total train loss: 0.0108; total val loss: 0.5089 val r: 0.7511; time: 0.94sec
[239/800][24/24] total train loss: 0.0099; total val loss: 0.4940 val r: 0.7561; time: 0.94sec
[240/800][24/24] total train loss: 0.0100; total val loss: 0.5196 val r: 0.7565; time: 0.95sec
[241/800][24/24] total train loss: 0.0107; total val loss: 0.4978 val r: 0.7568; time: 0.95sec
[242/800][24/24] total train loss: 0.0105; total val loss: 0.5106 val r: 0.7614; time: 0.95sec
[243/800][24/24] total train loss: 0.0096; total val loss: 0.5129 val r: 0.7550; time: 0.94sec
[244/800][24/24] total train loss: 0.0096; total val loss: 0.4915 val r: 0.7567; time: 0.95sec
[245/800][24/24] total train loss: 0.0094; total val loss: 0.5204 val r: 0.7558; time: 0.95sec
[246/800][24/24] total train loss: 0.0097; total val loss: 0.5166 val r: 0.7583; time: 0.94sec
[247/800][24/24] total train loss: 0.0101; total val loss: 0.4969 val r: 0.7565; time: 0.95sec
[248/800][24/24] total train loss: 0.0100; total val loss: 0.5103 val r: 0.7555; time: 0.95sec
[249/800][24/24] total train loss: 0.0100; total val loss: 0.5234 val r: 0.7614; time: 0.94sec
[250/800][24/24] total train loss: 0.0105; total val loss: 0.5026 val r: 0.7565; time: 0.95sec
[251/800][24/24] total train loss: 0.0106; total val loss: 0.4790 val r: 0.7567; time: 0.95sec
[252/800][24/24] total train loss: 0.0103; total val loss: 0.5027 val r: 0.7536; time: 0.95sec
[253/800][24/24] total train loss: 0.0098; total val loss: 0.5059 val r: 0.7553; time: 0.94sec
[254/800][24/24] total train loss: 0.0095; total val loss: 0.5128 val r: 0.7550; time: 0.96sec
[255/800][24/24] total train loss: 0.0099; total val loss: 0.5124 val r: 0.7549; time: 0.94sec
[256/800][24/24] total train loss: 0.0103; total val loss: 0.5051 val r: 0.7575; time: 0.95sec
[257/800][24/24] total train loss: 0.0101; total val loss: 0.5026 val r: 0.7577; time: 0.94sec
[258/800][24/24] total train loss: 0.0100; total val loss: 0.5148 val r: 0.7571; time: 0.95sec
[259/800][24/24] total train loss: 0.0098; total val loss: 0.5165 val r: 0.7576; time: 0.95sec
[260/800][24/24] total train loss: 0.0101; total val loss: 0.5185 val r: 0.7551; time: 0.95sec
[261/800][24/24] total train loss: 0.0098; total val loss: 0.5140 val r: 0.7596; time: 0.95sec
[262/800][24/24] total train loss: 0.0099; total val loss: 0.5065 val r: 0.7569; time: 0.94sec
[263/800][24/24] total train loss: 0.0100; total val loss: 0.4934 val r: 0.7520; time: 0.95sec
[264/800][24/24] total train loss: 0.0101; total val loss: 0.4695 val r: 0.7567; time: 0.94sec
[265/800][24/24] total train loss: 0.0099; total val loss: 0.4955 val r: 0.7561; time: 0.95sec
[266/800][24/24] total train loss: 0.0102; total val loss: 0.5146 val r: 0.7579; time: 0.95sec
[267/800][24/24] total train loss: 0.0100; total val loss: 0.4985 val r: 0.7522; time: 0.95sec
[268/800][24/24] total train loss: 0.0101; total val loss: 0.5070 val r: 0.7545; time: 0.95sec
[269/800][24/24] total train loss: 0.0098; total val loss: 0.5102 val r: 0.7552; time: 0.95sec
[270/800][24/24] total train loss: 0.0105; total val loss: 0.4957 val r: 0.7523; time: 0.94sec
[271/800][24/24] total train loss: 0.0096; total val loss: 0.4986 val r: 0.7558; time: 0.94sec
[272/800][24/24] total train loss: 0.0098; total val loss: 0.4898 val r: 0.7594; time: 0.94sec
[273/800][24/24] total train loss: 0.0100; total val loss: 0.5057 val r: 0.7535; time: 0.94sec
[274/800][24/24] total train loss: 0.0099; total val loss: 0.5062 val r: 0.7590; time: 0.95sec
[275/800][24/24] total train loss: 0.0096; total val loss: 0.5000 val r: 0.7570; time: 0.94sec
[276/800][24/24] total train loss: 0.0099; total val loss: 0.5143 val r: 0.7584; time: 0.95sec
[277/800][24/24] total train loss: 0.0102; total val loss: 0.4943 val r: 0.7591; time: 0.95sec
[278/800][24/24] total train loss: 0.0096; total val loss: 0.5145 val r: 0.7571; time: 0.95sec
[279/800][24/24] total train loss: 0.0096; total val loss: 0.4921 val r: 0.7582; time: 0.94sec
[280/800][24/24] total train loss: 0.0102; total val loss: 0.5091 val r: 0.7584; time: 0.95sec
[281/800][24/24] total train loss: 0.0099; total val loss: 0.4963 val r: 0.7573; time: 0.95sec
[282/800][24/24] total train loss: 0.0097; total val loss: 0.5024 val r: 0.7558; time: 0.94sec
[283/800][24/24] total train loss: 0.0092; total val loss: 0.4861 val r: 0.7636; time: 0.95sec
[284/800][24/24] total train loss: 0.0098; total val loss: 0.5086 val r: 0.7499; time: 0.95sec
[285/800][24/24] total train loss: 0.0095; total val loss: 0.5080 val r: 0.7603; time: 0.95sec
[286/800][24/24] total train loss: 0.0092; total val loss: 0.5276 val r: 0.7592; time: 0.95sec
[287/800][24/24] total train loss: 0.0093; total val loss: 0.5110 val r: 0.7565; time: 0.95sec
[288/800][24/24] total train loss: 0.0094; total val loss: 0.5209 val r: 0.7542; time: 0.95sec
[289/800][24/24] total train loss: 0.0096; total val loss: 0.5281 val r: 0.7556; time: 0.95sec
[290/800][24/24] total train loss: 0.0099; total val loss: 0.4933 val r: 0.7514; time: 0.94sec
[291/800][24/24] total train loss: 0.0098; total val loss: 0.5040 val r: 0.7560; time: 0.95sec
[292/800][24/24] total train loss: 0.0096; total val loss: 0.4819 val r: 0.7583; time: 0.94sec
[293/800][24/24] total train loss: 0.0099; total val loss: 0.5023 val r: 0.7575; time: 0.95sec
[294/800][24/24] total train loss: 0.0100; total val loss: 0.4951 val r: 0.7526; time: 0.95sec
[295/800][24/24] total train loss: 0.0095; total val loss: 0.4927 val r: 0.7532; time: 0.95sec
[296/800][24/24] total train loss: 0.0093; total val loss: 0.4988 val r: 0.7567; time: 0.95sec
[297/800][24/24] total train loss: 0.0095; total val loss: 0.5040 val r: 0.7545; time: 0.94sec
[298/800][24/24] total train loss: 0.0098; total val loss: 0.4926 val r: 0.7540; time: 0.95sec
[299/800][24/24] total train loss: 0.0095; total val loss: 0.5121 val r: 0.7603; time: 0.94sec
learning rate updated: 0.001
[300/800][24/24] total train loss: 0.0098; total val loss: 0.5021 val r: 0.7550; time: 0.95sec
[301/800][24/24] total train loss: 0.0099; total val loss: 0.4982 val r: 0.7606; time: 0.95sec
[302/800][24/24] total train loss: 0.0099; total val loss: 0.5075 val r: 0.7536; time: 0.95sec
[303/800][24/24] total train loss: 0.0096; total val loss: 0.5062 val r: 0.7555; time: 0.95sec
[304/800][24/24] total train loss: 0.0096; total val loss: 0.5051 val r: 0.7563; time: 0.94sec
[305/800][24/24] total train loss: 0.0096; total val loss: 0.5103 val r: 0.7575; time: 0.95sec
[306/800][24/24] total train loss: 0.0097; total val loss: 0.5121 val r: 0.7521; time: 0.96sec
[307/800][24/24] total train loss: 0.0092; total val loss: 0.5155 val r: 0.7581; time: 0.95sec
[308/800][24/24] total train loss: 0.0094; total val loss: 0.5010 val r: 0.7486; time: 0.96sec
[309/800][24/24] total train loss: 0.0094; total val loss: 0.5013 val r: 0.7542; time: 0.94sec
[310/800][24/24] total train loss: 0.0094; total val loss: 0.5059 val r: 0.7572; time: 0.95sec
[311/800][24/24] total train loss: 0.0095; total val loss: 0.5152 val r: 0.7579; time: 0.95sec
[312/800][24/24] total train loss: 0.0095; total val loss: 0.5069 val r: 0.7553; time: 0.95sec
[313/800][24/24] total train loss: 0.0095; total val loss: 0.5048 val r: 0.7568; time: 0.94sec
[314/800][24/24] total train loss: 0.0097; total val loss: 0.5014 val r: 0.7545; time: 0.94sec
[315/800][24/24] total train loss: 0.0098; total val loss: 0.5035 val r: 0.7555; time: 0.94sec
[316/800][24/24] total train loss: 0.0099; total val loss: 0.5139 val r: 0.7569; time: 0.95sec
[317/800][24/24] total train loss: 0.0100; total val loss: 0.5163 val r: 0.7551; time: 0.95sec
[318/800][24/24] total train loss: 0.0100; total val loss: 0.5035 val r: 0.7592; time: 0.95sec
[319/800][24/24] total train loss: 0.0100; total val loss: 0.5036 val r: 0.7572; time: 0.94sec
[320/800][24/24] total train loss: 0.0095; total val loss: 0.4983 val r: 0.7551; time: 0.94sec
[321/800][24/24] total train loss: 0.0094; total val loss: 0.4993 val r: 0.7554; time: 0.95sec
[322/800][24/24] total train loss: 0.0093; total val loss: 0.4923 val r: 0.7599; time: 0.94sec
[323/800][24/24] total train loss: 0.0093; total val loss: 0.5250 val r: 0.7552; time: 0.94sec
[324/800][24/24] total train loss: 0.0092; total val loss: 0.5071 val r: 0.7553; time: 0.94sec
[325/800][24/24] total train loss: 0.0095; total val loss: 0.5238 val r: 0.7574; time: 0.95sec
[326/800][24/24] total train loss: 0.0094; total val loss: 0.5061 val r: 0.7561; time: 0.94sec
[327/800][24/24] total train loss: 0.0093; total val loss: 0.4961 val r: 0.7591; time: 0.95sec
[328/800][24/24] total train loss: 0.0094; total val loss: 0.5067 val r: 0.7534; time: 0.94sec
[329/800][24/24] total train loss: 0.0096; total val loss: 0.4940 val r: 0.7530; time: 0.94sec
[330/800][24/24] total train loss: 0.0095; total val loss: 0.5063 val r: 0.7555; time: 0.95sec
[331/800][24/24] total train loss: 0.0092; total val loss: 0.4875 val r: 0.7543; time: 0.95sec
[332/800][24/24] total train loss: 0.0095; total val loss: 0.4933 val r: 0.7599; time: 0.95sec
[333/800][24/24] total train loss: 0.0098; total val loss: 0.5033 val r: 0.7550; time: 0.95sec
[334/800][24/24] total train loss: 0.0096; total val loss: 0.4904 val r: 0.7578; time: 0.95sec
[335/800][24/24] total train loss: 0.0095; total val loss: 0.4951 val r: 0.7525; time: 0.95sec
[336/800][24/24] total train loss: 0.0098; total val loss: 0.4967 val r: 0.7571; time: 0.95sec
[337/800][24/24] total train loss: 0.0098; total val loss: 0.5050 val r: 0.7544; time: 0.95sec
[338/800][24/24] total train loss: 0.0092; total val loss: 0.4960 val r: 0.7601; time: 0.95sec
[339/800][24/24] total train loss: 0.0094; total val loss: 0.4988 val r: 0.7541; time: 0.94sec
[340/800][24/24] total train loss: 0.0093; total val loss: 0.5117 val r: 0.7561; time: 0.95sec
[341/800][24/24] total train loss: 0.0092; total val loss: 0.5048 val r: 0.7597; time: 0.95sec
[342/800][24/24] total train loss: 0.0095; total val loss: 0.5083 val r: 0.7508; time: 0.94sec
[343/800][24/24] total train loss: 0.0096; total val loss: 0.5184 val r: 0.7574; time: 0.94sec
[344/800][24/24] total train loss: 0.0095; total val loss: 0.5108 val r: 0.7553; time: 0.95sec
[345/800][24/24] total train loss: 0.0092; total val loss: 0.5147 val r: 0.7584; time: 0.94sec
[346/800][24/24] total train loss: 0.0090; total val loss: 0.5039 val r: 0.7548; time: 0.95sec
[347/800][24/24] total train loss: 0.0092; total val loss: 0.4687 val r: 0.7526; time: 0.95sec
[348/800][24/24] total train loss: 0.0090; total val loss: 0.4964 val r: 0.7519; time: 0.94sec
[349/800][24/24] total train loss: 0.0093; total val loss: 0.5076 val r: 0.7618; time: 0.95sec
[350/800][24/24] total train loss: 0.0094; total val loss: 0.5002 val r: 0.7600; time: 0.96sec
[351/800][24/24] total train loss: 0.0093; total val loss: 0.5101 val r: 0.7600; time: 0.95sec
[352/800][24/24] total train loss: 0.0097; total val loss: 0.5195 val r: 0.7597; time: 0.95sec
[353/800][24/24] total train loss: 0.0095; total val loss: 0.5052 val r: 0.7588; time: 0.95sec
[354/800][24/24] total train loss: 0.0093; total val loss: 0.5165 val r: 0.7531; time: 0.95sec
[355/800][24/24] total train loss: 0.0095; total val loss: 0.4948 val r: 0.7576; time: 0.95sec
[356/800][24/24] total train loss: 0.0096; total val loss: 0.5168 val r: 0.7618; time: 0.95sec
[357/800][24/24] total train loss: 0.0096; total val loss: 0.5071 val r: 0.7524; time: 0.95sec
[358/800][24/24] total train loss: 0.0091; total val loss: 0.5284 val r: 0.7595; time: 0.95sec
[359/800][24/24] total train loss: 0.0095; total val loss: 0.4977 val r: 0.7565; time: 0.95sec
[360/800][24/24] total train loss: 0.0094; total val loss: 0.5150 val r: 0.7567; time: 0.95sec
[361/800][24/24] total train loss: 0.0091; total val loss: 0.5066 val r: 0.7587; time: 0.95sec
[362/800][24/24] total train loss: 0.0095; total val loss: 0.5100 val r: 0.7585; time: 0.95sec
[363/800][24/24] total train loss: 0.0093; total val loss: 0.4961 val r: 0.7555; time: 0.95sec
[364/800][24/24] total train loss: 0.0094; total val loss: 0.5077 val r: 0.7564; time: 0.95sec
[365/800][24/24] total train loss: 0.0090; total val loss: 0.5154 val r: 0.7585; time: 0.95sec
[366/800][24/24] total train loss: 0.0099; total val loss: 0.5174 val r: 0.7577; time: 0.95sec
[367/800][24/24] total train loss: 0.0098; total val loss: 0.4999 val r: 0.7555; time: 0.95sec
[368/800][24/24] total train loss: 0.0094; total val loss: 0.5128 val r: 0.7620; time: 0.95sec
[369/800][24/24] total train loss: 0.0096; total val loss: 0.4994 val r: 0.7611; time: 0.95sec
[370/800][24/24] total train loss: 0.0092; total val loss: 0.5026 val r: 0.7574; time: 0.94sec
[371/800][24/24] total train loss: 0.0093; total val loss: 0.5090 val r: 0.7580; time: 0.94sec
[372/800][24/24] total train loss: 0.0091; total val loss: 0.5117 val r: 0.7534; time: 0.94sec
[373/800][24/24] total train loss: 0.0095; total val loss: 0.4930 val r: 0.7540; time: 0.94sec
[374/800][24/24] total train loss: 0.0093; total val loss: 0.5084 val r: 0.7580; time: 0.93sec
[375/800][24/24] total train loss: 0.0091; total val loss: 0.5196 val r: 0.7548; time: 0.94sec
[376/800][24/24] total train loss: 0.0091; total val loss: 0.5115 val r: 0.7560; time: 0.93sec
[377/800][24/24] total train loss: 0.0093; total val loss: 0.5037 val r: 0.7545; time: 0.93sec
[378/800][24/24] total train loss: 0.0096; total val loss: 0.5019 val r: 0.7614; time: 0.93sec
[379/800][24/24] total train loss: 0.0092; total val loss: 0.5114 val r: 0.7505; time: 0.95sec
[380/800][24/24] total train loss: 0.0095; total val loss: 0.5062 val r: 0.7554; time: 0.94sec
[381/800][24/24] total train loss: 0.0093; total val loss: 0.5371 val r: 0.7541; time: 0.95sec
[382/800][24/24] total train loss: 0.0100; total val loss: 0.5075 val r: 0.7538; time: 0.95sec
[383/800][24/24] total train loss: 0.0099; total val loss: 0.4835 val r: 0.7516; time: 0.95sec
[384/800][24/24] total train loss: 0.0092; total val loss: 0.5033 val r: 0.7576; time: 0.95sec
[385/800][24/24] total train loss: 0.0091; total val loss: 0.5206 val r: 0.7576; time: 0.94sec
[386/800][24/24] total train loss: 0.0095; total val loss: 0.5293 val r: 0.7612; time: 0.95sec
[387/800][24/24] total train loss: 0.0094; total val loss: 0.5040 val r: 0.7559; time: 0.95sec
[388/800][24/24] total train loss: 0.0095; total val loss: 0.5148 val r: 0.7563; time: 0.94sec
[389/800][24/24] total train loss: 0.0093; total val loss: 0.4977 val r: 0.7518; time: 0.95sec
[390/800][24/24] total train loss: 0.0089; total val loss: 0.5081 val r: 0.7583; time: 0.95sec
[391/800][24/24] total train loss: 0.0089; total val loss: 0.5101 val r: 0.7557; time: 0.94sec
[392/800][24/24] total train loss: 0.0094; total val loss: 0.5219 val r: 0.7548; time: 0.95sec
[393/800][24/24] total train loss: 0.0095; total val loss: 0.5132 val r: 0.7582; time: 0.96sec
[394/800][24/24] total train loss: 0.0095; total val loss: 0.5032 val r: 0.7520; time: 0.94sec
[395/800][24/24] total train loss: 0.0095; total val loss: 0.5107 val r: 0.7598; time: 0.95sec
[396/800][24/24] total train loss: 0.0094; total val loss: 0.4978 val r: 0.7537; time: 0.95sec
[397/800][24/24] total train loss: 0.0094; total val loss: 0.4890 val r: 0.7592; time: 0.95sec
[398/800][24/24] total train loss: 0.0094; total val loss: 0.4980 val r: 0.7573; time: 0.95sec
[399/800][24/24] total train loss: 0.0091; total val loss: 0.5113 val r: 0.7569; time: 0.95sec
learning rate updated: 0.001
[400/800][24/24] total train loss: 0.0089; total val loss: 0.5262 val r: 0.7589; time: 0.95sec
[401/800][24/24] total train loss: 0.0094; total val loss: 0.5154 val r: 0.7549; time: 0.95sec
[402/800][24/24] total train loss: 0.0092; total val loss: 0.4947 val r: 0.7532; time: 0.94sec
[403/800][24/24] total train loss: 0.0094; total val loss: 0.5182 val r: 0.7522; time: 0.94sec
[404/800][24/24] total train loss: 0.0091; total val loss: 0.5100 val r: 0.7494; time: 0.95sec
[405/800][24/24] total train loss: 0.0089; total val loss: 0.4930 val r: 0.7542; time: 0.95sec
[406/800][24/24] total train loss: 0.0091; total val loss: 0.5089 val r: 0.7511; time: 0.94sec
[407/800][24/24] total train loss: 0.0094; total val loss: 0.4835 val r: 0.7579; time: 0.94sec
[408/800][24/24] total train loss: 0.0093; total val loss: 0.4987 val r: 0.7525; time: 0.95sec
[409/800][24/24] total train loss: 0.0091; total val loss: 0.5147 val r: 0.7529; time: 0.94sec
[410/800][24/24] total train loss: 0.0092; total val loss: 0.5145 val r: 0.7558; time: 0.95sec
[411/800][24/24] total train loss: 0.0092; total val loss: 0.5046 val r: 0.7519; time: 0.95sec
[412/800][24/24] total train loss: 0.0090; total val loss: 0.4964 val r: 0.7516; time: 0.95sec
[413/800][24/24] total train loss: 0.0091; total val loss: 0.5049 val r: 0.7531; time: 0.95sec
[414/800][24/24] total train loss: 0.0089; total val loss: 0.5090 val r: 0.7516; time: 0.95sec
[415/800][24/24] total train loss: 0.0090; total val loss: 0.5009 val r: 0.7536; time: 0.95sec
[416/800][24/24] total train loss: 0.0091; total val loss: 0.5154 val r: 0.7533; time: 0.94sec
[417/800][24/24] total train loss: 0.0090; total val loss: 0.4989 val r: 0.7536; time: 0.95sec
[418/800][24/24] total train loss: 0.0095; total val loss: 0.5077 val r: 0.7599; time: 0.95sec
[419/800][24/24] total train loss: 0.0095; total val loss: 0.4850 val r: 0.7547; time: 0.95sec
[420/800][24/24] total train loss: 0.0091; total val loss: 0.5003 val r: 0.7571; time: 0.94sec
[421/800][24/24] total train loss: 0.0088; total val loss: 0.5045 val r: 0.7531; time: 0.95sec
[422/800][24/24] total train loss: 0.0088; total val loss: 0.5097 val r: 0.7521; time: 0.94sec
[423/800][24/24] total train loss: 0.0088; total val loss: 0.5032 val r: 0.7504; time: 0.94sec
[424/800][24/24] total train loss: 0.0091; total val loss: 0.5146 val r: 0.7503; time: 0.95sec
[425/800][24/24] total train loss: 0.0089; total val loss: 0.5143 val r: 0.7539; time: 0.94sec
[426/800][24/24] total train loss: 0.0090; total val loss: 0.4745 val r: 0.7562; time: 0.94sec
[427/800][24/24] total train loss: 0.0091; total val loss: 0.5164 val r: 0.7505; time: 0.94sec
[428/800][24/24] total train loss: 0.0093; total val loss: 0.5112 val r: 0.7533; time: 0.95sec
[429/800][24/24] total train loss: 0.0097; total val loss: 0.5007 val r: 0.7524; time: 0.95sec
[430/800][24/24] total train loss: 0.0095; total val loss: 0.4944 val r: 0.7525; time: 0.95sec
[431/800][24/24] total train loss: 0.0093; total val loss: 0.5065 val r: 0.7568; time: 0.95sec
[432/800][24/24] total train loss: 0.0092; total val loss: 0.5083 val r: 0.7488; time: 0.95sec
[433/800][24/24] total train loss: 0.0092; total val loss: 0.5047 val r: 0.7555; time: 0.94sec
[434/800][24/24] total train loss: 0.0093; total val loss: 0.4994 val r: 0.7511; time: 0.95sec
[435/800][24/24] total train loss: 0.0090; total val loss: 0.5178 val r: 0.7545; time: 0.95sec
[436/800][24/24] total train loss: 0.0088; total val loss: 0.5033 val r: 0.7522; time: 0.94sec
[437/800][24/24] total train loss: 0.0090; total val loss: 0.5269 val r: 0.7520; time: 0.95sec
[438/800][24/24] total train loss: 0.0090; total val loss: 0.5012 val r: 0.7501; time: 0.94sec
[439/800][24/24] total train loss: 0.0090; total val loss: 0.5055 val r: 0.7516; time: 0.94sec
[440/800][24/24] total train loss: 0.0087; total val loss: 0.5114 val r: 0.7516; time: 0.95sec
[441/800][24/24] total train loss: 0.0087; total val loss: 0.4981 val r: 0.7572; time: 0.95sec
[442/800][24/24] total train loss: 0.0089; total val loss: 0.5098 val r: 0.7540; time: 0.95sec
[443/800][24/24] total train loss: 0.0093; total val loss: 0.5096 val r: 0.7551; time: 0.95sec
[444/800][24/24] total train loss: 0.0089; total val loss: 0.5009 val r: 0.7568; time: 0.95sec
[445/800][24/24] total train loss: 0.0088; total val loss: 0.5147 val r: 0.7551; time: 0.95sec
[446/800][24/24] total train loss: 0.0094; total val loss: 0.5198 val r: 0.7530; time: 0.94sec
[447/800][24/24] total train loss: 0.0090; total val loss: 0.5171 val r: 0.7591; time: 0.94sec
[448/800][24/24] total train loss: 0.0093; total val loss: 0.5067 val r: 0.7503; time: 0.95sec
[449/800][24/24] total train loss: 0.0092; total val loss: 0.4935 val r: 0.7575; time: 0.94sec
[450/800][24/24] total train loss: 0.0090; total val loss: 0.5056 val r: 0.7514; time: 0.95sec
[451/800][24/24] total train loss: 0.0090; total val loss: 0.5037 val r: 0.7493; time: 0.94sec
[452/800][24/24] total train loss: 0.0091; total val loss: 0.5148 val r: 0.7480; time: 0.94sec
[453/800][24/24] total train loss: 0.0090; total val loss: 0.5126 val r: 0.7467; time: 0.94sec
[454/800][24/24] total train loss: 0.0090; total val loss: 0.4757 val r: 0.7537; time: 0.94sec
[455/800][24/24] total train loss: 0.0089; total val loss: 0.5004 val r: 0.7553; time: 0.96sec
[456/800][24/24] total train loss: 0.0089; total val loss: 0.5200 val r: 0.7580; time: 0.94sec
[457/800][24/24] total train loss: 0.0088; total val loss: 0.5118 val r: 0.7547; time: 0.95sec
[458/800][24/24] total train loss: 0.0089; total val loss: 0.5036 val r: 0.7552; time: 0.94sec
[459/800][24/24] total train loss: 0.0088; total val loss: 0.5060 val r: 0.7550; time: 0.94sec
[460/800][24/24] total train loss: 0.0092; total val loss: 0.5082 val r: 0.7566; time: 0.95sec
[461/800][24/24] total train loss: 0.0093; total val loss: 0.5318 val r: 0.7517; time: 0.95sec
[462/800][24/24] total train loss: 0.0093; total val loss: 0.5024 val r: 0.7566; time: 0.94sec
[463/800][24/24] total train loss: 0.0088; total val loss: 0.5007 val r: 0.7526; time: 0.95sec
[464/800][24/24] total train loss: 0.0091; total val loss: 0.5103 val r: 0.7543; time: 0.94sec
[465/800][24/24] total train loss: 0.0095; total val loss: 0.4986 val r: 0.7565; time: 0.95sec
[466/800][24/24] total train loss: 0.0091; total val loss: 0.5122 val r: 0.7520; time: 0.94sec
[467/800][24/24] total train loss: 0.0090; total val loss: 0.5102 val r: 0.7548; time: 0.94sec
[468/800][24/24] total train loss: 0.0091; total val loss: 0.5063 val r: 0.7520; time: 0.95sec
[469/800][24/24] total train loss: 0.0089; total val loss: 0.5013 val r: 0.7548; time: 0.95sec
[470/800][24/24] total train loss: 0.0089; total val loss: 0.5021 val r: 0.7536; time: 0.95sec
[471/800][24/24] total train loss: 0.0088; total val loss: 0.5283 val r: 0.7526; time: 0.95sec
[472/800][24/24] total train loss: 0.0089; total val loss: 0.4865 val r: 0.7503; time: 0.94sec
[473/800][24/24] total train loss: 0.0093; total val loss: 0.5143 val r: 0.7527; time: 0.95sec
[474/800][24/24] total train loss: 0.0090; total val loss: 0.5265 val r: 0.7566; time: 0.94sec
[475/800][24/24] total train loss: 0.0090; total val loss: 0.5037 val r: 0.7560; time: 0.95sec
[476/800][24/24] total train loss: 0.0089; total val loss: 0.5105 val r: 0.7562; time: 0.93sec
[477/800][24/24] total train loss: 0.0089; total val loss: 0.4892 val r: 0.7523; time: 0.94sec
[478/800][24/24] total train loss: 0.0089; total val loss: 0.5023 val r: 0.7513; time: 0.95sec
[479/800][24/24] total train loss: 0.0093; total val loss: 0.5055 val r: 0.7592; time: 0.95sec
[480/800][24/24] total train loss: 0.0091; total val loss: 0.5154 val r: 0.7512; time: 0.95sec
[481/800][24/24] total train loss: 0.0091; total val loss: 0.4994 val r: 0.7573; time: 0.94sec
[482/800][24/24] total train loss: 0.0091; total val loss: 0.5091 val r: 0.7538; time: 0.95sec
[483/800][24/24] total train loss: 0.0089; total val loss: 0.5089 val r: 0.7527; time: 0.94sec
[484/800][24/24] total train loss: 0.0089; total val loss: 0.5052 val r: 0.7533; time: 0.94sec
[485/800][24/24] total train loss: 0.0091; total val loss: 0.5222 val r: 0.7579; time: 0.95sec
[486/800][24/24] total train loss: 0.0091; total val loss: 0.5114 val r: 0.7560; time: 0.95sec
[487/800][24/24] total train loss: 0.0090; total val loss: 0.5132 val r: 0.7544; time: 0.95sec
[488/800][24/24] total train loss: 0.0089; total val loss: 0.5100 val r: 0.7513; time: 0.95sec
[489/800][24/24] total train loss: 0.0089; total val loss: 0.5120 val r: 0.7513; time: 0.94sec
[490/800][24/24] total train loss: 0.0089; total val loss: 0.4992 val r: 0.7516; time: 0.95sec
[491/800][24/24] total train loss: 0.0093; total val loss: 0.5003 val r: 0.7556; time: 0.94sec
[492/800][24/24] total train loss: 0.0091; total val loss: 0.5161 val r: 0.7537; time: 0.94sec
[493/800][24/24] total train loss: 0.0090; total val loss: 0.5138 val r: 0.7586; time: 0.94sec
[494/800][24/24] total train loss: 0.0092; total val loss: 0.4975 val r: 0.7569; time: 0.95sec
[495/800][24/24] total train loss: 0.0090; total val loss: 0.5089 val r: 0.7528; time: 0.95sec
[496/800][24/24] total train loss: 0.0089; total val loss: 0.5117 val r: 0.7547; time: 0.95sec
[497/800][24/24] total train loss: 0.0088; total val loss: 0.5309 val r: 0.7526; time: 0.95sec
[498/800][24/24] total train loss: 0.0090; total val loss: 0.5055 val r: 0.7502; time: 0.95sec
[499/800][24/24] total train loss: 0.0090; total val loss: 0.5037 val r: 0.7576; time: 0.95sec
learning rate updated: 0.001
[500/800][24/24] total train loss: 0.0089; total val loss: 0.5121 val r: 0.7564; time: 0.94sec
[501/800][24/24] total train loss: 0.0090; total val loss: 0.5039 val r: 0.7536; time: 0.95sec
[502/800][24/24] total train loss: 0.0088; total val loss: 0.4909 val r: 0.7556; time: 0.94sec
[503/800][24/24] total train loss: 0.0090; total val loss: 0.5008 val r: 0.7564; time: 0.95sec
[504/800][24/24] total train loss: 0.0088; total val loss: 0.5244 val r: 0.7545; time: 0.94sec
[505/800][24/24] total train loss: 0.0089; total val loss: 0.5101 val r: 0.7578; time: 0.95sec
[506/800][24/24] total train loss: 0.0088; total val loss: 0.5061 val r: 0.7529; time: 0.95sec
[507/800][24/24] total train loss: 0.0087; total val loss: 0.5039 val r: 0.7519; time: 0.95sec
[508/800][24/24] total train loss: 0.0086; total val loss: 0.5135 val r: 0.7526; time: 0.94sec
[509/800][24/24] total train loss: 0.0090; total val loss: 0.5082 val r: 0.7602; time: 0.95sec
[510/800][24/24] total train loss: 0.0088; total val loss: 0.5094 val r: 0.7547; time: 0.95sec
[511/800][24/24] total train loss: 0.0090; total val loss: 0.5116 val r: 0.7541; time: 0.94sec
[512/800][24/24] total train loss: 0.0089; total val loss: 0.4928 val r: 0.7543; time: 0.95sec
[513/800][24/24] total train loss: 0.0090; total val loss: 0.5112 val r: 0.7567; time: 0.94sec
[514/800][24/24] total train loss: 0.0088; total val loss: 0.5246 val r: 0.7540; time: 0.94sec
[515/800][24/24] total train loss: 0.0089; total val loss: 0.5037 val r: 0.7500; time: 0.95sec
[516/800][24/24] total train loss: 0.0090; total val loss: 0.5104 val r: 0.7518; time: 0.95sec
[517/800][24/24] total train loss: 0.0089; total val loss: 0.5158 val r: 0.7543; time: 0.95sec
[518/800][24/24] total train loss: 0.0091; total val loss: 0.4710 val r: 0.7494; time: 0.95sec
[519/800][24/24] total train loss: 0.0088; total val loss: 0.5030 val r: 0.7570; time: 0.95sec
[520/800][24/24] total train loss: 0.0089; total val loss: 0.5096 val r: 0.7524; time: 0.95sec
[521/800][24/24] total train loss: 0.0089; total val loss: 0.5067 val r: 0.7534; time: 0.95sec
[522/800][24/24] total train loss: 0.0087; total val loss: 0.4858 val r: 0.7583; time: 0.95sec
[523/800][24/24] total train loss: 0.0089; total val loss: 0.5087 val r: 0.7573; time: 0.94sec
[524/800][24/24] total train loss: 0.0088; total val loss: 0.5085 val r: 0.7544; time: 0.94sec
[525/800][24/24] total train loss: 0.0087; total val loss: 0.5095 val r: 0.7545; time: 0.95sec
[526/800][24/24] total train loss: 0.0090; total val loss: 0.5054 val r: 0.7526; time: 0.94sec
[527/800][24/24] total train loss: 0.0091; total val loss: 0.4988 val r: 0.7529; time: 0.95sec
[528/800][24/24] total train loss: 0.0090; total val loss: 0.5076 val r: 0.7530; time: 0.94sec
[529/800][24/24] total train loss: 0.0091; total val loss: 0.4884 val r: 0.7562; time: 0.95sec
[530/800][24/24] total train loss: 0.0090; total val loss: 0.4955 val r: 0.7624; time: 0.95sec
[531/800][24/24] total train loss: 0.0090; total val loss: 0.5099 val r: 0.7536; time: 0.94sec
[532/800][24/24] total train loss: 0.0086; total val loss: 0.4972 val r: 0.7514; time: 0.94sec
[533/800][24/24] total train loss: 0.0089; total val loss: 0.4814 val r: 0.7549; time: 0.95sec
[534/800][24/24] total train loss: 0.0088; total val loss: 0.5110 val r: 0.7563; time: 0.94sec
[535/800][24/24] total train loss: 0.0088; total val loss: 0.5108 val r: 0.7581; time: 0.95sec
[536/800][24/24] total train loss: 0.0087; total val loss: 0.5016 val r: 0.7524; time: 0.95sec
[537/800][24/24] total train loss: 0.0089; total val loss: 0.5263 val r: 0.7528; time: 0.94sec
[538/800][24/24] total train loss: 0.0089; total val loss: 0.4839 val r: 0.7502; time: 0.94sec
[539/800][24/24] total train loss: 0.0089; total val loss: 0.5081 val r: 0.7513; time: 0.94sec
[540/800][24/24] total train loss: 0.0087; total val loss: 0.5093 val r: 0.7530; time: 0.95sec
[541/800][24/24] total train loss: 0.0088; total val loss: 0.5004 val r: 0.7522; time: 0.94sec
[542/800][24/24] total train loss: 0.0088; total val loss: 0.4932 val r: 0.7540; time: 0.95sec
[543/800][24/24] total train loss: 0.0088; total val loss: 0.5085 val r: 0.7500; time: 0.94sec
[544/800][24/24] total train loss: 0.0087; total val loss: 0.5124 val r: 0.7554; time: 0.95sec
[545/800][24/24] total train loss: 0.0091; total val loss: 0.5188 val r: 0.7575; time: 0.95sec
[546/800][24/24] total train loss: 0.0089; total val loss: 0.5196 val r: 0.7568; time: 0.95sec
[547/800][24/24] total train loss: 0.0090; total val loss: 0.5130 val r: 0.7544; time: 0.94sec
[548/800][24/24] total train loss: 0.0087; total val loss: 0.5127 val r: 0.7545; time: 0.95sec
[549/800][24/24] total train loss: 0.0089; total val loss: 0.4977 val r: 0.7568; time: 0.95sec
[550/800][24/24] total train loss: 0.0088; total val loss: 0.5043 val r: 0.7543; time: 0.95sec
[551/800][24/24] total train loss: 0.0089; total val loss: 0.4985 val r: 0.7582; time: 0.94sec
[552/800][24/24] total train loss: 0.0086; total val loss: 0.5029 val r: 0.7565; time: 0.94sec
[553/800][24/24] total train loss: 0.0090; total val loss: 0.5079 val r: 0.7513; time: 0.95sec
[554/800][24/24] total train loss: 0.0087; total val loss: 0.5014 val r: 0.7541; time: 0.95sec
[555/800][24/24] total train loss: 0.0086; total val loss: 0.5112 val r: 0.7599; time: 0.95sec
[556/800][24/24] total train loss: 0.0088; total val loss: 0.5297 val r: 0.7563; time: 0.94sec
[557/800][24/24] total train loss: 0.0087; total val loss: 0.5229 val r: 0.7534; time: 0.95sec
[558/800][24/24] total train loss: 0.0088; total val loss: 0.4915 val r: 0.7558; time: 0.95sec
[559/800][24/24] total train loss: 0.0088; total val loss: 0.5017 val r: 0.7484; time: 0.95sec
[560/800][24/24] total train loss: 0.0091; total val loss: 0.5131 val r: 0.7573; time: 0.95sec
[561/800][24/24] total train loss: 0.0088; total val loss: 0.5233 val r: 0.7550; time: 0.95sec
[562/800][24/24] total train loss: 0.0086; total val loss: 0.5074 val r: 0.7550; time: 0.94sec
[563/800][24/24] total train loss: 0.0087; total val loss: 0.5062 val r: 0.7573; time: 0.95sec
[564/800][24/24] total train loss: 0.0086; total val loss: 0.5052 val r: 0.7550; time: 0.95sec
[565/800][24/24] total train loss: 0.0088; total val loss: 0.5133 val r: 0.7567; time: 0.95sec
[566/800][24/24] total train loss: 0.0087; total val loss: 0.5229 val r: 0.7534; time: 0.94sec
[567/800][24/24] total train loss: 0.0088; total val loss: 0.5239 val r: 0.7544; time: 0.95sec
[568/800][24/24] total train loss: 0.0087; total val loss: 0.5086 val r: 0.7536; time: 0.94sec
[569/800][24/24] total train loss: 0.0089; total val loss: 0.5058 val r: 0.7524; time: 0.95sec
[570/800][24/24] total train loss: 0.0089; total val loss: 0.4990 val r: 0.7556; time: 0.95sec
[571/800][24/24] total train loss: 0.0091; total val loss: 0.5083 val r: 0.7574; time: 0.95sec
[572/800][24/24] total train loss: 0.0089; total val loss: 0.4951 val r: 0.7448; time: 0.94sec
[573/800][24/24] total train loss: 0.0088; total val loss: 0.5096 val r: 0.7513; time: 0.95sec
[574/800][24/24] total train loss: 0.0086; total val loss: 0.5126 val r: 0.7521; time: 0.95sec
[575/800][24/24] total train loss: 0.0087; total val loss: 0.5084 val r: 0.7527; time: 0.95sec
[576/800][24/24] total train loss: 0.0089; total val loss: 0.5040 val r: 0.7500; time: 0.95sec
[577/800][24/24] total train loss: 0.0086; total val loss: 0.5034 val r: 0.7544; time: 0.94sec
[578/800][24/24] total train loss: 0.0086; total val loss: 0.5099 val r: 0.7520; time: 0.94sec
[579/800][24/24] total train loss: 0.0087; total val loss: 0.5188 val r: 0.7508; time: 0.95sec
[580/800][24/24] total train loss: 0.0088; total val loss: 0.5022 val r: 0.7548; time: 0.95sec
[581/800][24/24] total train loss: 0.0086; total val loss: 0.5278 val r: 0.7498; time: 0.95sec
[582/800][24/24] total train loss: 0.0085; total val loss: 0.4810 val r: 0.7553; time: 0.95sec
[583/800][24/24] total train loss: 0.0089; total val loss: 0.5037 val r: 0.7533; time: 0.95sec
[584/800][24/24] total train loss: 0.0087; total val loss: 0.4910 val r: 0.7549; time: 0.94sec
[585/800][24/24] total train loss: 0.0087; total val loss: 0.5273 val r: 0.7478; time: 0.95sec
[586/800][24/24] total train loss: 0.0085; total val loss: 0.5155 val r: 0.7495; time: 0.95sec
[587/800][24/24] total train loss: 0.0086; total val loss: 0.5041 val r: 0.7528; time: 0.95sec
[588/800][24/24] total train loss: 0.0086; total val loss: 0.5051 val r: 0.7558; time: 0.94sec
[589/800][24/24] total train loss: 0.0090; total val loss: 0.5118 val r: 0.7562; time: 0.94sec
[590/800][24/24] total train loss: 0.0087; total val loss: 0.4913 val r: 0.7509; time: 0.95sec
[591/800][24/24] total train loss: 0.0089; total val loss: 0.5107 val r: 0.7513; time: 0.95sec
[592/800][24/24] total train loss: 0.0093; total val loss: 0.5089 val r: 0.7536; time: 0.94sec
[593/800][24/24] total train loss: 0.0086; total val loss: 0.5168 val r: 0.7536; time: 0.95sec
[594/800][24/24] total train loss: 0.0096; total val loss: 0.5017 val r: 0.7475; time: 0.94sec
[595/800][24/24] total train loss: 0.0090; total val loss: 0.4883 val r: 0.7515; time: 0.95sec
[596/800][24/24] total train loss: 0.0087; total val loss: 0.5177 val r: 0.7488; time: 0.95sec
[597/800][24/24] total train loss: 0.0089; total val loss: 0.5122 val r: 0.7472; time: 0.95sec
[598/800][24/24] total train loss: 0.0090; total val loss: 0.5163 val r: 0.7518; time: 0.94sec
[599/800][24/24] total train loss: 0.0093; total val loss: 0.5208 val r: 0.7521; time: 0.95sec
learning rate updated: 0.001
[600/800][24/24] total train loss: 0.0091; total val loss: 0.5183 val r: 0.7526; time: 0.96sec
[601/800][24/24] total train loss: 0.0088; total val loss: 0.4966 val r: 0.7518; time: 0.95sec
[602/800][24/24] total train loss: 0.0084; total val loss: 0.4804 val r: 0.7479; time: 0.96sec
[603/800][24/24] total train loss: 0.0084; total val loss: 0.5227 val r: 0.7487; time: 0.95sec
[604/800][24/24] total train loss: 0.0087; total val loss: 0.5004 val r: 0.7479; time: 0.95sec
[605/800][24/24] total train loss: 0.0082; total val loss: 0.5135 val r: 0.7494; time: 0.94sec
[606/800][24/24] total train loss: 0.0087; total val loss: 0.5130 val r: 0.7480; time: 0.95sec
[607/800][24/24] total train loss: 0.0094; total val loss: 0.5153 val r: 0.7529; time: 0.94sec
[608/800][24/24] total train loss: 0.0092; total val loss: 0.5058 val r: 0.7531; time: 0.95sec
[609/800][24/24] total train loss: 0.0090; total val loss: 0.5131 val r: 0.7502; time: 0.95sec
[610/800][24/24] total train loss: 0.0094; total val loss: 0.4980 val r: 0.7483; time: 0.94sec
[611/800][24/24] total train loss: 0.0087; total val loss: 0.4925 val r: 0.7527; time: 0.95sec
[612/800][24/24] total train loss: 0.0085; total val loss: 0.5025 val r: 0.7472; time: 0.94sec
[613/800][24/24] total train loss: 0.0090; total val loss: 0.5234 val r: 0.7528; time: 0.95sec
[614/800][24/24] total train loss: 0.0092; total val loss: 0.4844 val r: 0.7500; time: 0.95sec
[615/800][24/24] total train loss: 0.0084; total val loss: 0.5067 val r: 0.7478; time: 0.95sec
[616/800][24/24] total train loss: 0.0091; total val loss: 0.5089 val r: 0.7539; time: 0.95sec
[617/800][24/24] total train loss: 0.0089; total val loss: 0.5086 val r: 0.7527; time: 0.95sec
[618/800][24/24] total train loss: 0.0085; total val loss: 0.5218 val r: 0.7504; time: 0.95sec
[619/800][24/24] total train loss: 0.0085; total val loss: 0.5215 val r: 0.7483; time: 0.95sec
[620/800][24/24] total train loss: 0.0086; total val loss: 0.5149 val r: 0.7478; time: 0.94sec
[621/800][24/24] total train loss: 0.0088; total val loss: 0.5053 val r: 0.7526; time: 0.95sec
[622/800][24/24] total train loss: 0.0089; total val loss: 0.5070 val r: 0.7509; time: 0.95sec
[623/800][24/24] total train loss: 0.0087; total val loss: 0.5010 val r: 0.7486; time: 0.94sec
[624/800][24/24] total train loss: 0.0086; total val loss: 0.5124 val r: 0.7500; time: 0.95sec
[625/800][24/24] total train loss: 0.0088; total val loss: 0.5191 val r: 0.7552; time: 0.94sec
[626/800][24/24] total train loss: 0.0086; total val loss: 0.5092 val r: 0.7507; time: 0.95sec
[627/800][24/24] total train loss: 0.0088; total val loss: 0.5170 val r: 0.7514; time: 0.95sec
[628/800][24/24] total train loss: 0.0085; total val loss: 0.4950 val r: 0.7505; time: 0.94sec
[629/800][24/24] total train loss: 0.0092; total val loss: 0.5202 val r: 0.7479; time: 0.94sec
[630/800][24/24] total train loss: 0.0088; total val loss: 0.5064 val r: 0.7495; time: 0.95sec
[631/800][24/24] total train loss: 0.0093; total val loss: 0.5042 val r: 0.7540; time: 0.94sec
[632/800][24/24] total train loss: 0.0087; total val loss: 0.5169 val r: 0.7537; time: 0.95sec
[633/800][24/24] total train loss: 0.0089; total val loss: 0.5121 val r: 0.7483; time: 0.95sec
[634/800][24/24] total train loss: 0.0086; total val loss: 0.5114 val r: 0.7465; time: 0.95sec
[635/800][24/24] total train loss: 0.0085; total val loss: 0.4945 val r: 0.7514; time: 0.94sec
[636/800][24/24] total train loss: 0.0089; total val loss: 0.5061 val r: 0.7559; time: 0.95sec
[637/800][24/24] total train loss: 0.0086; total val loss: 0.5084 val r: 0.7530; time: 0.95sec
[638/800][24/24] total train loss: 0.0088; total val loss: 0.5204 val r: 0.7524; time: 0.95sec
[639/800][24/24] total train loss: 0.0087; total val loss: 0.4976 val r: 0.7505; time: 0.94sec
[640/800][24/24] total train loss: 0.0086; total val loss: 0.5248 val r: 0.7490; time: 0.95sec
[641/800][24/24] total train loss: 0.0087; total val loss: 0.5083 val r: 0.7535; time: 0.95sec
[642/800][24/24] total train loss: 0.0088; total val loss: 0.4922 val r: 0.7533; time: 0.94sec
[643/800][24/24] total train loss: 0.0083; total val loss: 0.4993 val r: 0.7539; time: 0.95sec
[644/800][24/24] total train loss: 0.0087; total val loss: 0.5178 val r: 0.7458; time: 0.95sec
[645/800][24/24] total train loss: 0.0085; total val loss: 0.4992 val r: 0.7500; time: 0.95sec
[646/800][24/24] total train loss: 0.0089; total val loss: 0.4986 val r: 0.7469; time: 0.95sec
[647/800][24/24] total train loss: 0.0085; total val loss: 0.4961 val r: 0.7477; time: 0.94sec
[648/800][24/24] total train loss: 0.0085; total val loss: 0.5048 val r: 0.7502; time: 0.95sec
[649/800][24/24] total train loss: 0.0088; total val loss: 0.5021 val r: 0.7478; time: 0.95sec
[650/800][24/24] total train loss: 0.0088; total val loss: 0.5033 val r: 0.7485; time: 0.95sec
[651/800][24/24] total train loss: 0.0092; total val loss: 0.5020 val r: 0.7480; time: 0.96sec
[652/800][24/24] total train loss: 0.0087; total val loss: 0.5132 val r: 0.7481; time: 0.96sec
[653/800][24/24] total train loss: 0.0082; total val loss: 0.5133 val r: 0.7462; time: 0.95sec
[654/800][24/24] total train loss: 0.0088; total val loss: 0.5180 val r: 0.7507; time: 0.94sec
[655/800][24/24] total train loss: 0.0089; total val loss: 0.4952 val r: 0.7504; time: 0.95sec
[656/800][24/24] total train loss: 0.0089; total val loss: 0.4963 val r: 0.7499; time: 0.95sec
[657/800][24/24] total train loss: 0.0084; total val loss: 0.5093 val r: 0.7462; time: 0.95sec
[658/800][24/24] total train loss: 0.0084; total val loss: 0.5060 val r: 0.7491; time: 0.94sec
[659/800][24/24] total train loss: 0.0086; total val loss: 0.5010 val r: 0.7472; time: 0.94sec
[660/800][24/24] total train loss: 0.0086; total val loss: 0.5132 val r: 0.7487; time: 0.95sec
[661/800][24/24] total train loss: 0.0081; total val loss: 0.5115 val r: 0.7468; time: 0.95sec
[662/800][24/24] total train loss: 0.0081; total val loss: 0.4994 val r: 0.7498; time: 0.94sec
[663/800][24/24] total train loss: 0.0086; total val loss: 0.5067 val r: 0.7439; time: 0.95sec
[664/800][24/24] total train loss: 0.0082; total val loss: 0.5069 val r: 0.7478; time: 0.95sec
[665/800][24/24] total train loss: 0.0089; total val loss: 0.5038 val r: 0.7482; time: 0.95sec
[666/800][24/24] total train loss: 0.0084; total val loss: 0.5163 val r: 0.7530; time: 0.94sec
[667/800][24/24] total train loss: 0.0085; total val loss: 0.5013 val r: 0.7514; time: 0.94sec
[668/800][24/24] total train loss: 0.0096; total val loss: 0.5125 val r: 0.7474; time: 0.95sec
[669/800][24/24] total train loss: 0.0081; total val loss: 0.5144 val r: 0.7469; time: 0.95sec
[670/800][24/24] total train loss: 0.0086; total val loss: 0.4934 val r: 0.7485; time: 0.95sec
[671/800][24/24] total train loss: 0.0093; total val loss: 0.4994 val r: 0.7499; time: 0.95sec
[672/800][24/24] total train loss: 0.0087; total val loss: 0.4944 val r: 0.7475; time: 0.95sec
[673/800][24/24] total train loss: 0.0090; total val loss: 0.4898 val r: 0.7476; time: 0.95sec
[674/800][24/24] total train loss: 0.0087; total val loss: 0.5215 val r: 0.7517; time: 0.95sec
[675/800][24/24] total train loss: 0.0087; total val loss: 0.5069 val r: 0.7500; time: 0.95sec
[676/800][24/24] total train loss: 0.0081; total val loss: 0.5046 val r: 0.7515; time: 0.95sec
[677/800][24/24] total train loss: 0.0086; total val loss: 0.5174 val r: 0.7497; time: 0.95sec
[678/800][24/24] total train loss: 0.0087; total val loss: 0.5095 val r: 0.7510; time: 0.95sec
[679/800][24/24] total train loss: 0.0086; total val loss: 0.5226 val r: 0.7511; time: 0.95sec
[680/800][24/24] total train loss: 0.0093; total val loss: 0.5097 val r: 0.7476; time: 0.95sec
[681/800][24/24] total train loss: 0.0089; total val loss: 0.5072 val r: 0.7427; time: 0.95sec
[682/800][24/24] total train loss: 0.0097; total val loss: 0.4951 val r: 0.7489; time: 0.94sec
[683/800][24/24] total train loss: 0.0083; total val loss: 0.5137 val r: 0.7516; time: 0.95sec
[684/800][24/24] total train loss: 0.0086; total val loss: 0.5102 val r: 0.7530; time: 0.95sec
[685/800][24/24] total train loss: 0.0089; total val loss: 0.5026 val r: 0.7526; time: 0.95sec
[686/800][24/24] total train loss: 0.0089; total val loss: 0.5146 val r: 0.7520; time: 0.95sec
[687/800][24/24] total train loss: 0.0083; total val loss: 0.4992 val r: 0.7500; time: 0.94sec
[688/800][24/24] total train loss: 0.0089; total val loss: 0.5081 val r: 0.7500; time: 0.95sec
[689/800][24/24] total train loss: 0.0086; total val loss: 0.4758 val r: 0.7474; time: 0.95sec
[690/800][24/24] total train loss: 0.0083; total val loss: 0.5023 val r: 0.7495; time: 0.94sec
[691/800][24/24] total train loss: 0.0089; total val loss: 0.5136 val r: 0.7464; time: 0.94sec
[692/800][24/24] total train loss: 0.0089; total val loss: 0.4992 val r: 0.7509; time: 0.95sec
[693/800][24/24] total train loss: 0.0087; total val loss: 0.5118 val r: 0.7495; time: 0.94sec
[694/800][24/24] total train loss: 0.0096; total val loss: 0.5116 val r: 0.7520; time: 0.95sec
[695/800][24/24] total train loss: 0.0085; total val loss: 0.5065 val r: 0.7498; time: 0.94sec
[696/800][24/24] total train loss: 0.0085; total val loss: 0.4854 val r: 0.7474; time: 0.95sec
[697/800][24/24] total train loss: 0.0087; total val loss: 0.5170 val r: 0.7519; time: 0.94sec
[698/800][24/24] total train loss: 0.0084; total val loss: 0.5111 val r: 0.7498; time: 0.94sec
[699/800][24/24] total train loss: 0.0084; total val loss: 0.5172 val r: 0.7436; time: 0.94sec
learning rate updated: 0.001
[700/800][24/24] total train loss: 0.0089; total val loss: 0.5131 val r: 0.7453; time: 0.94sec
[701/800][24/24] total train loss: 0.0088; total val loss: 0.4967 val r: 0.7458; time: 0.94sec
[702/800][24/24] total train loss: 0.0091; total val loss: 0.4954 val r: 0.7512; time: 0.94sec
[703/800][24/24] total train loss: 0.0083; total val loss: 0.5066 val r: 0.7485; time: 0.94sec
[704/800][24/24] total train loss: 0.0091; total val loss: 0.5104 val r: 0.7482; time: 0.94sec
[705/800][24/24] total train loss: 0.0089; total val loss: 0.5046 val r: 0.7472; time: 0.94sec
[706/800][24/24] total train loss: 0.0085; total val loss: 0.5045 val r: 0.7428; time: 0.95sec
[707/800][24/24] total train loss: 0.0088; total val loss: 0.5197 val r: 0.7462; time: 0.95sec
[708/800][24/24] total train loss: 0.0086; total val loss: 0.5107 val r: 0.7449; time: 0.95sec
[709/800][24/24] total train loss: 0.0086; total val loss: 0.4948 val r: 0.7467; time: 0.95sec
[710/800][24/24] total train loss: 0.0090; total val loss: 0.4837 val r: 0.7492; time: 0.96sec
[711/800][24/24] total train loss: 0.0087; total val loss: 0.5117 val r: 0.7524; time: 0.95sec
[712/800][24/24] total train loss: 0.0086; total val loss: 0.4946 val r: 0.7554; time: 0.95sec
[713/800][24/24] total train loss: 0.0083; total val loss: 0.5172 val r: 0.7487; time: 0.96sec
[714/800][24/24] total train loss: 0.0087; total val loss: 0.4915 val r: 0.7488; time: 0.95sec
[715/800][24/24] total train loss: 0.0082; total val loss: 0.5076 val r: 0.7531; time: 0.95sec
[716/800][24/24] total train loss: 0.0093; total val loss: 0.5049 val r: 0.7533; time: 0.95sec
[717/800][24/24] total train loss: 0.0089; total val loss: 0.5027 val r: 0.7526; time: 0.94sec
[718/800][24/24] total train loss: 0.0086; total val loss: 0.4707 val r: 0.7491; time: 0.95sec
[719/800][24/24] total train loss: 0.0085; total val loss: 0.5241 val r: 0.7465; time: 0.94sec
[720/800][24/24] total train loss: 0.0084; total val loss: 0.5090 val r: 0.7505; time: 0.95sec
[721/800][24/24] total train loss: 0.0089; total val loss: 0.5116 val r: 0.7525; time: 0.95sec
[722/800][24/24] total train loss: 0.0088; total val loss: 0.4991 val r: 0.7540; time: 0.95sec
[723/800][24/24] total train loss: 0.0091; total val loss: 0.4910 val r: 0.7550; time: 0.95sec
[724/800][24/24] total train loss: 0.0082; total val loss: 0.5052 val r: 0.7516; time: 0.94sec
[725/800][24/24] total train loss: 0.0081; total val loss: 0.5122 val r: 0.7484; time: 0.95sec
[726/800][24/24] total train loss: 0.0084; total val loss: 0.5023 val r: 0.7520; time: 0.95sec
[727/800][24/24] total train loss: 0.0086; total val loss: 0.4976 val r: 0.7504; time: 0.94sec
[728/800][24/24] total train loss: 0.0086; total val loss: 0.4915 val r: 0.7493; time: 0.94sec
[729/800][24/24] total train loss: 0.0085; total val loss: 0.5046 val r: 0.7505; time: 0.95sec
[730/800][24/24] total train loss: 0.0078; total val loss: 0.5092 val r: 0.7517; time: 0.94sec
[731/800][24/24] total train loss: 0.0082; total val loss: 0.5105 val r: 0.7483; time: 0.95sec
[732/800][24/24] total train loss: 0.0086; total val loss: 0.5013 val r: 0.7481; time: 0.95sec
[733/800][24/24] total train loss: 0.0082; total val loss: 0.5178 val r: 0.7479; time: 0.94sec
[734/800][24/24] total train loss: 0.0083; total val loss: 0.5085 val r: 0.7475; time: 0.95sec
[735/800][24/24] total train loss: 0.0084; total val loss: 0.5175 val r: 0.7470; time: 0.94sec
[736/800][24/24] total train loss: 0.0083; total val loss: 0.5058 val r: 0.7469; time: 0.95sec
[737/800][24/24] total train loss: 0.0083; total val loss: 0.5049 val r: 0.7486; time: 0.94sec
[738/800][24/24] total train loss: 0.0096; total val loss: 0.5220 val r: 0.7493; time: 0.95sec
[739/800][24/24] total train loss: 0.0090; total val loss: 0.5085 val r: 0.7524; time: 0.94sec
[740/800][24/24] total train loss: 0.0085; total val loss: 0.4992 val r: 0.7533; time: 0.95sec
[741/800][24/24] total train loss: 0.0091; total val loss: 0.4966 val r: 0.7506; time: 0.94sec
[742/800][24/24] total train loss: 0.0091; total val loss: 0.4974 val r: 0.7511; time: 0.94sec
[743/800][24/24] total train loss: 0.0088; total val loss: 0.4982 val r: 0.7480; time: 0.95sec
[744/800][24/24] total train loss: 0.0084; total val loss: 0.4940 val r: 0.7514; time: 0.95sec
[745/800][24/24] total train loss: 0.0093; total val loss: 0.5099 val r: 0.7506; time: 0.94sec
[746/800][24/24] total train loss: 0.0091; total val loss: 0.4885 val r: 0.7521; time: 0.95sec
[747/800][24/24] total train loss: 0.0082; total val loss: 0.5028 val r: 0.7493; time: 0.94sec
[748/800][24/24] total train loss: 0.0086; total val loss: 0.5027 val r: 0.7481; time: 0.94sec
[749/800][24/24] total train loss: 0.0087; total val loss: 0.5069 val r: 0.7458; time: 0.94sec
[750/800][24/24] total train loss: 0.0095; total val loss: 0.4892 val r: 0.7505; time: 0.95sec
[751/800][24/24] total train loss: 0.0082; total val loss: 0.5043 val r: 0.7500; time: 0.94sec
[752/800][24/24] total train loss: 0.0083; total val loss: 0.5078 val r: 0.7501; time: 0.95sec
[753/800][24/24] total train loss: 0.0090; total val loss: 0.5211 val r: 0.7512; time: 0.95sec
[754/800][24/24] total train loss: 0.0090; total val loss: 0.4702 val r: 0.7518; time: 0.94sec
[755/800][24/24] total train loss: 0.0085; total val loss: 0.5039 val r: 0.7486; time: 0.95sec
[756/800][24/24] total train loss: 0.0081; total val loss: 0.4997 val r: 0.7463; time: 0.94sec
[757/800][24/24] total train loss: 0.0090; total val loss: 0.5053 val r: 0.7495; time: 0.95sec
[758/800][24/24] total train loss: 0.0087; total val loss: 0.5135 val r: 0.7476; time: 0.95sec
[759/800][24/24] total train loss: 0.0083; total val loss: 0.4990 val r: 0.7490; time: 0.95sec
[760/800][24/24] total train loss: 0.0082; total val loss: 0.4990 val r: 0.7471; time: 0.95sec
[761/800][24/24] total train loss: 0.0086; total val loss: 0.4966 val r: 0.7496; time: 0.94sec
[762/800][24/24] total train loss: 0.0093; total val loss: 0.4983 val r: 0.7473; time: 0.95sec
[763/800][24/24] total train loss: 0.0089; total val loss: 0.5200 val r: 0.7472; time: 0.95sec
[764/800][24/24] total train loss: 0.0086; total val loss: 0.5171 val r: 0.7479; time: 0.95sec
[765/800][24/24] total train loss: 0.0090; total val loss: 0.5104 val r: 0.7455; time: 0.95sec
[766/800][24/24] total train loss: 0.0088; total val loss: 0.5305 val r: 0.7527; time: 0.94sec
[767/800][24/24] total train loss: 0.0087; total val loss: 0.5059 val r: 0.7519; time: 0.95sec
[768/800][24/24] total train loss: 0.0081; total val loss: 0.4731 val r: 0.7531; time: 0.96sec
[769/800][24/24] total train loss: 0.0086; total val loss: 0.5105 val r: 0.7534; time: 0.95sec
[770/800][24/24] total train loss: 0.0094; total val loss: 0.4956 val r: 0.7506; time: 0.95sec
[771/800][24/24] total train loss: 0.0084; total val loss: 0.5210 val r: 0.7474; time: 0.95sec
[772/800][24/24] total train loss: 0.0091; total val loss: 0.5102 val r: 0.7520; time: 0.95sec
[773/800][24/24] total train loss: 0.0087; total val loss: 0.4992 val r: 0.7464; time: 0.95sec
[774/800][24/24] total train loss: 0.0089; total val loss: 0.5032 val r: 0.7522; time: 0.95sec
[775/800][24/24] total train loss: 0.0092; total val loss: 0.4999 val r: 0.7511; time: 0.94sec
[776/800][24/24] total train loss: 0.0087; total val loss: 0.4946 val r: 0.7485; time: 0.95sec
[777/800][24/24] total train loss: 0.0089; total val loss: 0.4967 val r: 0.7463; time: 0.94sec
[778/800][24/24] total train loss: 0.0084; total val loss: 0.5163 val r: 0.7471; time: 0.95sec
[779/800][24/24] total train loss: 0.0086; total val loss: 0.5080 val r: 0.7425; time: 0.95sec
[780/800][24/24] total train loss: 0.0091; total val loss: 0.4931 val r: 0.7440; time: 0.95sec
[781/800][24/24] total train loss: 0.0088; total val loss: 0.5085 val r: 0.7472; time: 0.95sec
[782/800][24/24] total train loss: 0.0085; total val loss: 0.5016 val r: 0.7481; time: 0.95sec
[783/800][24/24] total train loss: 0.0087; total val loss: 0.5181 val r: 0.7444; time: 0.95sec
[784/800][24/24] total train loss: 0.0086; total val loss: 0.5193 val r: 0.7480; time: 0.96sec
[785/800][24/24] total train loss: 0.0089; total val loss: 0.4930 val r: 0.7472; time: 0.96sec
[786/800][24/24] total train loss: 0.0085; total val loss: 0.5049 val r: 0.7432; time: 0.94sec
[787/800][24/24] total train loss: 0.0087; total val loss: 0.5131 val r: 0.7432; time: 0.95sec
[788/800][24/24] total train loss: 0.0083; total val loss: 0.5190 val r: 0.7433; time: 0.94sec
[789/800][24/24] total train loss: 0.0085; total val loss: 0.4971 val r: 0.7494; time: 0.95sec
[790/800][24/24] total train loss: 0.0085; total val loss: 0.5178 val r: 0.7459; time: 0.95sec
[791/800][24/24] total train loss: 0.0084; total val loss: 0.5193 val r: 0.7464; time: 0.95sec
[792/800][24/24] total train loss: 0.0087; total val loss: 0.4987 val r: 0.7486; time: 0.95sec
[793/800][24/24] total train loss: 0.0088; total val loss: 0.5030 val r: 0.7489; time: 0.95sec
[794/800][24/24] total train loss: 0.0092; total val loss: 0.5065 val r: 0.7471; time: 0.94sec
[795/800][24/24] total train loss: 0.0090; total val loss: 0.5305 val r: 0.7449; time: 0.95sec
[796/800][24/24] total train loss: 0.0093; total val loss: 0.5205 val r: 0.7450; time: 0.95sec
[797/800][24/24] total train loss: 0.0088; total val loss: 0.5083 val r: 0.7464; time: 0.96sec
[798/800][24/24] total train loss: 0.0086; total val loss: 0.5083 val r: 0.7457; time: 0.94sec
[799/800][24/24] total train loss: 0.0089; total val loss: 0.5047 val r: 0.7451; time: 0.94sec
learning rate updated: 0.001
[800/800][24/24] total train loss: 0.0089; total val loss: 0.4951 val r: 0.7475; time: 0.95sec
Best epoch 283 with val_r = 0.7636.
Fold #4
- - - - - - - - - - - - -
initializing neural net
[1/800][24/24] total train loss: 1.1917; total val loss: 0.4902 val r: 0.6287; time: 0.96sec
[2/800][24/24] total train loss: 0.5947; total val loss: 0.4481 val r: 0.6819; time: 0.94sec
[3/800][24/24] total train loss: 0.4046; total val loss: 0.4238 val r: 0.7052; time: 0.96sec
[4/800][24/24] total train loss: 0.2903; total val loss: 0.4241 val r: 0.6886; time: 0.94sec
[5/800][24/24] total train loss: 0.2052; total val loss: 0.5028 val r: 0.6725; time: 0.94sec
[6/800][24/24] total train loss: 0.1298; total val loss: 0.4887 val r: 0.6820; time: 0.94sec
[7/800][24/24] total train loss: 0.0992; total val loss: 0.5097 val r: 0.6896; time: 0.95sec
[8/800][24/24] total train loss: 0.0704; total val loss: 0.4874 val r: 0.7066; time: 0.94sec
[9/800][24/24] total train loss: 0.0673; total val loss: 0.4719 val r: 0.6962; time: 0.95sec
[10/800][24/24] total train loss: 0.0501; total val loss: 0.4976 val r: 0.6956; time: 0.95sec
[11/800][24/24] total train loss: 0.0335; total val loss: 0.4717 val r: 0.7077; time: 0.95sec
[12/800][24/24] total train loss: 0.0269; total val loss: 0.4943 val r: 0.7043; time: 0.95sec
[13/800][24/24] total train loss: 0.0230; total val loss: 0.4847 val r: 0.7014; time: 0.94sec
[14/800][24/24] total train loss: 0.0234; total val loss: 0.4840 val r: 0.7045; time: 0.95sec
[15/800][24/24] total train loss: 0.0225; total val loss: 0.4671 val r: 0.7028; time: 0.95sec
[16/800][24/24] total train loss: 0.0251; total val loss: 0.4944 val r: 0.7105; time: 0.95sec
[17/800][24/24] total train loss: 0.0237; total val loss: 0.4798 val r: 0.7100; time: 0.94sec
[18/800][24/24] total train loss: 0.0205; total val loss: 0.5116 val r: 0.7090; time: 0.95sec
[19/800][24/24] total train loss: 0.0184; total val loss: 0.4875 val r: 0.7170; time: 0.94sec
[20/800][24/24] total train loss: 0.0164; total val loss: 0.5047 val r: 0.7210; time: 0.95sec
[21/800][24/24] total train loss: 0.0159; total val loss: 0.5015 val r: 0.7082; time: 0.95sec
[22/800][24/24] total train loss: 0.0146; total val loss: 0.5140 val r: 0.7181; time: 0.94sec
[23/800][24/24] total train loss: 0.0163; total val loss: 0.4839 val r: 0.7116; time: 0.95sec
[24/800][24/24] total train loss: 0.0177; total val loss: 0.4806 val r: 0.7156; time: 0.94sec
[25/800][24/24] total train loss: 0.0186; total val loss: 0.5034 val r: 0.7115; time: 0.94sec
[26/800][24/24] total train loss: 0.0166; total val loss: 0.5021 val r: 0.7129; time: 0.95sec
[27/800][24/24] total train loss: 0.0138; total val loss: 0.4848 val r: 0.7116; time: 0.95sec
[28/800][24/24] total train loss: 0.0142; total val loss: 0.4886 val r: 0.7180; time: 0.95sec
[29/800][24/24] total train loss: 0.0159; total val loss: 0.4804 val r: 0.7130; time: 0.95sec
[30/800][24/24] total train loss: 0.0153; total val loss: 0.4684 val r: 0.7226; time: 0.94sec
[31/800][24/24] total train loss: 0.0136; total val loss: 0.5002 val r: 0.7107; time: 0.95sec
[32/800][24/24] total train loss: 0.0119; total val loss: 0.4739 val r: 0.7188; time: 0.94sec
[33/800][24/24] total train loss: 0.0134; total val loss: 0.4960 val r: 0.7158; time: 0.94sec
[34/800][24/24] total train loss: 0.0162; total val loss: 0.4850 val r: 0.7115; time: 0.95sec
[35/800][24/24] total train loss: 0.0178; total val loss: 0.4985 val r: 0.7219; time: 0.95sec
[36/800][24/24] total train loss: 0.0157; total val loss: 0.4957 val r: 0.7213; time: 0.95sec
[37/800][24/24] total train loss: 0.0144; total val loss: 0.4980 val r: 0.7159; time: 0.95sec
[38/800][24/24] total train loss: 0.0150; total val loss: 0.4803 val r: 0.7245; time: 0.94sec
[39/800][24/24] total train loss: 0.0140; total val loss: 0.4851 val r: 0.7179; time: 0.95sec
[40/800][24/24] total train loss: 0.0124; total val loss: 0.4759 val r: 0.7186; time: 0.94sec
[41/800][24/24] total train loss: 0.0131; total val loss: 0.4867 val r: 0.7197; time: 0.94sec
[42/800][24/24] total train loss: 0.0141; total val loss: 0.4875 val r: 0.7222; time: 0.95sec
[43/800][24/24] total train loss: 0.0146; total val loss: 0.4958 val r: 0.7150; time: 0.95sec
[44/800][24/24] total train loss: 0.0142; total val loss: 0.4659 val r: 0.7199; time: 0.95sec
[45/800][24/24] total train loss: 0.0145; total val loss: 0.4768 val r: 0.7222; time: 0.95sec
[46/800][24/24] total train loss: 0.0134; total val loss: 0.4751 val r: 0.7142; time: 0.95sec
[47/800][24/24] total train loss: 0.0117; total val loss: 0.4718 val r: 0.7197; time: 0.94sec
[48/800][24/24] total train loss: 0.0137; total val loss: 0.5015 val r: 0.7237; time: 0.95sec
[49/800][24/24] total train loss: 0.0136; total val loss: 0.4761 val r: 0.7222; time: 0.94sec
[50/800][24/24] total train loss: 0.0127; total val loss: 0.4823 val r: 0.7231; time: 0.94sec
[51/800][24/24] total train loss: 0.0117; total val loss: 0.4907 val r: 0.7205; time: 0.94sec
[52/800][24/24] total train loss: 0.0116; total val loss: 0.4550 val r: 0.7236; time: 0.95sec
[53/800][24/24] total train loss: 0.0137; total val loss: 0.5005 val r: 0.7178; time: 0.94sec
[54/800][24/24] total train loss: 0.0130; total val loss: 0.5161 val r: 0.7247; time: 0.94sec
[55/800][24/24] total train loss: 0.0148; total val loss: 0.4831 val r: 0.7182; time: 0.95sec
[56/800][24/24] total train loss: 0.0151; total val loss: 0.4942 val r: 0.7163; time: 0.95sec
[57/800][24/24] total train loss: 0.0131; total val loss: 0.4819 val r: 0.7288; time: 0.95sec
[58/800][24/24] total train loss: 0.0128; total val loss: 0.4761 val r: 0.7243; time: 0.94sec
[59/800][24/24] total train loss: 0.0125; total val loss: 0.4711 val r: 0.7253; time: 0.93sec
[60/800][24/24] total train loss: 0.0123; total val loss: 0.4939 val r: 0.7249; time: 0.95sec
[61/800][24/24] total train loss: 0.0122; total val loss: 0.4847 val r: 0.7245; time: 0.94sec
[62/800][24/24] total train loss: 0.0112; total val loss: 0.4782 val r: 0.7226; time: 0.94sec
[63/800][24/24] total train loss: 0.0114; total val loss: 0.4817 val r: 0.7285; time: 0.94sec
[64/800][24/24] total train loss: 0.0120; total val loss: 0.4798 val r: 0.7258; time: 0.94sec
[65/800][24/24] total train loss: 0.0132; total val loss: 0.4784 val r: 0.7263; time: 0.95sec
[66/800][24/24] total train loss: 0.0119; total val loss: 0.4717 val r: 0.7271; time: 0.95sec
[67/800][24/24] total train loss: 0.0117; total val loss: 0.4902 val r: 0.7282; time: 0.94sec
[68/800][24/24] total train loss: 0.0122; total val loss: 0.4684 val r: 0.7264; time: 0.95sec
[69/800][24/24] total train loss: 0.0131; total val loss: 0.4754 val r: 0.7260; time: 0.95sec
[70/800][24/24] total train loss: 0.0138; total val loss: 0.4862 val r: 0.7262; time: 0.95sec
[71/800][24/24] total train loss: 0.0113; total val loss: 0.4921 val r: 0.7284; time: 0.95sec
[72/800][24/24] total train loss: 0.0110; total val loss: 0.4991 val r: 0.7245; time: 0.95sec
[73/800][24/24] total train loss: 0.0106; total val loss: 0.4746 val r: 0.7261; time: 0.95sec
[74/800][24/24] total train loss: 0.0102; total val loss: 0.4968 val r: 0.7257; time: 0.95sec
[75/800][24/24] total train loss: 0.0100; total val loss: 0.4720 val r: 0.7212; time: 0.95sec
[76/800][24/24] total train loss: 0.0105; total val loss: 0.4759 val r: 0.7284; time: 0.95sec
[77/800][24/24] total train loss: 0.0101; total val loss: 0.4855 val r: 0.7227; time: 0.95sec
[78/800][24/24] total train loss: 0.0100; total val loss: 0.4633 val r: 0.7269; time: 0.95sec
[79/800][24/24] total train loss: 0.0108; total val loss: 0.4653 val r: 0.7263; time: 0.95sec
[80/800][24/24] total train loss: 0.0118; total val loss: 0.5027 val r: 0.7302; time: 0.95sec
[81/800][24/24] total train loss: 0.0127; total val loss: 0.5103 val r: 0.7250; time: 0.94sec
[82/800][24/24] total train loss: 0.0129; total val loss: 0.4674 val r: 0.7333; time: 0.95sec
[83/800][24/24] total train loss: 0.0132; total val loss: 0.4842 val r: 0.7313; time: 0.95sec
[84/800][24/24] total train loss: 0.0115; total val loss: 0.4975 val r: 0.7281; time: 0.95sec
[85/800][24/24] total train loss: 0.0111; total val loss: 0.4865 val r: 0.7295; time: 0.95sec
[86/800][24/24] total train loss: 0.0108; total val loss: 0.4773 val r: 0.7286; time: 0.95sec
[87/800][24/24] total train loss: 0.0108; total val loss: 0.4939 val r: 0.7310; time: 0.95sec
[88/800][24/24] total train loss: 0.0107; total val loss: 0.4778 val r: 0.7313; time: 0.95sec
[89/800][24/24] total train loss: 0.0106; total val loss: 0.4686 val r: 0.7322; time: 0.95sec
[90/800][24/24] total train loss: 0.0100; total val loss: 0.4773 val r: 0.7324; time: 0.96sec
[91/800][24/24] total train loss: 0.0099; total val loss: 0.5055 val r: 0.7282; time: 0.95sec
[92/800][24/24] total train loss: 0.0105; total val loss: 0.4880 val r: 0.7294; time: 0.95sec
[93/800][24/24] total train loss: 0.0115; total val loss: 0.4743 val r: 0.7317; time: 0.95sec
[94/800][24/24] total train loss: 0.0112; total val loss: 0.4762 val r: 0.7347; time: 0.94sec
[95/800][24/24] total train loss: 0.0110; total val loss: 0.4805 val r: 0.7364; time: 0.94sec
[96/800][24/24] total train loss: 0.0116; total val loss: 0.4864 val r: 0.7252; time: 0.95sec
[97/800][24/24] total train loss: 0.0111; total val loss: 0.4888 val r: 0.7357; time: 0.95sec
[98/800][24/24] total train loss: 0.0113; total val loss: 0.4722 val r: 0.7311; time: 0.95sec
[99/800][24/24] total train loss: 0.0108; total val loss: 0.4588 val r: 0.7325; time: 0.95sec
learning rate updated: 0.001
[100/800][24/24] total train loss: 0.0112; total val loss: 0.4773 val r: 0.7313; time: 0.94sec
[101/800][24/24] total train loss: 0.0100; total val loss: 0.4704 val r: 0.7274; time: 0.95sec
[102/800][24/24] total train loss: 0.0102; total val loss: 0.4929 val r: 0.7352; time: 0.95sec
[103/800][24/24] total train loss: 0.0108; total val loss: 0.4780 val r: 0.7326; time: 0.94sec
[104/800][24/24] total train loss: 0.0096; total val loss: 0.4901 val r: 0.7328; time: 0.95sec
[105/800][24/24] total train loss: 0.0097; total val loss: 0.4820 val r: 0.7311; time: 0.96sec
[106/800][24/24] total train loss: 0.0107; total val loss: 0.4909 val r: 0.7293; time: 0.94sec
[107/800][24/24] total train loss: 0.0101; total val loss: 0.4892 val r: 0.7340; time: 0.94sec
[108/800][24/24] total train loss: 0.0096; total val loss: 0.4671 val r: 0.7354; time: 0.95sec
[109/800][24/24] total train loss: 0.0098; total val loss: 0.4509 val r: 0.7318; time: 0.94sec
[110/800][24/24] total train loss: 0.0102; total val loss: 0.4936 val r: 0.7349; time: 0.95sec
[111/800][24/24] total train loss: 0.0102; total val loss: 0.4782 val r: 0.7317; time: 0.95sec
[112/800][24/24] total train loss: 0.0093; total val loss: 0.4886 val r: 0.7332; time: 0.95sec
[113/800][24/24] total train loss: 0.0092; total val loss: 0.4636 val r: 0.7352; time: 0.95sec
[114/800][24/24] total train loss: 0.0094; total val loss: 0.4670 val r: 0.7310; time: 0.94sec
[115/800][24/24] total train loss: 0.0097; total val loss: 0.4852 val r: 0.7309; time: 0.95sec
[116/800][24/24] total train loss: 0.0094; total val loss: 0.4886 val r: 0.7361; time: 0.95sec
[117/800][24/24] total train loss: 0.0092; total val loss: 0.4672 val r: 0.7363; time: 0.95sec
[118/800][24/24] total train loss: 0.0089; total val loss: 0.4455 val r: 0.7356; time: 0.95sec
[119/800][24/24] total train loss: 0.0099; total val loss: 0.4841 val r: 0.7341; time: 0.95sec
[120/800][24/24] total train loss: 0.0107; total val loss: 0.4759 val r: 0.7350; time: 0.94sec
[121/800][24/24] total train loss: 0.0103; total val loss: 0.4904 val r: 0.7364; time: 0.95sec
[122/800][24/24] total train loss: 0.0096; total val loss: 0.4735 val r: 0.7304; time: 0.96sec
[123/800][24/24] total train loss: 0.0095; total val loss: 0.4935 val r: 0.7324; time: 0.95sec
[124/800][24/24] total train loss: 0.0096; total val loss: 0.4576 val r: 0.7287; time: 0.94sec
[125/800][24/24] total train loss: 0.0089; total val loss: 0.4629 val r: 0.7361; time: 0.95sec
[126/800][24/24] total train loss: 0.0093; total val loss: 0.4889 val r: 0.7300; time: 0.95sec
[127/800][24/24] total train loss: 0.0097; total val loss: 0.4896 val r: 0.7338; time: 0.94sec
[128/800][24/24] total train loss: 0.0104; total val loss: 0.4730 val r: 0.7424; time: 0.95sec
[129/800][24/24] total train loss: 0.0107; total val loss: 0.4736 val r: 0.7354; time: 0.95sec
[130/800][24/24] total train loss: 0.0103; total val loss: 0.4604 val r: 0.7366; time: 0.96sec
[131/800][24/24] total train loss: 0.0100; total val loss: 0.4843 val r: 0.7294; time: 0.95sec
[132/800][24/24] total train loss: 0.0100; total val loss: 0.4838 val r: 0.7301; time: 0.94sec
[133/800][24/24] total train loss: 0.0101; total val loss: 0.4849 val r: 0.7336; time: 0.95sec
[134/800][24/24] total train loss: 0.0093; total val loss: 0.4939 val r: 0.7282; time: 0.94sec
[135/800][24/24] total train loss: 0.0094; total val loss: 0.5006 val r: 0.7369; time: 0.95sec
[136/800][24/24] total train loss: 0.0097; total val loss: 0.4783 val r: 0.7314; time: 0.95sec
[137/800][24/24] total train loss: 0.0095; total val loss: 0.4790 val r: 0.7344; time: 0.95sec
[138/800][24/24] total train loss: 0.0098; total val loss: 0.4782 val r: 0.7300; time: 0.95sec
[139/800][24/24] total train loss: 0.0095; total val loss: 0.4801 val r: 0.7337; time: 0.95sec
[140/800][24/24] total train loss: 0.0087; total val loss: 0.4903 val r: 0.7333; time: 0.95sec
[141/800][24/24] total train loss: 0.0094; total val loss: 0.4811 val r: 0.7314; time: 0.94sec
[142/800][24/24] total train loss: 0.0096; total val loss: 0.4839 val r: 0.7334; time: 0.95sec
[143/800][24/24] total train loss: 0.0113; total val loss: 0.4617 val r: 0.7302; time: 0.95sec
[144/800][24/24] total train loss: 0.0109; total val loss: 0.5011 val r: 0.7349; time: 0.95sec
[145/800][24/24] total train loss: 0.0108; total val loss: 0.4672 val r: 0.7351; time: 0.95sec
[146/800][24/24] total train loss: 0.0100; total val loss: 0.4871 val r: 0.7270; time: 0.95sec
[147/800][24/24] total train loss: 0.0100; total val loss: 0.4759 val r: 0.7391; time: 0.94sec
[148/800][24/24] total train loss: 0.0098; total val loss: 0.4814 val r: 0.7295; time: 0.95sec
[149/800][24/24] total train loss: 0.0099; total val loss: 0.4715 val r: 0.7373; time: 0.95sec
[150/800][24/24] total train loss: 0.0099; total val loss: 0.4836 val r: 0.7308; time: 0.95sec
[151/800][24/24] total train loss: 0.0094; total val loss: 0.4778 val r: 0.7375; time: 0.95sec
[152/800][24/24] total train loss: 0.0087; total val loss: 0.4825 val r: 0.7326; time: 0.95sec
[153/800][24/24] total train loss: 0.0088; total val loss: 0.4740 val r: 0.7361; time: 0.95sec
[154/800][24/24] total train loss: 0.0082; total val loss: 0.4948 val r: 0.7329; time: 0.95sec
[155/800][24/24] total train loss: 0.0087; total val loss: 0.4631 val r: 0.7341; time: 0.95sec
[156/800][24/24] total train loss: 0.0093; total val loss: 0.4852 val r: 0.7353; time: 0.95sec
[157/800][24/24] total train loss: 0.0090; total val loss: 0.4835 val r: 0.7333; time: 0.95sec
[158/800][24/24] total train loss: 0.0094; total val loss: 0.4884 val r: 0.7408; time: 0.95sec
[159/800][24/24] total train loss: 0.0089; total val loss: 0.4675 val r: 0.7266; time: 0.95sec
[160/800][24/24] total train loss: 0.0092; total val loss: 0.4682 val r: 0.7356; time: 0.94sec
[161/800][24/24] total train loss: 0.0097; total val loss: 0.4672 val r: 0.7346; time: 0.95sec
[162/800][24/24] total train loss: 0.0096; total val loss: 0.4716 val r: 0.7391; time: 0.95sec
[163/800][24/24] total train loss: 0.0091; total val loss: 0.4748 val r: 0.7337; time: 0.95sec
[164/800][24/24] total train loss: 0.0089; total val loss: 0.4788 val r: 0.7370; time: 0.95sec
[165/800][24/24] total train loss: 0.0091; total val loss: 0.4773 val r: 0.7314; time: 0.95sec
[166/800][24/24] total train loss: 0.0092; total val loss: 0.4647 val r: 0.7348; time: 0.94sec
[167/800][24/24] total train loss: 0.0088; total val loss: 0.4859 val r: 0.7348; time: 0.96sec
[168/800][24/24] total train loss: 0.0089; total val loss: 0.4710 val r: 0.7355; time: 0.95sec
[169/800][24/24] total train loss: 0.0093; total val loss: 0.4861 val r: 0.7353; time: 0.95sec
[170/800][24/24] total train loss: 0.0090; total val loss: 0.4923 val r: 0.7347; time: 0.95sec
[171/800][24/24] total train loss: 0.0091; total val loss: 0.4743 val r: 0.7349; time: 0.95sec
[172/800][24/24] total train loss: 0.0090; total val loss: 0.4949 val r: 0.7322; time: 0.95sec
[173/800][24/24] total train loss: 0.0095; total val loss: 0.4868 val r: 0.7311; time: 0.95sec
[174/800][24/24] total train loss: 0.0093; total val loss: 0.4810 val r: 0.7379; time: 0.95sec
[175/800][24/24] total train loss: 0.0095; total val loss: 0.4641 val r: 0.7410; time: 0.94sec
[176/800][24/24] total train loss: 0.0097; total val loss: 0.4680 val r: 0.7370; time: 0.95sec
[177/800][24/24] total train loss: 0.0105; total val loss: 0.4746 val r: 0.7370; time: 0.95sec
[178/800][24/24] total train loss: 0.0086; total val loss: 0.4912 val r: 0.7325; time: 0.94sec
[179/800][24/24] total train loss: 0.0091; total val loss: 0.4728 val r: 0.7341; time: 0.95sec
[180/800][24/24] total train loss: 0.0084; total val loss: 0.4651 val r: 0.7364; time: 0.94sec
[181/800][24/24] total train loss: 0.0083; total val loss: 0.4972 val r: 0.7339; time: 0.95sec
[182/800][24/24] total train loss: 0.0084; total val loss: 0.4527 val r: 0.7407; time: 0.95sec
[183/800][24/24] total train loss: 0.0085; total val loss: 0.4889 val r: 0.7344; time: 0.94sec
[184/800][24/24] total train loss: 0.0089; total val loss: 0.4744 val r: 0.7375; time: 0.95sec
[185/800][24/24] total train loss: 0.0085; total val loss: 0.4776 val r: 0.7345; time: 0.94sec
[186/800][24/24] total train loss: 0.0086; total val loss: 0.4601 val r: 0.7394; time: 0.95sec
[187/800][24/24] total train loss: 0.0087; total val loss: 0.4754 val r: 0.7383; time: 0.95sec
[188/800][24/24] total train loss: 0.0088; total val loss: 0.4626 val r: 0.7384; time: 0.95sec
[189/800][24/24] total train loss: 0.0087; total val loss: 0.4679 val r: 0.7367; time: 0.95sec
[190/800][24/24] total train loss: 0.0083; total val loss: 0.4828 val r: 0.7370; time: 0.96sec
[191/800][24/24] total train loss: 0.0083; total val loss: 0.4748 val r: 0.7352; time: 0.94sec
[192/800][24/24] total train loss: 0.0091; total val loss: 0.4850 val r: 0.7360; time: 0.95sec
[193/800][24/24] total train loss: 0.0084; total val loss: 0.4863 val r: 0.7369; time: 0.95sec
[194/800][24/24] total train loss: 0.0086; total val loss: 0.4725 val r: 0.7354; time: 0.95sec
[195/800][24/24] total train loss: 0.0088; total val loss: 0.4927 val r: 0.7383; time: 0.95sec
[196/800][24/24] total train loss: 0.0087; total val loss: 0.4547 val r: 0.7399; time: 0.95sec
[197/800][24/24] total train loss: 0.0081; total val loss: 0.4764 val r: 0.7367; time: 0.96sec
[198/800][24/24] total train loss: 0.0085; total val loss: 0.4684 val r: 0.7360; time: 0.95sec
[199/800][24/24] total train loss: 0.0087; total val loss: 0.4706 val r: 0.7366; time: 0.95sec
learning rate updated: 0.001
[200/800][24/24] total train loss: 0.0089; total val loss: 0.4790 val r: 0.7341; time: 0.94sec
[201/800][24/24] total train loss: 0.0089; total val loss: 0.4787 val r: 0.7358; time: 0.95sec
[202/800][24/24] total train loss: 0.0087; total val loss: 0.4726 val r: 0.7378; time: 0.95sec
[203/800][24/24] total train loss: 0.0086; total val loss: 0.4816 val r: 0.7344; time: 0.95sec
[204/800][24/24] total train loss: 0.0087; total val loss: 0.4779 val r: 0.7374; time: 0.95sec
[205/800][24/24] total train loss: 0.0087; total val loss: 0.5012 val r: 0.7371; time: 0.95sec
[206/800][24/24] total train loss: 0.0093; total val loss: 0.4744 val r: 0.7353; time: 0.95sec
[207/800][24/24] total train loss: 0.0095; total val loss: 0.4540 val r: 0.7367; time: 0.96sec
[208/800][24/24] total train loss: 0.0099; total val loss: 0.4744 val r: 0.7387; time: 0.95sec
[209/800][24/24] total train loss: 0.0097; total val loss: 0.4842 val r: 0.7376; time: 0.95sec
[210/800][24/24] total train loss: 0.0089; total val loss: 0.4710 val r: 0.7414; time: 0.96sec
[211/800][24/24] total train loss: 0.0092; total val loss: 0.5001 val r: 0.7394; time: 0.95sec
[212/800][24/24] total train loss: 0.0089; total val loss: 0.4676 val r: 0.7383; time: 0.95sec
[213/800][24/24] total train loss: 0.0089; total val loss: 0.4686 val r: 0.7407; time: 0.96sec
[214/800][24/24] total train loss: 0.0086; total val loss: 0.4712 val r: 0.7383; time: 0.95sec
[215/800][24/24] total train loss: 0.0079; total val loss: 0.4933 val r: 0.7354; time: 0.94sec
[216/800][24/24] total train loss: 0.0085; total val loss: 0.4723 val r: 0.7395; time: 0.95sec
[217/800][24/24] total train loss: 0.0087; total val loss: 0.4610 val r: 0.7413; time: 0.95sec
[218/800][24/24] total train loss: 0.0090; total val loss: 0.4762 val r: 0.7399; time: 0.94sec
[219/800][24/24] total train loss: 0.0085; total val loss: 0.5032 val r: 0.7345; time: 0.94sec
[220/800][24/24] total train loss: 0.0090; total val loss: 0.4923 val r: 0.7376; time: 0.94sec
[221/800][24/24] total train loss: 0.0095; total val loss: 0.5029 val r: 0.7333; time: 0.95sec
[222/800][24/24] total train loss: 0.0091; total val loss: 0.4655 val r: 0.7377; time: 0.94sec
[223/800][24/24] total train loss: 0.0084; total val loss: 0.4848 val r: 0.7398; time: 0.95sec
[224/800][24/24] total train loss: 0.0080; total val loss: 0.4905 val r: 0.7310; time: 0.94sec
[225/800][24/24] total train loss: 0.0080; total val loss: 0.4767 val r: 0.7391; time: 0.95sec
[226/800][24/24] total train loss: 0.0081; total val loss: 0.4966 val r: 0.7375; time: 0.95sec
[227/800][24/24] total train loss: 0.0083; total val loss: 0.4788 val r: 0.7381; time: 0.95sec
[228/800][24/24] total train loss: 0.0083; total val loss: 0.4790 val r: 0.7355; time: 0.94sec
[229/800][24/24] total train loss: 0.0080; total val loss: 0.4845 val r: 0.7378; time: 0.95sec
[230/800][24/24] total train loss: 0.0084; total val loss: 0.4878 val r: 0.7364; time: 0.95sec
[231/800][24/24] total train loss: 0.0087; total val loss: 0.4793 val r: 0.7341; time: 0.95sec
[232/800][24/24] total train loss: 0.0093; total val loss: 0.4726 val r: 0.7420; time: 0.95sec
[233/800][24/24] total train loss: 0.0097; total val loss: 0.4833 val r: 0.7441; time: 0.95sec
[234/800][24/24] total train loss: 0.0087; total val loss: 0.4750 val r: 0.7418; time: 0.94sec
[235/800][24/24] total train loss: 0.0083; total val loss: 0.4572 val r: 0.7382; time: 0.95sec
[236/800][24/24] total train loss: 0.0085; total val loss: 0.4885 val r: 0.7428; time: 0.95sec
[237/800][24/24] total train loss: 0.0083; total val loss: 0.4890 val r: 0.7405; time: 0.95sec
[238/800][24/24] total train loss: 0.0082; total val loss: 0.4814 val r: 0.7442; time: 0.94sec
[239/800][24/24] total train loss: 0.0081; total val loss: 0.4727 val r: 0.7448; time: 0.95sec
[240/800][24/24] total train loss: 0.0086; total val loss: 0.4961 val r: 0.7348; time: 0.94sec
[241/800][24/24] total train loss: 0.0089; total val loss: 0.5041 val r: 0.7365; time: 0.94sec
[242/800][24/24] total train loss: 0.0095; total val loss: 0.4819 val r: 0.7370; time: 0.95sec
[243/800][24/24] total train loss: 0.0089; total val loss: 0.4943 val r: 0.7389; time: 0.95sec
[244/800][24/24] total train loss: 0.0086; total val loss: 0.4708 val r: 0.7401; time: 0.95sec
[245/800][24/24] total train loss: 0.0087; total val loss: 0.4801 val r: 0.7413; time: 0.94sec
[246/800][24/24] total train loss: 0.0085; total val loss: 0.4959 val r: 0.7345; time: 0.94sec
[247/800][24/24] total train loss: 0.0079; total val loss: 0.4944 val r: 0.7405; time: 0.96sec
[248/800][24/24] total train loss: 0.0079; total val loss: 0.4810 val r: 0.7356; time: 0.94sec
[249/800][24/24] total train loss: 0.0081; total val loss: 0.4962 val r: 0.7344; time: 0.95sec
[250/800][24/24] total train loss: 0.0080; total val loss: 0.4820 val r: 0.7418; time: 0.95sec
[251/800][24/24] total train loss: 0.0082; total val loss: 0.4864 val r: 0.7392; time: 0.95sec
[252/800][24/24] total train loss: 0.0083; total val loss: 0.4515 val r: 0.7378; time: 0.95sec
[253/800][24/24] total train loss: 0.0083; total val loss: 0.4841 val r: 0.7404; time: 0.95sec
[254/800][24/24] total train loss: 0.0083; total val loss: 0.4797 val r: 0.7382; time: 0.95sec
[255/800][24/24] total train loss: 0.0081; total val loss: 0.4748 val r: 0.7409; time: 0.95sec
[256/800][24/24] total train loss: 0.0082; total val loss: 0.4823 val r: 0.7386; time: 0.95sec
[257/800][24/24] total train loss: 0.0084; total val loss: 0.4835 val r: 0.7375; time: 0.94sec
[258/800][24/24] total train loss: 0.0085; total val loss: 0.4930 val r: 0.7405; time: 0.95sec
[259/800][24/24] total train loss: 0.0084; total val loss: 0.4682 val r: 0.7383; time: 0.94sec
[260/800][24/24] total train loss: 0.0084; total val loss: 0.4820 val r: 0.7379; time: 0.94sec
[261/800][24/24] total train loss: 0.0079; total val loss: 0.4846 val r: 0.7380; time: 0.94sec
[262/800][24/24] total train loss: 0.0078; total val loss: 0.4784 val r: 0.7378; time: 0.94sec
[263/800][24/24] total train loss: 0.0077; total val loss: 0.4861 val r: 0.7398; time: 0.95sec
[264/800][24/24] total train loss: 0.0076; total val loss: 0.4758 val r: 0.7407; time: 0.94sec
[265/800][24/24] total train loss: 0.0077; total val loss: 0.4754 val r: 0.7383; time: 0.96sec
[266/800][24/24] total train loss: 0.0078; total val loss: 0.4681 val r: 0.7417; time: 0.95sec
[267/800][24/24] total train loss: 0.0090; total val loss: 0.4854 val r: 0.7372; time: 0.95sec
[268/800][24/24] total train loss: 0.0086; total val loss: 0.4716 val r: 0.7375; time: 0.95sec
[269/800][24/24] total train loss: 0.0084; total val loss: 0.4682 val r: 0.7377; time: 0.95sec
[270/800][24/24] total train loss: 0.0080; total val loss: 0.4726 val r: 0.7358; time: 0.95sec
[271/800][24/24] total train loss: 0.0078; total val loss: 0.4951 val r: 0.7346; time: 0.94sec
[272/800][24/24] total train loss: 0.0078; total val loss: 0.4836 val r: 0.7390; time: 0.94sec
[273/800][24/24] total train loss: 0.0077; total val loss: 0.4715 val r: 0.7328; time: 0.95sec
[274/800][24/24] total train loss: 0.0077; total val loss: 0.4769 val r: 0.7388; time: 0.94sec
[275/800][24/24] total train loss: 0.0076; total val loss: 0.4703 val r: 0.7353; time: 0.95sec
[276/800][24/24] total train loss: 0.0076; total val loss: 0.4813 val r: 0.7352; time: 0.94sec
[277/800][24/24] total train loss: 0.0079; total val loss: 0.4958 val r: 0.7333; time: 0.95sec
[278/800][24/24] total train loss: 0.0083; total val loss: 0.4711 val r: 0.7378; time: 0.94sec
[279/800][24/24] total train loss: 0.0081; total val loss: 0.4774 val r: 0.7374; time: 0.94sec
[280/800][24/24] total train loss: 0.0079; total val loss: 0.4505 val r: 0.7362; time: 0.94sec
[281/800][24/24] total train loss: 0.0078; total val loss: 0.4879 val r: 0.7379; time: 0.95sec
[282/800][24/24] total train loss: 0.0078; total val loss: 0.4733 val r: 0.7427; time: 0.95sec
[283/800][24/24] total train loss: 0.0080; total val loss: 0.4758 val r: 0.7351; time: 0.95sec
[284/800][24/24] total train loss: 0.0080; total val loss: 0.4730 val r: 0.7385; time: 0.95sec
[285/800][24/24] total train loss: 0.0082; total val loss: 0.4600 val r: 0.7378; time: 0.94sec
[286/800][24/24] total train loss: 0.0081; total val loss: 0.4688 val r: 0.7385; time: 0.95sec
[287/800][24/24] total train loss: 0.0084; total val loss: 0.4745 val r: 0.7358; time: 0.94sec
[288/800][24/24] total train loss: 0.0087; total val loss: 0.4613 val r: 0.7402; time: 0.95sec
[289/800][24/24] total train loss: 0.0084; total val loss: 0.4957 val r: 0.7343; time: 0.94sec
[290/800][24/24] total train loss: 0.0089; total val loss: 0.4568 val r: 0.7452; time: 0.94sec
[291/800][24/24] total train loss: 0.0086; total val loss: 0.4705 val r: 0.7353; time: 0.93sec
[292/800][24/24] total train loss: 0.0080; total val loss: 0.4813 val r: 0.7362; time: 0.94sec
[293/800][24/24] total train loss: 0.0078; total val loss: 0.4959 val r: 0.7390; time: 0.95sec
[294/800][24/24] total train loss: 0.0079; total val loss: 0.4585 val r: 0.7409; time: 0.95sec
[295/800][24/24] total train loss: 0.0079; total val loss: 0.4696 val r: 0.7410; time: 0.94sec
[296/800][24/24] total train loss: 0.0078; total val loss: 0.4485 val r: 0.7391; time: 0.94sec
[297/800][24/24] total train loss: 0.0077; total val loss: 0.4800 val r: 0.7407; time: 0.96sec
[298/800][24/24] total train loss: 0.0076; total val loss: 0.4847 val r: 0.7387; time: 0.94sec
[299/800][24/24] total train loss: 0.0077; total val loss: 0.4799 val r: 0.7334; time: 0.95sec
learning rate updated: 0.001
[300/800][24/24] total train loss: 0.0078; total val loss: 0.4706 val r: 0.7383; time: 0.95sec
[301/800][24/24] total train loss: 0.0078; total val loss: 0.4811 val r: 0.7375; time: 0.95sec
[302/800][24/24] total train loss: 0.0079; total val loss: 0.4905 val r: 0.7368; time: 0.95sec
[303/800][24/24] total train loss: 0.0079; total val loss: 0.4738 val r: 0.7363; time: 0.95sec
[304/800][24/24] total train loss: 0.0090; total val loss: 0.4606 val r: 0.7369; time: 0.95sec
[305/800][24/24] total train loss: 0.0090; total val loss: 0.4715 val r: 0.7320; time: 0.95sec
[306/800][24/24] total train loss: 0.0090; total val loss: 0.4825 val r: 0.7327; time: 0.95sec
[307/800][24/24] total train loss: 0.0087; total val loss: 0.4885 val r: 0.7383; time: 0.95sec
[308/800][24/24] total train loss: 0.0083; total val loss: 0.4870 val r: 0.7337; time: 0.95sec
[309/800][24/24] total train loss: 0.0083; total val loss: 0.4794 val r: 0.7366; time: 0.95sec
[310/800][24/24] total train loss: 0.0082; total val loss: 0.4761 val r: 0.7342; time: 0.95sec
[311/800][24/24] total train loss: 0.0077; total val loss: 0.4849 val r: 0.7364; time: 0.95sec
[312/800][24/24] total train loss: 0.0075; total val loss: 0.4848 val r: 0.7367; time: 0.95sec
[313/800][24/24] total train loss: 0.0075; total val loss: 0.4696 val r: 0.7373; time: 0.95sec
[314/800][24/24] total train loss: 0.0075; total val loss: 0.4703 val r: 0.7367; time: 0.95sec
[315/800][24/24] total train loss: 0.0080; total val loss: 0.4928 val r: 0.7366; time: 0.96sec
[316/800][24/24] total train loss: 0.0076; total val loss: 0.4811 val r: 0.7346; time: 0.94sec
[317/800][24/24] total train loss: 0.0080; total val loss: 0.4701 val r: 0.7342; time: 0.95sec
[318/800][24/24] total train loss: 0.0079; total val loss: 0.4709 val r: 0.7367; time: 0.94sec
[319/800][24/24] total train loss: 0.0079; total val loss: 0.4922 val r: 0.7395; time: 0.95sec
[320/800][24/24] total train loss: 0.0076; total val loss: 0.4806 val r: 0.7365; time: 0.94sec
[321/800][24/24] total train loss: 0.0078; total val loss: 0.4638 val r: 0.7362; time: 0.94sec
[322/800][24/24] total train loss: 0.0077; total val loss: 0.4826 val r: 0.7371; time: 0.95sec
[323/800][24/24] total train loss: 0.0079; total val loss: 0.4863 val r: 0.7313; time: 0.95sec
[324/800][24/24] total train loss: 0.0079; total val loss: 0.4631 val r: 0.7372; time: 0.95sec
[325/800][24/24] total train loss: 0.0073; total val loss: 0.4887 val r: 0.7329; time: 0.95sec
[326/800][24/24] total train loss: 0.0075; total val loss: 0.4911 val r: 0.7320; time: 0.95sec
[327/800][24/24] total train loss: 0.0079; total val loss: 0.4682 val r: 0.7372; time: 0.95sec
[328/800][24/24] total train loss: 0.0079; total val loss: 0.4659 val r: 0.7343; time: 0.95sec
[329/800][24/24] total train loss: 0.0076; total val loss: 0.4546 val r: 0.7374; time: 0.94sec
[330/800][24/24] total train loss: 0.0079; total val loss: 0.4714 val r: 0.7388; time: 0.95sec
[331/800][24/24] total train loss: 0.0083; total val loss: 0.4807 val r: 0.7399; time: 0.95sec
[332/800][24/24] total train loss: 0.0081; total val loss: 0.4850 val r: 0.7353; time: 0.95sec
[333/800][24/24] total train loss: 0.0080; total val loss: 0.4966 val r: 0.7296; time: 0.96sec
[334/800][24/24] total train loss: 0.0077; total val loss: 0.4868 val r: 0.7366; time: 0.96sec
[335/800][24/24] total train loss: 0.0076; total val loss: 0.4781 val r: 0.7395; time: 0.94sec
[336/800][24/24] total train loss: 0.0076; total val loss: 0.4920 val r: 0.7325; time: 0.95sec
[337/800][24/24] total train loss: 0.0078; total val loss: 0.4908 val r: 0.7348; time: 0.95sec
[338/800][24/24] total train loss: 0.0078; total val loss: 0.4717 val r: 0.7347; time: 0.94sec
[339/800][24/24] total train loss: 0.0080; total val loss: 0.4714 val r: 0.7398; time: 0.95sec
[340/800][24/24] total train loss: 0.0078; total val loss: 0.4931 val r: 0.7347; time: 0.95sec
[341/800][24/24] total train loss: 0.0080; total val loss: 0.4833 val r: 0.7371; time: 0.95sec
[342/800][24/24] total train loss: 0.0078; total val loss: 0.4920 val r: 0.7365; time: 0.95sec
[343/800][24/24] total train loss: 0.0074; total val loss: 0.4781 val r: 0.7383; time: 0.96sec
[344/800][24/24] total train loss: 0.0076; total val loss: 0.4846 val r: 0.7389; time: 0.95sec
[345/800][24/24] total train loss: 0.0074; total val loss: 0.4469 val r: 0.7381; time: 0.94sec
[346/800][24/24] total train loss: 0.0073; total val loss: 0.4733 val r: 0.7372; time: 0.95sec
[347/800][24/24] total train loss: 0.0072; total val loss: 0.4782 val r: 0.7388; time: 0.95sec
[348/800][24/24] total train loss: 0.0074; total val loss: 0.4573 val r: 0.7349; time: 0.96sec
[349/800][24/24] total train loss: 0.0075; total val loss: 0.4910 val r: 0.7370; time: 0.95sec
[350/800][24/24] total train loss: 0.0073; total val loss: 0.4668 val r: 0.7366; time: 0.94sec
[351/800][24/24] total train loss: 0.0075; total val loss: 0.4627 val r: 0.7424; time: 0.95sec
[352/800][24/24] total train loss: 0.0077; total val loss: 0.4729 val r: 0.7337; time: 0.94sec
[353/800][24/24] total train loss: 0.0076; total val loss: 0.4888 val r: 0.7347; time: 0.94sec
[354/800][24/24] total train loss: 0.0076; total val loss: 0.4762 val r: 0.7349; time: 0.95sec
[355/800][24/24] total train loss: 0.0075; total val loss: 0.4751 val r: 0.7358; time: 0.94sec
[356/800][24/24] total train loss: 0.0076; total val loss: 0.4880 val r: 0.7367; time: 0.95sec
[357/800][24/24] total train loss: 0.0077; total val loss: 0.4705 val r: 0.7343; time: 0.95sec
[358/800][24/24] total train loss: 0.0073; total val loss: 0.4842 val r: 0.7400; time: 0.95sec
[359/800][24/24] total train loss: 0.0076; total val loss: 0.4895 val r: 0.7343; time: 0.95sec
[360/800][24/24] total train loss: 0.0074; total val loss: 0.4678 val r: 0.7377; time: 0.95sec
[361/800][24/24] total train loss: 0.0075; total val loss: 0.4942 val r: 0.7360; time: 0.95sec
[362/800][24/24] total train loss: 0.0074; total val loss: 0.4655 val r: 0.7395; time: 0.94sec
[363/800][24/24] total train loss: 0.0078; total val loss: 0.4748 val r: 0.7369; time: 0.95sec
[364/800][24/24] total train loss: 0.0074; total val loss: 0.4648 val r: 0.7382; time: 0.95sec
[365/800][24/24] total train loss: 0.0076; total val loss: 0.4707 val r: 0.7363; time: 0.95sec
[366/800][24/24] total train loss: 0.0078; total val loss: 0.4806 val r: 0.7355; time: 0.95sec
[367/800][24/24] total train loss: 0.0073; total val loss: 0.4842 val r: 0.7374; time: 0.94sec
[368/800][24/24] total train loss: 0.0075; total val loss: 0.4748 val r: 0.7364; time: 0.96sec
[369/800][24/24] total train loss: 0.0077; total val loss: 0.4751 val r: 0.7354; time: 0.95sec
[370/800][24/24] total train loss: 0.0074; total val loss: 0.4666 val r: 0.7389; time: 0.95sec
[371/800][24/24] total train loss: 0.0076; total val loss: 0.4991 val r: 0.7353; time: 0.95sec
[372/800][24/24] total train loss: 0.0074; total val loss: 0.4720 val r: 0.7383; time: 0.95sec
[373/800][24/24] total train loss: 0.0074; total val loss: 0.4703 val r: 0.7369; time: 0.94sec
[374/800][24/24] total train loss: 0.0079; total val loss: 0.4798 val r: 0.7337; time: 0.94sec
[375/800][24/24] total train loss: 0.0075; total val loss: 0.4871 val r: 0.7391; time: 0.95sec
[376/800][24/24] total train loss: 0.0075; total val loss: 0.4656 val r: 0.7366; time: 0.95sec
[377/800][24/24] total train loss: 0.0073; total val loss: 0.4682 val r: 0.7387; time: 0.95sec
[378/800][24/24] total train loss: 0.0072; total val loss: 0.4842 val r: 0.7361; time: 0.95sec
[379/800][24/24] total train loss: 0.0073; total val loss: 0.4767 val r: 0.7374; time: 0.95sec
[380/800][24/24] total train loss: 0.0075; total val loss: 0.4732 val r: 0.7344; time: 0.95sec
[381/800][24/24] total train loss: 0.0075; total val loss: 0.4726 val r: 0.7390; time: 0.95sec
[382/800][24/24] total train loss: 0.0074; total val loss: 0.4710 val r: 0.7405; time: 0.95sec
[383/800][24/24] total train loss: 0.0075; total val loss: 0.4733 val r: 0.7415; time: 0.95sec
[384/800][24/24] total train loss: 0.0075; total val loss: 0.4658 val r: 0.7365; time: 0.95sec
[385/800][24/24] total train loss: 0.0071; total val loss: 0.4682 val r: 0.7387; time: 0.95sec
[386/800][24/24] total train loss: 0.0070; total val loss: 0.4703 val r: 0.7396; time: 0.95sec
[387/800][24/24] total train loss: 0.0073; total val loss: 0.4788 val r: 0.7393; time: 0.95sec
[388/800][24/24] total train loss: 0.0073; total val loss: 0.4929 val r: 0.7375; time: 0.95sec
[389/800][24/24] total train loss: 0.0075; total val loss: 0.4771 val r: 0.7410; time: 0.95sec
[390/800][24/24] total train loss: 0.0072; total val loss: 0.4714 val r: 0.7366; time: 0.95sec
[391/800][24/24] total train loss: 0.0072; total val loss: 0.4753 val r: 0.7425; time: 0.95sec
[392/800][24/24] total train loss: 0.0073; total val loss: 0.4814 val r: 0.7432; time: 0.95sec
[393/800][24/24] total train loss: 0.0074; total val loss: 0.4920 val r: 0.7372; time: 0.95sec
[394/800][24/24] total train loss: 0.0079; total val loss: 0.4786 val r: 0.7362; time: 0.95sec
[395/800][24/24] total train loss: 0.0078; total val loss: 0.4763 val r: 0.7400; time: 0.95sec
[396/800][24/24] total train loss: 0.0075; total val loss: 0.4969 val r: 0.7369; time: 0.95sec
[397/800][24/24] total train loss: 0.0076; total val loss: 0.4826 val r: 0.7397; time: 0.95sec
[398/800][24/24] total train loss: 0.0078; total val loss: 0.4631 val r: 0.7438; time: 0.94sec
[399/800][24/24] total train loss: 0.0073; total val loss: 0.4811 val r: 0.7351; time: 0.96sec
learning rate updated: 0.001
[400/800][24/24] total train loss: 0.0077; total val loss: 0.4799 val r: 0.7370; time: 0.95sec
[401/800][24/24] total train loss: 0.0078; total val loss: 0.5032 val r: 0.7334; time: 0.95sec
[402/800][24/24] total train loss: 0.0074; total val loss: 0.4826 val r: 0.7396; time: 0.95sec
[403/800][24/24] total train loss: 0.0073; total val loss: 0.4673 val r: 0.7365; time: 0.94sec
[404/800][24/24] total train loss: 0.0073; total val loss: 0.4892 val r: 0.7369; time: 0.95sec
[405/800][24/24] total train loss: 0.0073; total val loss: 0.4811 val r: 0.7389; time: 0.95sec
[406/800][24/24] total train loss: 0.0074; total val loss: 0.5004 val r: 0.7342; time: 0.95sec
[407/800][24/24] total train loss: 0.0074; total val loss: 0.4818 val r: 0.7385; time: 0.94sec
[408/800][24/24] total train loss: 0.0072; total val loss: 0.4682 val r: 0.7381; time: 0.93sec
[409/800][24/24] total train loss: 0.0072; total val loss: 0.4733 val r: 0.7390; time: 0.95sec
[410/800][24/24] total train loss: 0.0075; total val loss: 0.4860 val r: 0.7370; time: 0.95sec
[411/800][24/24] total train loss: 0.0073; total val loss: 0.4759 val r: 0.7375; time: 0.95sec
[412/800][24/24] total train loss: 0.0073; total val loss: 0.4751 val r: 0.7388; time: 0.94sec
[413/800][24/24] total train loss: 0.0072; total val loss: 0.4591 val r: 0.7374; time: 0.94sec
[414/800][24/24] total train loss: 0.0073; total val loss: 0.4882 val r: 0.7375; time: 0.95sec
[415/800][24/24] total train loss: 0.0077; total val loss: 0.4684 val r: 0.7401; time: 0.95sec
[416/800][24/24] total train loss: 0.0075; total val loss: 0.5064 val r: 0.7343; time: 0.95sec
[417/800][24/24] total train loss: 0.0074; total val loss: 0.4606 val r: 0.7384; time: 0.94sec
[418/800][24/24] total train loss: 0.0075; total val loss: 0.4867 val r: 0.7370; time: 0.95sec
[419/800][24/24] total train loss: 0.0075; total val loss: 0.4804 val r: 0.7370; time: 0.94sec
[420/800][24/24] total train loss: 0.0076; total val loss: 0.4722 val r: 0.7366; time: 0.95sec
[421/800][24/24] total train loss: 0.0074; total val loss: 0.4835 val r: 0.7375; time: 0.94sec
[422/800][24/24] total train loss: 0.0074; total val loss: 0.4694 val r: 0.7362; time: 0.95sec
[423/800][24/24] total train loss: 0.0076; total val loss: 0.4757 val r: 0.7369; time: 0.96sec
[424/800][24/24] total train loss: 0.0074; total val loss: 0.4811 val r: 0.7400; time: 0.96sec
[425/800][24/24] total train loss: 0.0073; total val loss: 0.4588 val r: 0.7405; time: 0.95sec
[426/800][24/24] total train loss: 0.0073; total val loss: 0.4710 val r: 0.7380; time: 0.94sec
[427/800][24/24] total train loss: 0.0074; total val loss: 0.4658 val r: 0.7351; time: 0.95sec
[428/800][24/24] total train loss: 0.0075; total val loss: 0.4859 val r: 0.7355; time: 0.94sec
[429/800][24/24] total train loss: 0.0074; total val loss: 0.4934 val r: 0.7412; time: 0.94sec
[430/800][24/24] total train loss: 0.0076; total val loss: 0.4913 val r: 0.7337; time: 0.96sec
[431/800][24/24] total train loss: 0.0074; total val loss: 0.4744 val r: 0.7371; time: 0.94sec
[432/800][24/24] total train loss: 0.0073; total val loss: 0.4732 val r: 0.7353; time: 0.94sec
[433/800][24/24] total train loss: 0.0072; total val loss: 0.4793 val r: 0.7333; time: 0.94sec
[434/800][24/24] total train loss: 0.0074; total val loss: 0.4731 val r: 0.7382; time: 0.95sec
[435/800][24/24] total train loss: 0.0075; total val loss: 0.4852 val r: 0.7346; time: 0.95sec
[436/800][24/24] total train loss: 0.0075; total val loss: 0.4702 val r: 0.7368; time: 0.95sec
[437/800][24/24] total train loss: 0.0078; total val loss: 0.4785 val r: 0.7349; time: 0.94sec
[438/800][24/24] total train loss: 0.0076; total val loss: 0.4710 val r: 0.7357; time: 0.96sec
[439/800][24/24] total train loss: 0.0075; total val loss: 0.4767 val r: 0.7395; time: 0.95sec
[440/800][24/24] total train loss: 0.0075; total val loss: 0.4944 val r: 0.7360; time: 0.96sec
[441/800][24/24] total train loss: 0.0073; total val loss: 0.4801 val r: 0.7362; time: 0.95sec
[442/800][24/24] total train loss: 0.0075; total val loss: 0.4793 val r: 0.7360; time: 0.94sec
[443/800][24/24] total train loss: 0.0073; total val loss: 0.4754 val r: 0.7356; time: 0.95sec
[444/800][24/24] total train loss: 0.0073; total val loss: 0.4772 val r: 0.7386; time: 0.95sec
[445/800][24/24] total train loss: 0.0074; total val loss: 0.4643 val r: 0.7368; time: 0.95sec
[446/800][24/24] total train loss: 0.0074; total val loss: 0.4709 val r: 0.7403; time: 0.95sec
[447/800][24/24] total train loss: 0.0072; total val loss: 0.4910 val r: 0.7353; time: 0.95sec
[448/800][24/24] total train loss: 0.0073; total val loss: 0.4771 val r: 0.7321; time: 0.94sec
[449/800][24/24] total train loss: 0.0073; total val loss: 0.4716 val r: 0.7358; time: 0.94sec
[450/800][24/24] total train loss: 0.0072; total val loss: 0.4876 val r: 0.7347; time: 0.94sec
[451/800][24/24] total train loss: 0.0073; total val loss: 0.4814 val r: 0.7329; time: 0.95sec
[452/800][24/24] total train loss: 0.0073; total val loss: 0.4797 val r: 0.7327; time: 0.96sec
[453/800][24/24] total train loss: 0.0073; total val loss: 0.4519 val r: 0.7375; time: 0.94sec
[454/800][24/24] total train loss: 0.0071; total val loss: 0.4879 val r: 0.7369; time: 0.95sec
[455/800][24/24] total train loss: 0.0076; total val loss: 0.4779 val r: 0.7376; time: 0.95sec
[456/800][24/24] total train loss: 0.0075; total val loss: 0.4817 val r: 0.7348; time: 0.94sec
[457/800][24/24] total train loss: 0.0071; total val loss: 0.4936 val r: 0.7357; time: 0.95sec
[458/800][24/24] total train loss: 0.0074; total val loss: 0.4957 val r: 0.7376; time: 0.94sec
[459/800][24/24] total train loss: 0.0073; total val loss: 0.4777 val r: 0.7352; time: 0.95sec
[460/800][24/24] total train loss: 0.0074; total val loss: 0.4822 val r: 0.7367; time: 0.95sec
[461/800][24/24] total train loss: 0.0073; total val loss: 0.4891 val r: 0.7353; time: 0.95sec
[462/800][24/24] total train loss: 0.0074; total val loss: 0.4725 val r: 0.7391; time: 0.95sec
[463/800][24/24] total train loss: 0.0073; total val loss: 0.4827 val r: 0.7358; time: 0.95sec
[464/800][24/24] total train loss: 0.0075; total val loss: 0.4678 val r: 0.7390; time: 0.95sec
[465/800][24/24] total train loss: 0.0074; total val loss: 0.4641 val r: 0.7365; time: 0.94sec
[466/800][24/24] total train loss: 0.0074; total val loss: 0.4760 val r: 0.7397; time: 0.94sec
[467/800][24/24] total train loss: 0.0078; total val loss: 0.4774 val r: 0.7375; time: 0.95sec
[468/800][24/24] total train loss: 0.0074; total val loss: 0.4929 val r: 0.7359; time: 0.94sec
[469/800][24/24] total train loss: 0.0074; total val loss: 0.4902 val r: 0.7360; time: 0.95sec
[470/800][24/24] total train loss: 0.0074; total val loss: 0.4444 val r: 0.7367; time: 0.95sec
[471/800][24/24] total train loss: 0.0072; total val loss: 0.4833 val r: 0.7324; time: 0.94sec
[472/800][24/24] total train loss: 0.0072; total val loss: 0.4831 val r: 0.7370; time: 0.94sec
[473/800][24/24] total train loss: 0.0073; total val loss: 0.4818 val r: 0.7382; time: 0.95sec
[474/800][24/24] total train loss: 0.0072; total val loss: 0.4644 val r: 0.7363; time: 0.95sec
[475/800][24/24] total train loss: 0.0072; total val loss: 0.4772 val r: 0.7395; time: 0.95sec
[476/800][24/24] total train loss: 0.0074; total val loss: 0.4742 val r: 0.7390; time: 0.95sec
[477/800][24/24] total train loss: 0.0073; total val loss: 0.4887 val r: 0.7364; time: 0.95sec
[478/800][24/24] total train loss: 0.0075; total val loss: 0.5011 val r: 0.7387; time: 0.94sec
[479/800][24/24] total train loss: 0.0076; total val loss: 0.4828 val r: 0.7355; time: 0.95sec
[480/800][24/24] total train loss: 0.0076; total val loss: 0.4853 val r: 0.7386; time: 0.94sec
[481/800][24/24] total train loss: 0.0074; total val loss: 0.4604 val r: 0.7364; time: 0.96sec
[482/800][24/24] total train loss: 0.0074; total val loss: 0.4950 val r: 0.7387; time: 0.95sec
[483/800][24/24] total train loss: 0.0073; total val loss: 0.4929 val r: 0.7357; time: 0.95sec
[484/800][24/24] total train loss: 0.0074; total val loss: 0.4809 val r: 0.7322; time: 0.94sec
[485/800][24/24] total train loss: 0.0074; total val loss: 0.4836 val r: 0.7361; time: 0.94sec
[486/800][24/24] total train loss: 0.0072; total val loss: 0.4644 val r: 0.7353; time: 0.95sec
[487/800][24/24] total train loss: 0.0073; total val loss: 0.4602 val r: 0.7363; time: 0.94sec
[488/800][24/24] total train loss: 0.0073; total val loss: 0.4863 val r: 0.7387; time: 0.95sec
[489/800][24/24] total train loss: 0.0072; total val loss: 0.4923 val r: 0.7324; time: 0.94sec
[490/800][24/24] total train loss: 0.0073; total val loss: 0.4866 val r: 0.7346; time: 0.94sec
[491/800][24/24] total train loss: 0.0070; total val loss: 0.4875 val r: 0.7325; time: 0.95sec
[492/800][24/24] total train loss: 0.0073; total val loss: 0.4671 val r: 0.7342; time: 0.95sec
[493/800][24/24] total train loss: 0.0072; total val loss: 0.4796 val r: 0.7368; time: 0.95sec
[494/800][24/24] total train loss: 0.0074; total val loss: 0.4722 val r: 0.7365; time: 0.95sec
[495/800][24/24] total train loss: 0.0073; total val loss: 0.5097 val r: 0.7322; time: 0.95sec
[496/800][24/24] total train loss: 0.0073; total val loss: 0.4734 val r: 0.7386; time: 0.94sec
[497/800][24/24] total train loss: 0.0075; total val loss: 0.4799 val r: 0.7371; time: 0.94sec
[498/800][24/24] total train loss: 0.0073; total val loss: 0.4720 val r: 0.7342; time: 0.95sec
[499/800][24/24] total train loss: 0.0074; total val loss: 0.4863 val r: 0.7354; time: 0.95sec
learning rate updated: 0.001
[500/800][24/24] total train loss: 0.0071; total val loss: 0.4681 val r: 0.7356; time: 0.96sec
[501/800][24/24] total train loss: 0.0071; total val loss: 0.4996 val r: 0.7359; time: 0.95sec
[502/800][24/24] total train loss: 0.0072; total val loss: 0.4973 val r: 0.7378; time: 0.95sec
[503/800][24/24] total train loss: 0.0073; total val loss: 0.4777 val r: 0.7338; time: 0.95sec
[504/800][24/24] total train loss: 0.0071; total val loss: 0.4868 val r: 0.7372; time: 0.94sec
[505/800][24/24] total train loss: 0.0070; total val loss: 0.4918 val r: 0.7376; time: 0.96sec
[506/800][24/24] total train loss: 0.0072; total val loss: 0.4898 val r: 0.7378; time: 0.95sec
[507/800][24/24] total train loss: 0.0071; total val loss: 0.4801 val r: 0.7394; time: 0.95sec
[508/800][24/24] total train loss: 0.0071; total val loss: 0.4936 val r: 0.7359; time: 0.95sec
[509/800][24/24] total train loss: 0.0071; total val loss: 0.4886 val r: 0.7355; time: 0.95sec
[510/800][24/24] total train loss: 0.0071; total val loss: 0.4936 val r: 0.7373; time: 0.96sec
[511/800][24/24] total train loss: 0.0071; total val loss: 0.4901 val r: 0.7363; time: 0.95sec
[512/800][24/24] total train loss: 0.0071; total val loss: 0.4843 val r: 0.7366; time: 0.95sec
[513/800][24/24] total train loss: 0.0071; total val loss: 0.4778 val r: 0.7355; time: 0.95sec
[514/800][24/24] total train loss: 0.0070; total val loss: 0.4859 val r: 0.7354; time: 0.95sec
[515/800][24/24] total train loss: 0.0070; total val loss: 0.4847 val r: 0.7387; time: 0.95sec
[516/800][24/24] total train loss: 0.0068; total val loss: 0.4835 val r: 0.7358; time: 0.94sec
[517/800][24/24] total train loss: 0.0071; total val loss: 0.4781 val r: 0.7425; time: 0.95sec
[518/800][24/24] total train loss: 0.0072; total val loss: 0.4792 val r: 0.7372; time: 0.95sec
[519/800][24/24] total train loss: 0.0070; total val loss: 0.4638 val r: 0.7365; time: 0.95sec
[520/800][24/24] total train loss: 0.0071; total val loss: 0.4871 val r: 0.7368; time: 0.95sec
[521/800][24/24] total train loss: 0.0071; total val loss: 0.4724 val r: 0.7389; time: 0.95sec
[522/800][24/24] total train loss: 0.0073; total val loss: 0.4737 val r: 0.7376; time: 0.95sec
[523/800][24/24] total train loss: 0.0073; total val loss: 0.4683 val r: 0.7405; time: 0.95sec
[524/800][24/24] total train loss: 0.0074; total val loss: 0.4817 val r: 0.7374; time: 0.95sec
[525/800][24/24] total train loss: 0.0075; total val loss: 0.4761 val r: 0.7377; time: 0.94sec
[526/800][24/24] total train loss: 0.0074; total val loss: 0.4956 val r: 0.7349; time: 0.95sec
[527/800][24/24] total train loss: 0.0073; total val loss: 0.4776 val r: 0.7351; time: 0.95sec
[528/800][24/24] total train loss: 0.0071; total val loss: 0.4671 val r: 0.7344; time: 0.95sec
[529/800][24/24] total train loss: 0.0074; total val loss: 0.4764 val r: 0.7328; time: 0.95sec
[530/800][24/24] total train loss: 0.0072; total val loss: 0.5081 val r: 0.7332; time: 0.95sec
[531/800][24/24] total train loss: 0.0070; total val loss: 0.4830 val r: 0.7387; time: 0.94sec
[532/800][24/24] total train loss: 0.0071; total val loss: 0.4628 val r: 0.7348; time: 0.94sec
[533/800][24/24] total train loss: 0.0070; total val loss: 0.4778 val r: 0.7360; time: 0.94sec
[534/800][24/24] total train loss: 0.0070; total val loss: 0.4890 val r: 0.7388; time: 0.94sec
[535/800][24/24] total train loss: 0.0072; total val loss: 0.4684 val r: 0.7391; time: 0.94sec
[536/800][24/24] total train loss: 0.0071; total val loss: 0.4895 val r: 0.7354; time: 0.94sec
[537/800][24/24] total train loss: 0.0073; total val loss: 0.4847 val r: 0.7387; time: 0.94sec
[538/800][24/24] total train loss: 0.0071; total val loss: 0.4790 val r: 0.7366; time: 0.94sec
[539/800][24/24] total train loss: 0.0072; total val loss: 0.4926 val r: 0.7386; time: 0.94sec
[540/800][24/24] total train loss: 0.0075; total val loss: 0.4762 val r: 0.7363; time: 0.94sec
[541/800][24/24] total train loss: 0.0072; total val loss: 0.4919 val r: 0.7357; time: 0.95sec
[542/800][24/24] total train loss: 0.0071; total val loss: 0.4816 val r: 0.7340; time: 0.95sec
[543/800][24/24] total train loss: 0.0072; total val loss: 0.4485 val r: 0.7320; time: 0.95sec
[544/800][24/24] total train loss: 0.0071; total val loss: 0.4713 val r: 0.7345; time: 0.95sec
[545/800][24/24] total train loss: 0.0070; total val loss: 0.4756 val r: 0.7362; time: 0.95sec
[546/800][24/24] total train loss: 0.0070; total val loss: 0.4764 val r: 0.7339; time: 0.95sec
[547/800][24/24] total train loss: 0.0072; total val loss: 0.4832 val r: 0.7343; time: 0.95sec
[548/800][24/24] total train loss: 0.0070; total val loss: 0.4803 val r: 0.7341; time: 0.94sec
[549/800][24/24] total train loss: 0.0072; total val loss: 0.4809 val r: 0.7327; time: 0.94sec
[550/800][24/24] total train loss: 0.0073; total val loss: 0.4675 val r: 0.7368; time: 0.96sec
[551/800][24/24] total train loss: 0.0072; total val loss: 0.4837 val r: 0.7346; time: 0.96sec
[552/800][24/24] total train loss: 0.0072; total val loss: 0.4921 val r: 0.7361; time: 0.95sec
[553/800][24/24] total train loss: 0.0070; total val loss: 0.4954 val r: 0.7328; time: 0.95sec
[554/800][24/24] total train loss: 0.0072; total val loss: 0.4894 val r: 0.7342; time: 0.94sec
[555/800][24/24] total train loss: 0.0071; total val loss: 0.4811 val r: 0.7373; time: 0.95sec
[556/800][24/24] total train loss: 0.0070; total val loss: 0.4856 val r: 0.7333; time: 0.95sec
[557/800][24/24] total train loss: 0.0069; total val loss: 0.4853 val r: 0.7326; time: 0.95sec
[558/800][24/24] total train loss: 0.0072; total val loss: 0.4766 val r: 0.7332; time: 0.94sec
[559/800][24/24] total train loss: 0.0071; total val loss: 0.4814 val r: 0.7342; time: 0.95sec
[560/800][24/24] total train loss: 0.0073; total val loss: 0.4782 val r: 0.7341; time: 0.96sec
[561/800][24/24] total train loss: 0.0071; total val loss: 0.4715 val r: 0.7331; time: 0.95sec
[562/800][24/24] total train loss: 0.0072; total val loss: 0.4923 val r: 0.7318; time: 0.95sec
[563/800][24/24] total train loss: 0.0070; total val loss: 0.4780 val r: 0.7313; time: 0.95sec
[564/800][24/24] total train loss: 0.0070; total val loss: 0.4873 val r: 0.7326; time: 0.95sec
[565/800][24/24] total train loss: 0.0070; total val loss: 0.4818 val r: 0.7346; time: 0.95sec
[566/800][24/24] total train loss: 0.0070; total val loss: 0.4700 val r: 0.7333; time: 0.95sec
[567/800][24/24] total train loss: 0.0072; total val loss: 0.4718 val r: 0.7311; time: 0.94sec
[568/800][24/24] total train loss: 0.0073; total val loss: 0.4733 val r: 0.7378; time: 0.95sec
[569/800][24/24] total train loss: 0.0071; total val loss: 0.4893 val r: 0.7327; time: 0.95sec
[570/800][24/24] total train loss: 0.0072; total val loss: 0.4827 val r: 0.7313; time: 0.95sec
[571/800][24/24] total train loss: 0.0072; total val loss: 0.4677 val r: 0.7335; time: 0.95sec
[572/800][24/24] total train loss: 0.0071; total val loss: 0.5114 val r: 0.7359; time: 0.94sec
[573/800][24/24] total train loss: 0.0069; total val loss: 0.4928 val r: 0.7354; time: 0.95sec
[574/800][24/24] total train loss: 0.0071; total val loss: 0.4713 val r: 0.7343; time: 0.94sec
[575/800][24/24] total train loss: 0.0072; total val loss: 0.4741 val r: 0.7345; time: 0.95sec
[576/800][24/24] total train loss: 0.0069; total val loss: 0.4784 val r: 0.7345; time: 0.95sec
[577/800][24/24] total train loss: 0.0068; total val loss: 0.4811 val r: 0.7355; time: 0.95sec
[578/800][24/24] total train loss: 0.0071; total val loss: 0.4852 val r: 0.7331; time: 0.95sec
[579/800][24/24] total train loss: 0.0071; total val loss: 0.4838 val r: 0.7346; time: 0.94sec
[580/800][24/24] total train loss: 0.0070; total val loss: 0.4908 val r: 0.7345; time: 0.94sec
[581/800][24/24] total train loss: 0.0073; total val loss: 0.4905 val r: 0.7333; time: 0.95sec
[582/800][24/24] total train loss: 0.0072; total val loss: 0.4799 val r: 0.7340; time: 0.95sec
[583/800][24/24] total train loss: 0.0071; total val loss: 0.4731 val r: 0.7320; time: 0.95sec
[584/800][24/24] total train loss: 0.0070; total val loss: 0.4584 val r: 0.7335; time: 0.95sec
[585/800][24/24] total train loss: 0.0072; total val loss: 0.4690 val r: 0.7355; time: 0.94sec
[586/800][24/24] total train loss: 0.0071; total val loss: 0.4952 val r: 0.7345; time: 0.95sec
[587/800][24/24] total train loss: 0.0068; total val loss: 0.4724 val r: 0.7339; time: 0.95sec
[588/800][24/24] total train loss: 0.0069; total val loss: 0.4849 val r: 0.7357; time: 0.95sec
[589/800][24/24] total train loss: 0.0070; total val loss: 0.4748 val r: 0.7320; time: 0.95sec
[590/800][24/24] total train loss: 0.0072; total val loss: 0.5084 val r: 0.7311; time: 0.95sec
[591/800][24/24] total train loss: 0.0076; total val loss: 0.4571 val r: 0.7319; time: 0.94sec
[592/800][24/24] total train loss: 0.0073; total val loss: 0.5043 val r: 0.7348; time: 0.94sec
[593/800][24/24] total train loss: 0.0074; total val loss: 0.4921 val r: 0.7372; time: 0.94sec
[594/800][24/24] total train loss: 0.0071; total val loss: 0.4692 val r: 0.7343; time: 0.95sec
[595/800][24/24] total train loss: 0.0074; total val loss: 0.4662 val r: 0.7362; time: 0.95sec
[596/800][24/24] total train loss: 0.0076; total val loss: 0.4754 val r: 0.7343; time: 0.95sec
[597/800][24/24] total train loss: 0.0070; total val loss: 0.4750 val r: 0.7359; time: 0.94sec
[598/800][24/24] total train loss: 0.0068; total val loss: 0.4879 val r: 0.7358; time: 0.95sec
[599/800][24/24] total train loss: 0.0069; total val loss: 0.4707 val r: 0.7383; time: 0.94sec
learning rate updated: 0.001
[600/800][24/24] total train loss: 0.0071; total val loss: 0.4638 val r: 0.7347; time: 0.95sec
[601/800][24/24] total train loss: 0.0070; total val loss: 0.4771 val r: 0.7374; time: 0.95sec
[602/800][24/24] total train loss: 0.0069; total val loss: 0.4724 val r: 0.7382; time: 0.95sec
[603/800][24/24] total train loss: 0.0070; total val loss: 0.4866 val r: 0.7360; time: 0.95sec
[604/800][24/24] total train loss: 0.0072; total val loss: 0.4880 val r: 0.7375; time: 0.95sec
[605/800][24/24] total train loss: 0.0071; total val loss: 0.4692 val r: 0.7348; time: 0.94sec
[606/800][24/24] total train loss: 0.0070; total val loss: 0.4864 val r: 0.7340; time: 0.95sec
[607/800][24/24] total train loss: 0.0071; total val loss: 0.4746 val r: 0.7356; time: 0.95sec
[608/800][24/24] total train loss: 0.0073; total val loss: 0.4864 val r: 0.7382; time: 0.94sec
[609/800][24/24] total train loss: 0.0071; total val loss: 0.4819 val r: 0.7349; time: 0.95sec
[610/800][24/24] total train loss: 0.0070; total val loss: 0.4881 val r: 0.7386; time: 0.95sec
[611/800][24/24] total train loss: 0.0069; total val loss: 0.4792 val r: 0.7374; time: 0.95sec
[612/800][24/24] total train loss: 0.0070; total val loss: 0.4948 val r: 0.7351; time: 0.93sec
[613/800][24/24] total train loss: 0.0072; total val loss: 0.4522 val r: 0.7347; time: 0.95sec
[614/800][24/24] total train loss: 0.0071; total val loss: 0.4829 val r: 0.7307; time: 0.95sec
[615/800][24/24] total train loss: 0.0070; total val loss: 0.4901 val r: 0.7360; time: 0.94sec
[616/800][24/24] total train loss: 0.0069; total val loss: 0.4752 val r: 0.7351; time: 0.95sec
[617/800][24/24] total train loss: 0.0071; total val loss: 0.4648 val r: 0.7327; time: 0.94sec
[618/800][24/24] total train loss: 0.0071; total val loss: 0.4925 val r: 0.7337; time: 0.95sec
[619/800][24/24] total train loss: 0.0072; total val loss: 0.5103 val r: 0.7309; time: 0.95sec
[620/800][24/24] total train loss: 0.0070; total val loss: 0.4817 val r: 0.7336; time: 0.94sec
[621/800][24/24] total train loss: 0.0068; total val loss: 0.4772 val r: 0.7362; time: 0.96sec
[622/800][24/24] total train loss: 0.0073; total val loss: 0.4896 val r: 0.7335; time: 0.95sec
[623/800][24/24] total train loss: 0.0074; total val loss: 0.4637 val r: 0.7293; time: 0.94sec
[624/800][24/24] total train loss: 0.0070; total val loss: 0.4721 val r: 0.7336; time: 0.95sec
[625/800][24/24] total train loss: 0.0070; total val loss: 0.4715 val r: 0.7347; time: 0.95sec
[626/800][24/24] total train loss: 0.0071; total val loss: 0.4921 val r: 0.7335; time: 0.95sec
[627/800][24/24] total train loss: 0.0074; total val loss: 0.4748 val r: 0.7306; time: 0.95sec
[628/800][24/24] total train loss: 0.0074; total val loss: 0.4526 val r: 0.7332; time: 0.94sec
[629/800][24/24] total train loss: 0.0072; total val loss: 0.4873 val r: 0.7389; time: 0.95sec
[630/800][24/24] total train loss: 0.0072; total val loss: 0.4881 val r: 0.7342; time: 0.95sec
[631/800][24/24] total train loss: 0.0069; total val loss: 0.4831 val r: 0.7378; time: 0.95sec
[632/800][24/24] total train loss: 0.0072; total val loss: 0.4897 val r: 0.7372; time: 0.95sec
[633/800][24/24] total train loss: 0.0069; total val loss: 0.4739 val r: 0.7387; time: 0.95sec
[634/800][24/24] total train loss: 0.0071; total val loss: 0.4770 val r: 0.7339; time: 0.96sec
[635/800][24/24] total train loss: 0.0071; total val loss: 0.4845 val r: 0.7322; time: 0.94sec
[636/800][24/24] total train loss: 0.0071; total val loss: 0.5067 val r: 0.7372; time: 0.94sec
[637/800][24/24] total train loss: 0.0072; total val loss: 0.4611 val r: 0.7347; time: 0.95sec
[638/800][24/24] total train loss: 0.0072; total val loss: 0.4936 val r: 0.7341; time: 0.95sec
[639/800][24/24] total train loss: 0.0073; total val loss: 0.4746 val r: 0.7350; time: 0.94sec
[640/800][24/24] total train loss: 0.0070; total val loss: 0.4867 val r: 0.7316; time: 0.95sec
[641/800][24/24] total train loss: 0.0074; total val loss: 0.4893 val r: 0.7304; time: 0.95sec
[642/800][24/24] total train loss: 0.0073; total val loss: 0.4732 val r: 0.7301; time: 0.94sec
[643/800][24/24] total train loss: 0.0073; total val loss: 0.4846 val r: 0.7348; time: 0.95sec
[644/800][24/24] total train loss: 0.0072; total val loss: 0.4805 val r: 0.7348; time: 0.94sec
[645/800][24/24] total train loss: 0.0070; total val loss: 0.4692 val r: 0.7322; time: 0.95sec
[646/800][24/24] total train loss: 0.0067; total val loss: 0.4833 val r: 0.7334; time: 0.96sec
[647/800][24/24] total train loss: 0.0069; total val loss: 0.4796 val r: 0.7344; time: 0.95sec
[648/800][24/24] total train loss: 0.0067; total val loss: 0.4816 val r: 0.7313; time: 0.95sec
[649/800][24/24] total train loss: 0.0070; total val loss: 0.4768 val r: 0.7342; time: 0.95sec
[650/800][24/24] total train loss: 0.0069; total val loss: 0.4691 val r: 0.7332; time: 0.95sec
[651/800][24/24] total train loss: 0.0069; total val loss: 0.4795 val r: 0.7325; time: 0.94sec
[652/800][24/24] total train loss: 0.0070; total val loss: 0.4693 val r: 0.7342; time: 0.95sec
[653/800][24/24] total train loss: 0.0068; total val loss: 0.4825 val r: 0.7304; time: 0.95sec
[654/800][24/24] total train loss: 0.0067; total val loss: 0.4755 val r: 0.7344; time: 0.95sec
[655/800][24/24] total train loss: 0.0069; total val loss: 0.4638 val r: 0.7350; time: 0.96sec
[656/800][24/24] total train loss: 0.0074; total val loss: 0.4651 val r: 0.7342; time: 0.95sec
[657/800][24/24] total train loss: 0.0069; total val loss: 0.4759 val r: 0.7314; time: 0.94sec
[658/800][24/24] total train loss: 0.0068; total val loss: 0.4836 val r: 0.7352; time: 0.95sec
[659/800][24/24] total train loss: 0.0069; total val loss: 0.4917 val r: 0.7322; time: 0.95sec
[660/800][24/24] total train loss: 0.0075; total val loss: 0.4857 val r: 0.7346; time: 0.95sec
[661/800][24/24] total train loss: 0.0067; total val loss: 0.4951 val r: 0.7372; time: 0.95sec
[662/800][24/24] total train loss: 0.0072; total val loss: 0.4743 val r: 0.7313; time: 0.95sec
[663/800][24/24] total train loss: 0.0070; total val loss: 0.4907 val r: 0.7273; time: 0.94sec
[664/800][24/24] total train loss: 0.0074; total val loss: 0.4813 val r: 0.7315; time: 0.95sec
[665/800][24/24] total train loss: 0.0072; total val loss: 0.4740 val r: 0.7339; time: 0.95sec
[666/800][24/24] total train loss: 0.0068; total val loss: 0.4682 val r: 0.7310; time: 0.95sec
[667/800][24/24] total train loss: 0.0072; total val loss: 0.5026 val r: 0.7338; time: 0.95sec
[668/800][24/24] total train loss: 0.0070; total val loss: 0.4876 val r: 0.7346; time: 0.94sec
[669/800][24/24] total train loss: 0.0075; total val loss: 0.4736 val r: 0.7352; time: 0.95sec
[670/800][24/24] total train loss: 0.0070; total val loss: 0.4714 val r: 0.7355; time: 0.95sec
[671/800][24/24] total train loss: 0.0072; total val loss: 0.4876 val r: 0.7345; time: 0.95sec
[672/800][24/24] total train loss: 0.0069; total val loss: 0.4720 val r: 0.7346; time: 0.95sec
[673/800][24/24] total train loss: 0.0070; total val loss: 0.4944 val r: 0.7332; time: 0.95sec
[674/800][24/24] total train loss: 0.0069; total val loss: 0.4690 val r: 0.7366; time: 0.95sec
[675/800][24/24] total train loss: 0.0073; total val loss: 0.5033 val r: 0.7339; time: 0.94sec
[676/800][24/24] total train loss: 0.0074; total val loss: 0.4751 val r: 0.7327; time: 0.95sec
[677/800][24/24] total train loss: 0.0070; total val loss: 0.4476 val r: 0.7337; time: 0.95sec
[678/800][24/24] total train loss: 0.0070; total val loss: 0.4725 val r: 0.7366; time: 0.94sec
[679/800][24/24] total train loss: 0.0071; total val loss: 0.4901 val r: 0.7355; time: 0.96sec
[680/800][24/24] total train loss: 0.0072; total val loss: 0.4654 val r: 0.7374; time: 0.94sec
[681/800][24/24] total train loss: 0.0073; total val loss: 0.4842 val r: 0.7365; time: 0.95sec
[682/800][24/24] total train loss: 0.0070; total val loss: 0.4853 val r: 0.7311; time: 0.94sec
[683/800][24/24] total train loss: 0.0070; total val loss: 0.4701 val r: 0.7305; time: 0.94sec
[684/800][24/24] total train loss: 0.0070; total val loss: 0.4973 val r: 0.7338; time: 0.95sec
[685/800][24/24] total train loss: 0.0071; total val loss: 0.4888 val r: 0.7326; time: 0.95sec
[686/800][24/24] total train loss: 0.0070; total val loss: 0.4731 val r: 0.7337; time: 0.95sec
[687/800][24/24] total train loss: 0.0069; total val loss: 0.4881 val r: 0.7300; time: 0.95sec
[688/800][24/24] total train loss: 0.0071; total val loss: 0.4748 val r: 0.7320; time: 0.95sec
[689/800][24/24] total train loss: 0.0074; total val loss: 0.4808 val r: 0.7339; time: 0.94sec
[690/800][24/24] total train loss: 0.0071; total val loss: 0.4696 val r: 0.7334; time: 0.95sec
[691/800][24/24] total train loss: 0.0068; total val loss: 0.4871 val r: 0.7345; time: 0.93sec
[692/800][24/24] total train loss: 0.0070; total val loss: 0.4877 val r: 0.7352; time: 0.95sec
[693/800][24/24] total train loss: 0.0066; total val loss: 0.4773 val r: 0.7340; time: 0.94sec
[694/800][24/24] total train loss: 0.0071; total val loss: 0.4567 val r: 0.7357; time: 0.95sec
[695/800][24/24] total train loss: 0.0068; total val loss: 0.4631 val r: 0.7353; time: 0.95sec
[696/800][24/24] total train loss: 0.0072; total val loss: 0.4827 val r: 0.7362; time: 0.94sec
[697/800][24/24] total train loss: 0.0073; total val loss: 0.4770 val r: 0.7333; time: 0.95sec
[698/800][24/24] total train loss: 0.0071; total val loss: 0.4791 val r: 0.7339; time: 0.95sec
[699/800][24/24] total train loss: 0.0072; total val loss: 0.4731 val r: 0.7352; time: 0.95sec
learning rate updated: 0.001
[700/800][24/24] total train loss: 0.0070; total val loss: 0.4994 val r: 0.7352; time: 0.95sec
[701/800][24/24] total train loss: 0.0069; total val loss: 0.4833 val r: 0.7350; time: 0.95sec
[702/800][24/24] total train loss: 0.0070; total val loss: 0.4761 val r: 0.7345; time: 0.95sec
[703/800][24/24] total train loss: 0.0071; total val loss: 0.4793 val r: 0.7395; time: 0.94sec
[704/800][24/24] total train loss: 0.0073; total val loss: 0.4599 val r: 0.7338; time: 0.95sec
[705/800][24/24] total train loss: 0.0071; total val loss: 0.4939 val r: 0.7360; time: 0.95sec
[706/800][24/24] total train loss: 0.0070; total val loss: 0.4749 val r: 0.7312; time: 0.95sec
[707/800][24/24] total train loss: 0.0070; total val loss: 0.4907 val r: 0.7321; time: 0.95sec
[708/800][24/24] total train loss: 0.0070; total val loss: 0.4828 val r: 0.7362; time: 0.94sec
[709/800][24/24] total train loss: 0.0067; total val loss: 0.4764 val r: 0.7346; time: 0.95sec
[710/800][24/24] total train loss: 0.0070; total val loss: 0.4904 val r: 0.7338; time: 0.94sec
[711/800][24/24] total train loss: 0.0070; total val loss: 0.4925 val r: 0.7330; time: 0.95sec
[712/800][24/24] total train loss: 0.0068; total val loss: 0.4926 val r: 0.7340; time: 0.95sec
[713/800][24/24] total train loss: 0.0071; total val loss: 0.4976 val r: 0.7325; time: 0.95sec
[714/800][24/24] total train loss: 0.0070; total val loss: 0.4587 val r: 0.7308; time: 0.94sec
[715/800][24/24] total train loss: 0.0070; total val loss: 0.4756 val r: 0.7334; time: 0.95sec
[716/800][24/24] total train loss: 0.0072; total val loss: 0.4965 val r: 0.7337; time: 0.94sec
[717/800][24/24] total train loss: 0.0071; total val loss: 0.4969 val r: 0.7323; time: 0.95sec
[718/800][24/24] total train loss: 0.0071; total val loss: 0.4754 val r: 0.7331; time: 0.94sec
[719/800][24/24] total train loss: 0.0067; total val loss: 0.4965 val r: 0.7312; time: 0.95sec
[720/800][24/24] total train loss: 0.0075; total val loss: 0.4757 val r: 0.7308; time: 0.96sec
[721/800][24/24] total train loss: 0.0070; total val loss: 0.4725 val r: 0.7320; time: 0.95sec
[722/800][24/24] total train loss: 0.0071; total val loss: 0.4964 val r: 0.7370; time: 0.94sec
[723/800][24/24] total train loss: 0.0070; total val loss: 0.4743 val r: 0.7363; time: 0.94sec
[724/800][24/24] total train loss: 0.0066; total val loss: 0.4801 val r: 0.7319; time: 0.95sec
[725/800][24/24] total train loss: 0.0070; total val loss: 0.4793 val r: 0.7350; time: 0.95sec
[726/800][24/24] total train loss: 0.0071; total val loss: 0.4714 val r: 0.7335; time: 0.95sec
[727/800][24/24] total train loss: 0.0073; total val loss: 0.4946 val r: 0.7341; time: 0.94sec
[728/800][24/24] total train loss: 0.0068; total val loss: 0.4988 val r: 0.7378; time: 0.95sec
[729/800][24/24] total train loss: 0.0071; total val loss: 0.4777 val r: 0.7328; time: 0.94sec
[730/800][24/24] total train loss: 0.0066; total val loss: 0.4826 val r: 0.7348; time: 0.94sec
[731/800][24/24] total train loss: 0.0069; total val loss: 0.4792 val r: 0.7328; time: 0.94sec
[732/800][24/24] total train loss: 0.0070; total val loss: 0.4852 val r: 0.7340; time: 0.94sec
[733/800][24/24] total train loss: 0.0071; total val loss: 0.4686 val r: 0.7362; time: 0.96sec
[734/800][24/24] total train loss: 0.0068; total val loss: 0.4749 val r: 0.7311; time: 0.94sec
[735/800][24/24] total train loss: 0.0071; total val loss: 0.4917 val r: 0.7347; time: 0.95sec
[736/800][24/24] total train loss: 0.0069; total val loss: 0.4982 val r: 0.7327; time: 0.95sec
[737/800][24/24] total train loss: 0.0069; total val loss: 0.4585 val r: 0.7341; time: 0.94sec
[738/800][24/24] total train loss: 0.0070; total val loss: 0.4748 val r: 0.7352; time: 0.95sec
[739/800][24/24] total train loss: 0.0070; total val loss: 0.4787 val r: 0.7332; time: 0.95sec
[740/800][24/24] total train loss: 0.0072; total val loss: 0.4866 val r: 0.7349; time: 0.94sec
[741/800][24/24] total train loss: 0.0071; total val loss: 0.4738 val r: 0.7309; time: 0.95sec
[742/800][24/24] total train loss: 0.0071; total val loss: 0.4967 val r: 0.7356; time: 0.94sec
[743/800][24/24] total train loss: 0.0071; total val loss: 0.4726 val r: 0.7363; time: 0.95sec
[744/800][24/24] total train loss: 0.0073; total val loss: 0.4950 val r: 0.7312; time: 0.95sec
[745/800][24/24] total train loss: 0.0068; total val loss: 0.4856 val r: 0.7328; time: 0.95sec
[746/800][24/24] total train loss: 0.0071; total val loss: 0.4919 val r: 0.7358; time: 0.94sec
[747/800][24/24] total train loss: 0.0070; total val loss: 0.4644 val r: 0.7351; time: 0.94sec
[748/800][24/24] total train loss: 0.0071; total val loss: 0.5022 val r: 0.7339; time: 0.95sec
[749/800][24/24] total train loss: 0.0070; total val loss: 0.5022 val r: 0.7343; time: 0.94sec
[750/800][24/24] total train loss: 0.0072; total val loss: 0.4740 val r: 0.7320; time: 0.95sec
[751/800][24/24] total train loss: 0.0073; total val loss: 0.4992 val r: 0.7354; time: 0.95sec
[752/800][24/24] total train loss: 0.0071; total val loss: 0.4785 val r: 0.7353; time: 0.94sec
[753/800][24/24] total train loss: 0.0071; total val loss: 0.4876 val r: 0.7375; time: 0.95sec
[754/800][24/24] total train loss: 0.0068; total val loss: 0.4729 val r: 0.7365; time: 0.95sec
[755/800][24/24] total train loss: 0.0069; total val loss: 0.4763 val r: 0.7361; time: 0.94sec
[756/800][24/24] total train loss: 0.0071; total val loss: 0.4937 val r: 0.7378; time: 0.95sec
[757/800][24/24] total train loss: 0.0071; total val loss: 0.4747 val r: 0.7363; time: 0.95sec
[758/800][24/24] total train loss: 0.0071; total val loss: 0.4820 val r: 0.7353; time: 0.95sec
[759/800][24/24] total train loss: 0.0070; total val loss: 0.4809 val r: 0.7344; time: 0.94sec
[760/800][24/24] total train loss: 0.0087; total val loss: 0.4807 val r: 0.7380; time: 0.94sec
[761/800][24/24] total train loss: 0.0075; total val loss: 0.5056 val r: 0.7385; time: 0.94sec
[762/800][24/24] total train loss: 0.0074; total val loss: 0.4886 val r: 0.7367; time: 0.94sec
[763/800][24/24] total train loss: 0.0072; total val loss: 0.4914 val r: 0.7357; time: 0.94sec
[764/800][24/24] total train loss: 0.0069; total val loss: 0.4854 val r: 0.7269; time: 0.95sec
[765/800][24/24] total train loss: 0.0072; total val loss: 0.4552 val r: 0.7305; time: 0.95sec
[766/800][24/24] total train loss: 0.0107; total val loss: 0.4891 val r: 0.7207; time: 0.95sec
[767/800][24/24] total train loss: 0.0142; total val loss: 0.4746 val r: 0.7091; time: 0.95sec
[768/800][24/24] total train loss: 0.0152; total val loss: 0.4949 val r: 0.7385; time: 0.95sec
[769/800][24/24] total train loss: 0.0214; total val loss: 0.4780 val r: 0.7048; time: 0.95sec
[770/800][24/24] total train loss: 0.0127; total val loss: 0.4819 val r: 0.7225; time: 0.94sec
[771/800][24/24] total train loss: 0.0133; total val loss: 0.4845 val r: 0.7041; time: 0.94sec
[772/800][24/24] total train loss: 0.0099; total val loss: 0.5017 val r: 0.7052; time: 0.94sec
[773/800][24/24] total train loss: 0.0084; total val loss: 0.4826 val r: 0.7190; time: 0.95sec
[774/800][24/24] total train loss: 0.0079; total val loss: 0.4750 val r: 0.7202; time: 0.95sec
[775/800][24/24] total train loss: 0.0074; total val loss: 0.4830 val r: 0.7207; time: 0.94sec
[776/800][24/24] total train loss: 0.0072; total val loss: 0.4807 val r: 0.7174; time: 0.95sec
[777/800][24/24] total train loss: 0.0072; total val loss: 0.4599 val r: 0.7201; time: 0.95sec
[778/800][24/24] total train loss: 0.0074; total val loss: 0.4936 val r: 0.7208; time: 0.95sec
[779/800][24/24] total train loss: 0.0073; total val loss: 0.4782 val r: 0.7206; time: 0.95sec
[780/800][24/24] total train loss: 0.0069; total val loss: 0.4829 val r: 0.7226; time: 0.96sec
[781/800][24/24] total train loss: 0.0071; total val loss: 0.5008 val r: 0.7233; time: 0.95sec
[782/800][24/24] total train loss: 0.0071; total val loss: 0.4721 val r: 0.7231; time: 0.94sec
[783/800][24/24] total train loss: 0.0073; total val loss: 0.4774 val r: 0.7235; time: 0.94sec
[784/800][24/24] total train loss: 0.0072; total val loss: 0.4828 val r: 0.7225; time: 0.95sec
[785/800][24/24] total train loss: 0.0071; total val loss: 0.4828 val r: 0.7228; time: 0.95sec
[786/800][24/24] total train loss: 0.0073; total val loss: 0.4879 val r: 0.7204; time: 0.94sec
[787/800][24/24] total train loss: 0.0068; total val loss: 0.4871 val r: 0.7203; time: 0.95sec
[788/800][24/24] total train loss: 0.0069; total val loss: 0.4909 val r: 0.7230; time: 0.94sec
[789/800][24/24] total train loss: 0.0070; total val loss: 0.4694 val r: 0.7235; time: 0.95sec
[790/800][24/24] total train loss: 0.0071; total val loss: 0.4821 val r: 0.7231; time: 0.95sec
[791/800][24/24] total train loss: 0.0069; total val loss: 0.4806 val r: 0.7239; time: 0.95sec
[792/800][24/24] total train loss: 0.0068; total val loss: 0.4821 val r: 0.7207; time: 0.95sec
[793/800][24/24] total train loss: 0.0074; total val loss: 0.4819 val r: 0.7211; time: 0.95sec
[794/800][24/24] total train loss: 0.0070; total val loss: 0.4850 val r: 0.7242; time: 0.95sec
[795/800][24/24] total train loss: 0.0068; total val loss: 0.4919 val r: 0.7200; time: 0.95sec
[796/800][24/24] total train loss: 0.0071; total val loss: 0.4859 val r: 0.7185; time: 0.94sec
[797/800][24/24] total train loss: 0.0070; total val loss: 0.4776 val r: 0.7235; time: 0.95sec
[798/800][24/24] total train loss: 0.0065; total val loss: 0.4739 val r: 0.7219; time: 0.95sec
[799/800][24/24] total train loss: 0.0070; total val loss: 0.4689 val r: 0.7215; time: 0.95sec
learning rate updated: 0.001
[800/800][24/24] total train loss: 0.0069; total val loss: 0.4785 val r: 0.7240; time: 0.94sec
Best epoch 290 with val_r = 0.7452.
Fold #5
- - - - - - - - - - - - -
initializing neural net
[1/800][24/24] total train loss: 1.0675; total val loss: 0.4662 val r: 0.6778; time: 0.97sec
[2/800][24/24] total train loss: 0.5385; total val loss: 0.5248 val r: 0.7507; time: 0.94sec
[3/800][24/24] total train loss: 0.4186; total val loss: 0.4555 val r: 0.7710; time: 0.94sec
[4/800][24/24] total train loss: 0.2962; total val loss: 0.4762 val r: 0.7563; time: 0.94sec
[5/800][24/24] total train loss: 0.2320; total val loss: 0.5439 val r: 0.7697; time: 0.95sec
[6/800][24/24] total train loss: 0.1633; total val loss: 0.5546 val r: 0.7449; time: 0.94sec
[7/800][24/24] total train loss: 0.0845; total val loss: 0.5412 val r: 0.7646; time: 0.94sec
[8/800][24/24] total train loss: 0.0593; total val loss: 0.5597 val r: 0.7695; time: 0.95sec
[9/800][24/24] total train loss: 0.0622; total val loss: 0.5012 val r: 0.7636; time: 0.94sec
[10/800][24/24] total train loss: 0.0374; total val loss: 0.5186 val r: 0.7656; time: 0.94sec
[11/800][24/24] total train loss: 0.0244; total val loss: 0.5569 val r: 0.7637; time: 0.94sec
[12/800][24/24] total train loss: 0.0255; total val loss: 0.5433 val r: 0.7604; time: 0.94sec
[13/800][24/24] total train loss: 0.0237; total val loss: 0.5197 val r: 0.7655; time: 0.95sec
[14/800][24/24] total train loss: 0.0247; total val loss: 0.5494 val r: 0.7686; time: 0.94sec
[15/800][24/24] total train loss: 0.0215; total val loss: 0.4830 val r: 0.7614; time: 0.95sec
[16/800][24/24] total train loss: 0.0193; total val loss: 0.5232 val r: 0.7651; time: 0.95sec
[17/800][24/24] total train loss: 0.0172; total val loss: 0.5045 val r: 0.7650; time: 0.94sec
[18/800][24/24] total train loss: 0.0140; total val loss: 0.5089 val r: 0.7637; time: 0.94sec
[19/800][24/24] total train loss: 0.0144; total val loss: 0.4848 val r: 0.7619; time: 0.94sec
[20/800][24/24] total train loss: 0.0131; total val loss: 0.5218 val r: 0.7665; time: 0.95sec
[21/800][24/24] total train loss: 0.0126; total val loss: 0.4939 val r: 0.7664; time: 0.93sec
[22/800][24/24] total train loss: 0.0140; total val loss: 0.5201 val r: 0.7655; time: 0.95sec
[23/800][24/24] total train loss: 0.0123; total val loss: 0.4990 val r: 0.7648; time: 0.95sec
[24/800][24/24] total train loss: 0.0126; total val loss: 0.5070 val r: 0.7637; time: 0.95sec
[25/800][24/24] total train loss: 0.0142; total val loss: 0.5161 val r: 0.7718; time: 0.95sec
[26/800][24/24] total train loss: 0.0147; total val loss: 0.5078 val r: 0.7656; time: 0.94sec
[27/800][24/24] total train loss: 0.0136; total val loss: 0.5122 val r: 0.7664; time: 0.94sec
[28/800][24/24] total train loss: 0.0124; total val loss: 0.5089 val r: 0.7711; time: 0.94sec
[29/800][24/24] total train loss: 0.0138; total val loss: 0.5060 val r: 0.7645; time: 0.95sec
[30/800][24/24] total train loss: 0.0138; total val loss: 0.5209 val r: 0.7696; time: 0.95sec
[31/800][24/24] total train loss: 0.0145; total val loss: 0.5273 val r: 0.7656; time: 0.95sec
[32/800][24/24] total train loss: 0.0155; total val loss: 0.5118 val r: 0.7709; time: 0.95sec
[33/800][24/24] total train loss: 0.0158; total val loss: 0.5235 val r: 0.7644; time: 0.96sec
[34/800][24/24] total train loss: 0.0150; total val loss: 0.5293 val r: 0.7722; time: 0.94sec
[35/800][24/24] total train loss: 0.0141; total val loss: 0.5316 val r: 0.7662; time: 0.95sec
[36/800][24/24] total train loss: 0.0143; total val loss: 0.4949 val r: 0.7628; time: 0.95sec
[37/800][24/24] total train loss: 0.0162; total val loss: 0.4816 val r: 0.7697; time: 0.94sec
[38/800][24/24] total train loss: 0.0169; total val loss: 0.5144 val r: 0.7711; time: 0.95sec
[39/800][24/24] total train loss: 0.0166; total val loss: 0.5194 val r: 0.7776; time: 0.95sec
[40/800][24/24] total train loss: 0.0131; total val loss: 0.5042 val r: 0.7665; time: 0.95sec
[41/800][24/24] total train loss: 0.0115; total val loss: 0.5313 val r: 0.7771; time: 0.95sec
[42/800][24/24] total train loss: 0.0116; total val loss: 0.5041 val r: 0.7727; time: 0.95sec
[43/800][24/24] total train loss: 0.0117; total val loss: 0.5206 val r: 0.7739; time: 0.94sec
[44/800][24/24] total train loss: 0.0117; total val loss: 0.4985 val r: 0.7698; time: 0.95sec
[45/800][24/24] total train loss: 0.0117; total val loss: 0.5056 val r: 0.7777; time: 0.95sec
[46/800][24/24] total train loss: 0.0121; total val loss: 0.5085 val r: 0.7733; time: 0.95sec
[47/800][24/24] total train loss: 0.0137; total val loss: 0.5073 val r: 0.7780; time: 0.94sec
[48/800][24/24] total train loss: 0.0131; total val loss: 0.4969 val r: 0.7674; time: 0.94sec
[49/800][24/24] total train loss: 0.0113; total val loss: 0.4966 val r: 0.7722; time: 0.95sec
[50/800][24/24] total train loss: 0.0149; total val loss: 0.4966 val r: 0.7765; time: 0.94sec
[51/800][24/24] total train loss: 0.0154; total val loss: 0.5121 val r: 0.7713; time: 0.94sec
[52/800][24/24] total train loss: 0.0132; total val loss: 0.5001 val r: 0.7743; time: 0.93sec
[53/800][24/24] total train loss: 0.0107; total val loss: 0.5116 val r: 0.7729; time: 0.93sec
[54/800][24/24] total train loss: 0.0101; total val loss: 0.5330 val r: 0.7756; time: 0.93sec
[55/800][24/24] total train loss: 0.0106; total val loss: 0.5330 val r: 0.7715; time: 0.94sec
[56/800][24/24] total train loss: 0.0108; total val loss: 0.5319 val r: 0.7725; time: 0.93sec
[57/800][24/24] total train loss: 0.0106; total val loss: 0.5111 val r: 0.7725; time: 0.93sec
[58/800][24/24] total train loss: 0.0106; total val loss: 0.5219 val r: 0.7714; time: 0.96sec
[59/800][24/24] total train loss: 0.0107; total val loss: 0.5028 val r: 0.7763; time: 0.94sec
[60/800][24/24] total train loss: 0.0108; total val loss: 0.4865 val r: 0.7771; time: 0.95sec
[61/800][24/24] total train loss: 0.0115; total val loss: 0.5107 val r: 0.7737; time: 0.94sec
[62/800][24/24] total train loss: 0.0110; total val loss: 0.5201 val r: 0.7718; time: 0.95sec
[63/800][24/24] total train loss: 0.0093; total val loss: 0.5197 val r: 0.7771; time: 0.94sec
[64/800][24/24] total train loss: 0.0089; total val loss: 0.5124 val r: 0.7745; time: 0.94sec
[65/800][24/24] total train loss: 0.0088; total val loss: 0.5174 val r: 0.7700; time: 0.95sec
[66/800][24/24] total train loss: 0.0084; total val loss: 0.5233 val r: 0.7724; time: 0.94sec
[67/800][24/24] total train loss: 0.0088; total val loss: 0.4945 val r: 0.7747; time: 0.94sec
[68/800][24/24] total train loss: 0.0103; total val loss: 0.5006 val r: 0.7754; time: 0.94sec
[69/800][24/24] total train loss: 0.0107; total val loss: 0.5050 val r: 0.7766; time: 0.94sec
[70/800][24/24] total train loss: 0.0103; total val loss: 0.5317 val r: 0.7703; time: 0.95sec
[71/800][24/24] total train loss: 0.0108; total val loss: 0.5326 val r: 0.7767; time: 0.94sec
[72/800][24/24] total train loss: 0.0101; total val loss: 0.4959 val r: 0.7743; time: 0.95sec
[73/800][24/24] total train loss: 0.0106; total val loss: 0.5279 val r: 0.7742; time: 0.93sec
[74/800][24/24] total train loss: 0.0114; total val loss: 0.4715 val r: 0.7735; time: 0.94sec
[75/800][24/24] total train loss: 0.0123; total val loss: 0.5242 val r: 0.7752; time: 0.94sec
[76/800][24/24] total train loss: 0.0103; total val loss: 0.5181 val r: 0.7780; time: 0.95sec
[77/800][24/24] total train loss: 0.0108; total val loss: 0.5061 val r: 0.7749; time: 0.95sec
[78/800][24/24] total train loss: 0.0102; total val loss: 0.5120 val r: 0.7778; time: 0.96sec
[79/800][24/24] total train loss: 0.0111; total val loss: 0.4838 val r: 0.7730; time: 0.95sec
[80/800][24/24] total train loss: 0.0121; total val loss: 0.5027 val r: 0.7778; time: 0.94sec
[81/800][24/24] total train loss: 0.0123; total val loss: 0.5015 val r: 0.7735; time: 0.94sec
[82/800][24/24] total train loss: 0.0100; total val loss: 0.5101 val r: 0.7782; time: 0.95sec
[83/800][24/24] total train loss: 0.0099; total val loss: 0.5302 val r: 0.7757; time: 0.95sec
[84/800][24/24] total train loss: 0.0097; total val loss: 0.4960 val r: 0.7749; time: 0.95sec
[85/800][24/24] total train loss: 0.0090; total val loss: 0.4883 val r: 0.7767; time: 0.95sec
[86/800][24/24] total train loss: 0.0095; total val loss: 0.5063 val r: 0.7765; time: 0.95sec
[87/800][24/24] total train loss: 0.0096; total val loss: 0.5141 val r: 0.7785; time: 0.94sec
[88/800][24/24] total train loss: 0.0090; total val loss: 0.4973 val r: 0.7732; time: 0.94sec
[89/800][24/24] total train loss: 0.0093; total val loss: 0.4788 val r: 0.7794; time: 0.94sec
[90/800][24/24] total train loss: 0.0109; total val loss: 0.4999 val r: 0.7759; time: 0.95sec
[91/800][24/24] total train loss: 0.0100; total val loss: 0.5303 val r: 0.7788; time: 0.95sec
[92/800][24/24] total train loss: 0.0106; total val loss: 0.5293 val r: 0.7762; time: 0.94sec
[93/800][24/24] total train loss: 0.0095; total val loss: 0.5284 val r: 0.7750; time: 0.94sec
[94/800][24/24] total train loss: 0.0096; total val loss: 0.5189 val r: 0.7749; time: 0.95sec
[95/800][24/24] total train loss: 0.0093; total val loss: 0.5013 val r: 0.7770; time: 0.94sec
[96/800][24/24] total train loss: 0.0093; total val loss: 0.5133 val r: 0.7766; time: 0.94sec
[97/800][24/24] total train loss: 0.0089; total val loss: 0.5082 val r: 0.7749; time: 0.95sec
[98/800][24/24] total train loss: 0.0094; total val loss: 0.5314 val r: 0.7764; time: 0.95sec
[99/800][24/24] total train loss: 0.0100; total val loss: 0.5245 val r: 0.7792; time: 0.95sec
learning rate updated: 0.001
[100/800][24/24] total train loss: 0.0103; total val loss: 0.5021 val r: 0.7744; time: 0.94sec
[101/800][24/24] total train loss: 0.0101; total val loss: 0.5018 val r: 0.7780; time: 0.95sec
[102/800][24/24] total train loss: 0.0110; total val loss: 0.5141 val r: 0.7732; time: 0.94sec
[103/800][24/24] total train loss: 0.0101; total val loss: 0.5096 val r: 0.7782; time: 0.95sec
[104/800][24/24] total train loss: 0.0094; total val loss: 0.5004 val r: 0.7749; time: 0.95sec
[105/800][24/24] total train loss: 0.0091; total val loss: 0.5086 val r: 0.7774; time: 0.95sec
[106/800][24/24] total train loss: 0.0092; total val loss: 0.5069 val r: 0.7754; time: 0.95sec
[107/800][24/24] total train loss: 0.0099; total val loss: 0.4835 val r: 0.7747; time: 0.95sec
[108/800][24/24] total train loss: 0.0094; total val loss: 0.5159 val r: 0.7745; time: 0.95sec
[109/800][24/24] total train loss: 0.0100; total val loss: 0.4880 val r: 0.7763; time: 0.94sec
[110/800][24/24] total train loss: 0.0112; total val loss: 0.5223 val r: 0.7763; time: 0.94sec
[111/800][24/24] total train loss: 0.0109; total val loss: 0.5233 val r: 0.7759; time: 0.95sec
[112/800][24/24] total train loss: 0.0092; total val loss: 0.5096 val r: 0.7786; time: 0.94sec
[113/800][24/24] total train loss: 0.0089; total val loss: 0.5115 val r: 0.7778; time: 0.94sec
[114/800][24/24] total train loss: 0.0086; total val loss: 0.5092 val r: 0.7747; time: 0.94sec
[115/800][24/24] total train loss: 0.0093; total val loss: 0.5227 val r: 0.7763; time: 0.95sec
[116/800][24/24] total train loss: 0.0083; total val loss: 0.4933 val r: 0.7768; time: 0.94sec
[117/800][24/24] total train loss: 0.0095; total val loss: 0.5099 val r: 0.7794; time: 0.95sec
[118/800][24/24] total train loss: 0.0088; total val loss: 0.5024 val r: 0.7754; time: 0.95sec
[119/800][24/24] total train loss: 0.0092; total val loss: 0.5275 val r: 0.7781; time: 0.94sec
[120/800][24/24] total train loss: 0.0092; total val loss: 0.5034 val r: 0.7783; time: 0.94sec
[121/800][24/24] total train loss: 0.0093; total val loss: 0.5115 val r: 0.7781; time: 0.95sec
[122/800][24/24] total train loss: 0.0093; total val loss: 0.4826 val r: 0.7776; time: 0.95sec
[123/800][24/24] total train loss: 0.0093; total val loss: 0.4718 val r: 0.7789; time: 0.95sec
[124/800][24/24] total train loss: 0.0109; total val loss: 0.5014 val r: 0.7798; time: 0.95sec
[125/800][24/24] total train loss: 0.0114; total val loss: 0.5238 val r: 0.7778; time: 0.94sec
[126/800][24/24] total train loss: 0.0109; total val loss: 0.5067 val r: 0.7789; time: 0.94sec
[127/800][24/24] total train loss: 0.0095; total val loss: 0.5038 val r: 0.7797; time: 0.94sec
[128/800][24/24] total train loss: 0.0087; total val loss: 0.4971 val r: 0.7759; time: 0.95sec
[129/800][24/24] total train loss: 0.0087; total val loss: 0.5179 val r: 0.7793; time: 0.94sec
[130/800][24/24] total train loss: 0.0086; total val loss: 0.5007 val r: 0.7805; time: 0.94sec
[131/800][24/24] total train loss: 0.0083; total val loss: 0.5090 val r: 0.7777; time: 0.94sec
[132/800][24/24] total train loss: 0.0091; total val loss: 0.5049 val r: 0.7811; time: 0.95sec
[133/800][24/24] total train loss: 0.0094; total val loss: 0.4921 val r: 0.7766; time: 0.95sec
[134/800][24/24] total train loss: 0.0090; total val loss: 0.5303 val r: 0.7818; time: 0.95sec
[135/800][24/24] total train loss: 0.0086; total val loss: 0.4963 val r: 0.7788; time: 0.95sec
[136/800][24/24] total train loss: 0.0084; total val loss: 0.5043 val r: 0.7792; time: 0.95sec
[137/800][24/24] total train loss: 0.0085; total val loss: 0.5115 val r: 0.7814; time: 0.95sec
[138/800][24/24] total train loss: 0.0080; total val loss: 0.4821 val r: 0.7787; time: 0.95sec
[139/800][24/24] total train loss: 0.0081; total val loss: 0.5016 val r: 0.7803; time: 0.94sec
[140/800][24/24] total train loss: 0.0085; total val loss: 0.4762 val r: 0.7787; time: 0.94sec
[141/800][24/24] total train loss: 0.0088; total val loss: 0.5088 val r: 0.7806; time: 0.95sec
[142/800][24/24] total train loss: 0.0093; total val loss: 0.5065 val r: 0.7791; time: 0.94sec
[143/800][24/24] total train loss: 0.0087; total val loss: 0.5016 val r: 0.7823; time: 0.94sec
[144/800][24/24] total train loss: 0.0078; total val loss: 0.5046 val r: 0.7800; time: 0.95sec
[145/800][24/24] total train loss: 0.0084; total val loss: 0.4916 val r: 0.7795; time: 0.95sec
[146/800][24/24] total train loss: 0.0086; total val loss: 0.4813 val r: 0.7804; time: 0.94sec
[147/800][24/24] total train loss: 0.0096; total val loss: 0.5240 val r: 0.7810; time: 0.94sec
[148/800][24/24] total train loss: 0.0094; total val loss: 0.5048 val r: 0.7792; time: 0.94sec
[149/800][24/24] total train loss: 0.0104; total val loss: 0.4967 val r: 0.7813; time: 0.94sec
[150/800][24/24] total train loss: 0.0091; total val loss: 0.4872 val r: 0.7778; time: 0.95sec
[151/800][24/24] total train loss: 0.0087; total val loss: 0.4983 val r: 0.7827; time: 0.95sec
[152/800][24/24] total train loss: 0.0085; total val loss: 0.4915 val r: 0.7805; time: 0.96sec
[153/800][24/24] total train loss: 0.0082; total val loss: 0.5002 val r: 0.7820; time: 0.95sec
[154/800][24/24] total train loss: 0.0078; total val loss: 0.5191 val r: 0.7832; time: 0.95sec
[155/800][24/24] total train loss: 0.0075; total val loss: 0.5122 val r: 0.7821; time: 0.94sec
[156/800][24/24] total train loss: 0.0078; total val loss: 0.4946 val r: 0.7817; time: 0.95sec
[157/800][24/24] total train loss: 0.0075; total val loss: 0.5124 val r: 0.7781; time: 0.95sec
[158/800][24/24] total train loss: 0.0078; total val loss: 0.5144 val r: 0.7829; time: 0.94sec
[159/800][24/24] total train loss: 0.0079; total val loss: 0.5080 val r: 0.7805; time: 0.95sec
[160/800][24/24] total train loss: 0.0084; total val loss: 0.5017 val r: 0.7792; time: 0.94sec
[161/800][24/24] total train loss: 0.0077; total val loss: 0.4983 val r: 0.7784; time: 0.95sec
[162/800][24/24] total train loss: 0.0075; total val loss: 0.4768 val r: 0.7788; time: 0.95sec
[163/800][24/24] total train loss: 0.0077; total val loss: 0.4832 val r: 0.7796; time: 0.94sec
[164/800][24/24] total train loss: 0.0078; total val loss: 0.5238 val r: 0.7803; time: 0.95sec
[165/800][24/24] total train loss: 0.0080; total val loss: 0.5053 val r: 0.7812; time: 0.95sec
[166/800][24/24] total train loss: 0.0078; total val loss: 0.5089 val r: 0.7773; time: 0.94sec
[167/800][24/24] total train loss: 0.0074; total val loss: 0.5201 val r: 0.7838; time: 0.95sec
[168/800][24/24] total train loss: 0.0076; total val loss: 0.5141 val r: 0.7812; time: 0.95sec
[169/800][24/24] total train loss: 0.0075; total val loss: 0.5046 val r: 0.7816; time: 0.94sec
[170/800][24/24] total train loss: 0.0077; total val loss: 0.5026 val r: 0.7809; time: 0.94sec
[171/800][24/24] total train loss: 0.0083; total val loss: 0.5160 val r: 0.7798; time: 0.95sec
[172/800][24/24] total train loss: 0.0077; total val loss: 0.4979 val r: 0.7811; time: 0.94sec
[173/800][24/24] total train loss: 0.0078; total val loss: 0.5062 val r: 0.7800; time: 0.94sec
[174/800][24/24] total train loss: 0.0078; total val loss: 0.5201 val r: 0.7812; time: 0.94sec
[175/800][24/24] total train loss: 0.0076; total val loss: 0.4890 val r: 0.7806; time: 0.95sec
[176/800][24/24] total train loss: 0.0076; total val loss: 0.4802 val r: 0.7801; time: 0.95sec
[177/800][24/24] total train loss: 0.0082; total val loss: 0.5216 val r: 0.7760; time: 0.95sec
[178/800][24/24] total train loss: 0.0084; total val loss: 0.5025 val r: 0.7810; time: 0.94sec
[179/800][24/24] total train loss: 0.0082; total val loss: 0.5015 val r: 0.7795; time: 0.95sec
[180/800][24/24] total train loss: 0.0079; total val loss: 0.5078 val r: 0.7792; time: 0.94sec
[181/800][24/24] total train loss: 0.0077; total val loss: 0.4995 val r: 0.7813; time: 0.94sec
[182/800][24/24] total train loss: 0.0083; total val loss: 0.4737 val r: 0.7810; time: 0.95sec
[183/800][24/24] total train loss: 0.0089; total val loss: 0.5093 val r: 0.7804; time: 0.95sec
[184/800][24/24] total train loss: 0.0089; total val loss: 0.4974 val r: 0.7775; time: 0.94sec
[185/800][24/24] total train loss: 0.0077; total val loss: 0.5149 val r: 0.7769; time: 0.94sec
[186/800][24/24] total train loss: 0.0074; total val loss: 0.5078 val r: 0.7793; time: 0.95sec
[187/800][24/24] total train loss: 0.0072; total val loss: 0.5094 val r: 0.7795; time: 0.94sec
[188/800][24/24] total train loss: 0.0071; total val loss: 0.4967 val r: 0.7848; time: 0.94sec
[189/800][24/24] total train loss: 0.0074; total val loss: 0.5068 val r: 0.7780; time: 0.94sec
[190/800][24/24] total train loss: 0.0078; total val loss: 0.5217 val r: 0.7827; time: 0.94sec
[191/800][24/24] total train loss: 0.0087; total val loss: 0.5042 val r: 0.7825; time: 0.95sec
[192/800][24/24] total train loss: 0.0087; total val loss: 0.5059 val r: 0.7831; time: 0.95sec
[193/800][24/24] total train loss: 0.0084; total val loss: 0.5236 val r: 0.7793; time: 0.94sec
[194/800][24/24] total train loss: 0.0079; total val loss: 0.4926 val r: 0.7789; time: 0.94sec
[195/800][24/24] total train loss: 0.0076; total val loss: 0.5194 val r: 0.7804; time: 0.94sec
[196/800][24/24] total train loss: 0.0080; total val loss: 0.5071 val r: 0.7819; time: 0.94sec
[197/800][24/24] total train loss: 0.0073; total val loss: 0.5043 val r: 0.7808; time: 0.95sec
[198/800][24/24] total train loss: 0.0073; total val loss: 0.4900 val r: 0.7851; time: 0.94sec
[199/800][24/24] total train loss: 0.0076; total val loss: 0.5169 val r: 0.7818; time: 0.94sec
learning rate updated: 0.001
[200/800][24/24] total train loss: 0.0077; total val loss: 0.5200 val r: 0.7819; time: 0.95sec
[201/800][24/24] total train loss: 0.0078; total val loss: 0.5031 val r: 0.7808; time: 0.94sec
[202/800][24/24] total train loss: 0.0070; total val loss: 0.5238 val r: 0.7824; time: 0.95sec
[203/800][24/24] total train loss: 0.0072; total val loss: 0.4950 val r: 0.7809; time: 0.94sec
[204/800][24/24] total train loss: 0.0072; total val loss: 0.5162 val r: 0.7823; time: 0.94sec
[205/800][24/24] total train loss: 0.0077; total val loss: 0.5035 val r: 0.7840; time: 0.95sec
[206/800][24/24] total train loss: 0.0075; total val loss: 0.4940 val r: 0.7813; time: 0.94sec
[207/800][24/24] total train loss: 0.0071; total val loss: 0.5059 val r: 0.7827; time: 0.95sec
[208/800][24/24] total train loss: 0.0076; total val loss: 0.4889 val r: 0.7814; time: 0.95sec
[209/800][24/24] total train loss: 0.0076; total val loss: 0.5091 val r: 0.7816; time: 0.95sec
[210/800][24/24] total train loss: 0.0075; total val loss: 0.5127 val r: 0.7824; time: 0.94sec
[211/800][24/24] total train loss: 0.0082; total val loss: 0.5297 val r: 0.7837; time: 0.94sec
[212/800][24/24] total train loss: 0.0078; total val loss: 0.4948 val r: 0.7821; time: 0.96sec
[213/800][24/24] total train loss: 0.0074; total val loss: 0.5018 val r: 0.7801; time: 0.95sec
[214/800][24/24] total train loss: 0.0079; total val loss: 0.5258 val r: 0.7843; time: 0.95sec
[215/800][24/24] total train loss: 0.0084; total val loss: 0.5001 val r: 0.7823; time: 0.94sec
[216/800][24/24] total train loss: 0.0083; total val loss: 0.5052 val r: 0.7811; time: 0.94sec
[217/800][24/24] total train loss: 0.0085; total val loss: 0.4988 val r: 0.7770; time: 0.95sec
[218/800][24/24] total train loss: 0.0079; total val loss: 0.4895 val r: 0.7815; time: 0.94sec
[219/800][24/24] total train loss: 0.0073; total val loss: 0.5033 val r: 0.7847; time: 0.94sec
[220/800][24/24] total train loss: 0.0073; total val loss: 0.5100 val r: 0.7853; time: 0.94sec
[221/800][24/24] total train loss: 0.0080; total val loss: 0.5050 val r: 0.7831; time: 0.94sec
[222/800][24/24] total train loss: 0.0079; total val loss: 0.5020 val r: 0.7830; time: 0.93sec
[223/800][24/24] total train loss: 0.0071; total val loss: 0.5084 val r: 0.7776; time: 0.95sec
[224/800][24/24] total train loss: 0.0074; total val loss: 0.4727 val r: 0.7822; time: 0.94sec
[225/800][24/24] total train loss: 0.0071; total val loss: 0.5111 val r: 0.7817; time: 0.94sec
[226/800][24/24] total train loss: 0.0071; total val loss: 0.5033 val r: 0.7832; time: 0.95sec
[227/800][24/24] total train loss: 0.0074; total val loss: 0.5015 val r: 0.7846; time: 0.95sec
[228/800][24/24] total train loss: 0.0073; total val loss: 0.5253 val r: 0.7859; time: 0.95sec
[229/800][24/24] total train loss: 0.0074; total val loss: 0.5044 val r: 0.7816; time: 0.95sec
[230/800][24/24] total train loss: 0.0072; total val loss: 0.5333 val r: 0.7824; time: 0.94sec
[231/800][24/24] total train loss: 0.0073; total val loss: 0.4947 val r: 0.7839; time: 0.95sec
[232/800][24/24] total train loss: 0.0071; total val loss: 0.5173 val r: 0.7817; time: 0.94sec
[233/800][24/24] total train loss: 0.0069; total val loss: 0.5131 val r: 0.7810; time: 0.94sec
[234/800][24/24] total train loss: 0.0072; total val loss: 0.5094 val r: 0.7817; time: 0.94sec
[235/800][24/24] total train loss: 0.0070; total val loss: 0.5020 val r: 0.7852; time: 0.95sec
[236/800][24/24] total train loss: 0.0073; total val loss: 0.4969 val r: 0.7808; time: 0.94sec
[237/800][24/24] total train loss: 0.0072; total val loss: 0.5078 val r: 0.7822; time: 0.94sec
[238/800][24/24] total train loss: 0.0069; total val loss: 0.4985 val r: 0.7815; time: 0.95sec
[239/800][24/24] total train loss: 0.0072; total val loss: 0.4711 val r: 0.7832; time: 0.95sec
[240/800][24/24] total train loss: 0.0075; total val loss: 0.5054 val r: 0.7837; time: 0.95sec
[241/800][24/24] total train loss: 0.0073; total val loss: 0.5242 val r: 0.7832; time: 0.95sec
[242/800][24/24] total train loss: 0.0071; total val loss: 0.4882 val r: 0.7802; time: 0.94sec
[243/800][24/24] total train loss: 0.0080; total val loss: 0.5160 val r: 0.7808; time: 0.94sec
[244/800][24/24] total train loss: 0.0074; total val loss: 0.5115 val r: 0.7817; time: 0.95sec
[245/800][24/24] total train loss: 0.0069; total val loss: 0.4921 val r: 0.7826; time: 0.94sec
[246/800][24/24] total train loss: 0.0069; total val loss: 0.4824 val r: 0.7798; time: 0.95sec
[247/800][24/24] total train loss: 0.0070; total val loss: 0.5029 val r: 0.7833; time: 0.96sec
[248/800][24/24] total train loss: 0.0072; total val loss: 0.4934 val r: 0.7835; time: 0.95sec
[249/800][24/24] total train loss: 0.0071; total val loss: 0.5123 val r: 0.7832; time: 0.95sec
[250/800][24/24] total train loss: 0.0068; total val loss: 0.5093 val r: 0.7844; time: 0.94sec
[251/800][24/24] total train loss: 0.0069; total val loss: 0.5066 val r: 0.7789; time: 0.96sec
[252/800][24/24] total train loss: 0.0075; total val loss: 0.4936 val r: 0.7827; time: 0.95sec
[253/800][24/24] total train loss: 0.0073; total val loss: 0.5015 val r: 0.7841; time: 0.94sec
[254/800][24/24] total train loss: 0.0070; total val loss: 0.5038 val r: 0.7835; time: 0.94sec
[255/800][24/24] total train loss: 0.0071; total val loss: 0.4951 val r: 0.7789; time: 0.94sec
[256/800][24/24] total train loss: 0.0073; total val loss: 0.4926 val r: 0.7847; time: 0.94sec
[257/800][24/24] total train loss: 0.0074; total val loss: 0.4878 val r: 0.7803; time: 0.94sec
[258/800][24/24] total train loss: 0.0074; total val loss: 0.5223 val r: 0.7796; time: 0.95sec
[259/800][24/24] total train loss: 0.0076; total val loss: 0.5162 val r: 0.7839; time: 0.94sec
[260/800][24/24] total train loss: 0.0073; total val loss: 0.5114 val r: 0.7769; time: 0.95sec
[261/800][24/24] total train loss: 0.0070; total val loss: 0.5167 val r: 0.7827; time: 0.95sec
[262/800][24/24] total train loss: 0.0075; total val loss: 0.4786 val r: 0.7841; time: 0.95sec
[263/800][24/24] total train loss: 0.0083; total val loss: 0.5033 val r: 0.7802; time: 0.95sec
[264/800][24/24] total train loss: 0.0077; total val loss: 0.5218 val r: 0.7793; time: 0.95sec
[265/800][24/24] total train loss: 0.0081; total val loss: 0.5194 val r: 0.7791; time: 0.94sec
[266/800][24/24] total train loss: 0.0073; total val loss: 0.5130 val r: 0.7832; time: 0.94sec
[267/800][24/24] total train loss: 0.0069; total val loss: 0.4915 val r: 0.7816; time: 0.95sec
[268/800][24/24] total train loss: 0.0074; total val loss: 0.4842 val r: 0.7841; time: 0.95sec
[269/800][24/24] total train loss: 0.0071; total val loss: 0.5050 val r: 0.7860; time: 0.94sec
[270/800][24/24] total train loss: 0.0066; total val loss: 0.5140 val r: 0.7858; time: 0.95sec
[271/800][24/24] total train loss: 0.0067; total val loss: 0.5101 val r: 0.7853; time: 0.95sec
[272/800][24/24] total train loss: 0.0072; total val loss: 0.5248 val r: 0.7845; time: 0.94sec
[273/800][24/24] total train loss: 0.0073; total val loss: 0.5051 val r: 0.7827; time: 0.95sec
[274/800][24/24] total train loss: 0.0069; total val loss: 0.4972 val r: 0.7844; time: 0.95sec
[275/800][24/24] total train loss: 0.0068; total val loss: 0.4944 val r: 0.7825; time: 0.95sec
[276/800][24/24] total train loss: 0.0068; total val loss: 0.5028 val r: 0.7845; time: 0.94sec
[277/800][24/24] total train loss: 0.0068; total val loss: 0.5057 val r: 0.7870; time: 0.94sec
[278/800][24/24] total train loss: 0.0068; total val loss: 0.5104 val r: 0.7846; time: 0.94sec
[279/800][24/24] total train loss: 0.0068; total val loss: 0.5059 val r: 0.7867; time: 0.95sec
[280/800][24/24] total train loss: 0.0066; total val loss: 0.5124 val r: 0.7859; time: 0.94sec
[281/800][24/24] total train loss: 0.0070; total val loss: 0.4916 val r: 0.7834; time: 0.95sec
[282/800][24/24] total train loss: 0.0069; total val loss: 0.4947 val r: 0.7819; time: 0.94sec
[283/800][24/24] total train loss: 0.0069; total val loss: 0.5036 val r: 0.7878; time: 0.94sec
[284/800][24/24] total train loss: 0.0067; total val loss: 0.5230 val r: 0.7825; time: 0.94sec
[285/800][24/24] total train loss: 0.0066; total val loss: 0.4999 val r: 0.7842; time: 0.94sec
[286/800][24/24] total train loss: 0.0068; total val loss: 0.5133 val r: 0.7824; time: 0.94sec
[287/800][24/24] total train loss: 0.0067; total val loss: 0.5108 val r: 0.7850; time: 0.95sec
[288/800][24/24] total train loss: 0.0067; total val loss: 0.5030 val r: 0.7811; time: 0.95sec
[289/800][24/24] total train loss: 0.0068; total val loss: 0.5224 val r: 0.7854; time: 0.95sec
[290/800][24/24] total train loss: 0.0065; total val loss: 0.5217 val r: 0.7850; time: 0.95sec
[291/800][24/24] total train loss: 0.0067; total val loss: 0.4902 val r: 0.7838; time: 0.94sec
[292/800][24/24] total train loss: 0.0069; total val loss: 0.5116 val r: 0.7849; time: 0.95sec
[293/800][24/24] total train loss: 0.0070; total val loss: 0.4922 val r: 0.7838; time: 0.95sec
[294/800][24/24] total train loss: 0.0069; total val loss: 0.4817 val r: 0.7834; time: 0.94sec
[295/800][24/24] total train loss: 0.0069; total val loss: 0.5103 val r: 0.7865; time: 0.95sec
[296/800][24/24] total train loss: 0.0069; total val loss: 0.5335 val r: 0.7877; time: 0.95sec
[297/800][24/24] total train loss: 0.0077; total val loss: 0.5077 val r: 0.7891; time: 0.95sec
[298/800][24/24] total train loss: 0.0075; total val loss: 0.5278 val r: 0.7801; time: 0.94sec
[299/800][24/24] total train loss: 0.0077; total val loss: 0.5149 val r: 0.7781; time: 0.95sec
learning rate updated: 0.001
[300/800][24/24] total train loss: 0.0076; total val loss: 0.5050 val r: 0.7821; time: 0.94sec
[301/800][24/24] total train loss: 0.0076; total val loss: 0.5156 val r: 0.7817; time: 0.94sec
[302/800][24/24] total train loss: 0.0071; total val loss: 0.5048 val r: 0.7841; time: 0.94sec
[303/800][24/24] total train loss: 0.0067; total val loss: 0.5145 val r: 0.7843; time: 0.94sec
[304/800][24/24] total train loss: 0.0065; total val loss: 0.5240 val r: 0.7835; time: 0.94sec
[305/800][24/24] total train loss: 0.0066; total val loss: 0.5157 val r: 0.7863; time: 0.94sec
[306/800][24/24] total train loss: 0.0063; total val loss: 0.5076 val r: 0.7839; time: 0.95sec
[307/800][24/24] total train loss: 0.0064; total val loss: 0.5076 val r: 0.7869; time: 0.94sec
[308/800][24/24] total train loss: 0.0065; total val loss: 0.4925 val r: 0.7846; time: 0.94sec
[309/800][24/24] total train loss: 0.0064; total val loss: 0.5044 val r: 0.7844; time: 0.95sec
[310/800][24/24] total train loss: 0.0066; total val loss: 0.5152 val r: 0.7826; time: 0.96sec
[311/800][24/24] total train loss: 0.0065; total val loss: 0.5163 val r: 0.7836; time: 0.94sec
[312/800][24/24] total train loss: 0.0070; total val loss: 0.5101 val r: 0.7844; time: 0.94sec
[313/800][24/24] total train loss: 0.0070; total val loss: 0.4917 val r: 0.7836; time: 0.95sec
[314/800][24/24] total train loss: 0.0067; total val loss: 0.5168 val r: 0.7844; time: 0.94sec
[315/800][24/24] total train loss: 0.0065; total val loss: 0.5190 val r: 0.7872; time: 0.95sec
[316/800][24/24] total train loss: 0.0068; total val loss: 0.5124 val r: 0.7863; time: 0.94sec
[317/800][24/24] total train loss: 0.0070; total val loss: 0.5036 val r: 0.7828; time: 0.95sec
[318/800][24/24] total train loss: 0.0068; total val loss: 0.4995 val r: 0.7838; time: 0.95sec
[319/800][24/24] total train loss: 0.0067; total val loss: 0.4927 val r: 0.7830; time: 0.95sec
[320/800][24/24] total train loss: 0.0066; total val loss: 0.4878 val r: 0.7833; time: 0.94sec
[321/800][24/24] total train loss: 0.0068; total val loss: 0.5102 val r: 0.7833; time: 0.94sec
[322/800][24/24] total train loss: 0.0067; total val loss: 0.5028 val r: 0.7863; time: 0.95sec
[323/800][24/24] total train loss: 0.0064; total val loss: 0.5220 val r: 0.7853; time: 0.94sec
[324/800][24/24] total train loss: 0.0065; total val loss: 0.5019 val r: 0.7871; time: 0.94sec
[325/800][24/24] total train loss: 0.0066; total val loss: 0.5127 val r: 0.7868; time: 0.95sec
[326/800][24/24] total train loss: 0.0075; total val loss: 0.5183 val r: 0.7849; time: 0.95sec
[327/800][24/24] total train loss: 0.0070; total val loss: 0.5005 val r: 0.7857; time: 0.95sec
[328/800][24/24] total train loss: 0.0066; total val loss: 0.5133 val r: 0.7834; time: 0.94sec
[329/800][24/24] total train loss: 0.0069; total val loss: 0.5247 val r: 0.7839; time: 0.95sec
[330/800][24/24] total train loss: 0.0067; total val loss: 0.4978 val r: 0.7864; time: 0.94sec
[331/800][24/24] total train loss: 0.0069; total val loss: 0.5054 val r: 0.7919; time: 0.95sec
[332/800][24/24] total train loss: 0.0065; total val loss: 0.5016 val r: 0.7892; time: 0.95sec
[333/800][24/24] total train loss: 0.0065; total val loss: 0.5034 val r: 0.7894; time: 0.94sec
[334/800][24/24] total train loss: 0.0068; total val loss: 0.5141 val r: 0.7864; time: 0.94sec
[335/800][24/24] total train loss: 0.0064; total val loss: 0.5083 val r: 0.7865; time: 0.94sec
[336/800][24/24] total train loss: 0.0066; total val loss: 0.5194 val r: 0.7874; time: 0.94sec
[337/800][24/24] total train loss: 0.0065; total val loss: 0.5055 val r: 0.7868; time: 0.95sec
[338/800][24/24] total train loss: 0.0066; total val loss: 0.5042 val r: 0.7891; time: 0.94sec
[339/800][24/24] total train loss: 0.0068; total val loss: 0.5006 val r: 0.7885; time: 0.95sec
[340/800][24/24] total train loss: 0.0063; total val loss: 0.5066 val r: 0.7865; time: 0.95sec
[341/800][24/24] total train loss: 0.0063; total val loss: 0.4965 val r: 0.7828; time: 0.95sec
[342/800][24/24] total train loss: 0.0065; total val loss: 0.4985 val r: 0.7878; time: 0.95sec
[343/800][24/24] total train loss: 0.0066; total val loss: 0.5092 val r: 0.7858; time: 0.95sec
[344/800][24/24] total train loss: 0.0066; total val loss: 0.5135 val r: 0.7892; time: 0.94sec
[345/800][24/24] total train loss: 0.0066; total val loss: 0.5083 val r: 0.7867; time: 0.94sec
[346/800][24/24] total train loss: 0.0066; total val loss: 0.4909 val r: 0.7876; time: 0.94sec
[347/800][24/24] total train loss: 0.0068; total val loss: 0.5007 val r: 0.7904; time: 0.95sec
[348/800][24/24] total train loss: 0.0137; total val loss: 0.5062 val r: 0.7593; time: 0.95sec
[349/800][24/24] total train loss: 0.0404; total val loss: 0.5008 val r: 0.7644; time: 0.94sec
[350/800][24/24] total train loss: 0.0452; total val loss: 0.4719 val r: 0.7619; time: 0.95sec
[351/800][24/24] total train loss: 0.0397; total val loss: 0.5489 val r: 0.7756; time: 0.94sec
[352/800][24/24] total train loss: 0.0228; total val loss: 0.5271 val r: 0.7882; time: 0.94sec
[353/800][24/24] total train loss: 0.0150; total val loss: 0.4763 val r: 0.7820; time: 0.96sec
[354/800][24/24] total train loss: 0.0120; total val loss: 0.4690 val r: 0.7838; time: 0.95sec
[355/800][24/24] total train loss: 0.0092; total val loss: 0.5071 val r: 0.7848; time: 0.94sec
[356/800][24/24] total train loss: 0.0078; total val loss: 0.5008 val r: 0.7850; time: 0.95sec
[357/800][24/24] total train loss: 0.0073; total val loss: 0.4703 val r: 0.7872; time: 0.95sec
[358/800][24/24] total train loss: 0.0070; total val loss: 0.4983 val r: 0.7844; time: 0.94sec
[359/800][24/24] total train loss: 0.0071; total val loss: 0.4930 val r: 0.7865; time: 0.95sec
[360/800][24/24] total train loss: 0.0068; total val loss: 0.4976 val r: 0.7866; time: 0.95sec
[361/800][24/24] total train loss: 0.0066; total val loss: 0.4810 val r: 0.7890; time: 0.95sec
[362/800][24/24] total train loss: 0.0064; total val loss: 0.4670 val r: 0.7874; time: 0.94sec
[363/800][24/24] total train loss: 0.0064; total val loss: 0.5065 val r: 0.7899; time: 0.94sec
[364/800][24/24] total train loss: 0.0064; total val loss: 0.4894 val r: 0.7886; time: 0.96sec
[365/800][24/24] total train loss: 0.0066; total val loss: 0.4960 val r: 0.7864; time: 0.95sec
[366/800][24/24] total train loss: 0.0070; total val loss: 0.5073 val r: 0.7840; time: 0.94sec
[367/800][24/24] total train loss: 0.0068; total val loss: 0.5004 val r: 0.7882; time: 0.95sec
[368/800][24/24] total train loss: 0.0066; total val loss: 0.4957 val r: 0.7880; time: 0.95sec
[369/800][24/24] total train loss: 0.0066; total val loss: 0.5005 val r: 0.7880; time: 0.95sec
[370/800][24/24] total train loss: 0.0065; total val loss: 0.5108 val r: 0.7875; time: 0.94sec
[371/800][24/24] total train loss: 0.0066; total val loss: 0.5116 val r: 0.7860; time: 0.94sec
[372/800][24/24] total train loss: 0.0064; total val loss: 0.4973 val r: 0.7861; time: 0.95sec
[373/800][24/24] total train loss: 0.0063; total val loss: 0.4831 val r: 0.7881; time: 0.94sec
[374/800][24/24] total train loss: 0.0065; total val loss: 0.5007 val r: 0.7911; time: 0.95sec
[375/800][24/24] total train loss: 0.0068; total val loss: 0.5001 val r: 0.7862; time: 0.94sec
[376/800][24/24] total train loss: 0.0066; total val loss: 0.4866 val r: 0.7915; time: 0.93sec
[377/800][24/24] total train loss: 0.0065; total val loss: 0.4890 val r: 0.7905; time: 0.94sec
[378/800][24/24] total train loss: 0.0064; total val loss: 0.4940 val r: 0.7881; time: 0.94sec
[379/800][24/24] total train loss: 0.0064; total val loss: 0.5134 val r: 0.7887; time: 0.93sec
[380/800][24/24] total train loss: 0.0067; total val loss: 0.4975 val r: 0.7886; time: 0.94sec
[381/800][24/24] total train loss: 0.0069; total val loss: 0.5063 val r: 0.7881; time: 0.94sec
[382/800][24/24] total train loss: 0.0065; total val loss: 0.5113 val r: 0.7867; time: 0.95sec
[383/800][24/24] total train loss: 0.0063; total val loss: 0.4922 val r: 0.7890; time: 0.94sec
[384/800][24/24] total train loss: 0.0064; total val loss: 0.5001 val r: 0.7863; time: 0.94sec
[385/800][24/24] total train loss: 0.0063; total val loss: 0.4929 val r: 0.7884; time: 0.95sec
[386/800][24/24] total train loss: 0.0065; total val loss: 0.4911 val r: 0.7872; time: 0.94sec
[387/800][24/24] total train loss: 0.0062; total val loss: 0.4878 val r: 0.7873; time: 0.94sec
[388/800][24/24] total train loss: 0.0064; total val loss: 0.4909 val r: 0.7884; time: 0.94sec
[389/800][24/24] total train loss: 0.0064; total val loss: 0.5061 val r: 0.7890; time: 0.94sec
[390/800][24/24] total train loss: 0.0063; total val loss: 0.4975 val r: 0.7861; time: 0.94sec
[391/800][24/24] total train loss: 0.0064; total val loss: 0.5059 val r: 0.7857; time: 0.95sec
[392/800][24/24] total train loss: 0.0062; total val loss: 0.5003 val r: 0.7900; time: 0.95sec
[393/800][24/24] total train loss: 0.0062; total val loss: 0.5039 val r: 0.7896; time: 0.94sec
[394/800][24/24] total train loss: 0.0064; total val loss: 0.4916 val r: 0.7867; time: 0.94sec
[395/800][24/24] total train loss: 0.0068; total val loss: 0.5190 val r: 0.7864; time: 0.95sec
[396/800][24/24] total train loss: 0.0072; total val loss: 0.4928 val r: 0.7860; time: 0.95sec
[397/800][24/24] total train loss: 0.0065; total val loss: 0.4819 val r: 0.7873; time: 0.96sec
[398/800][24/24] total train loss: 0.0064; total val loss: 0.4914 val r: 0.7881; time: 0.94sec
[399/800][24/24] total train loss: 0.0065; total val loss: 0.5012 val r: 0.7851; time: 0.95sec
learning rate updated: 0.001
[400/800][24/24] total train loss: 0.0065; total val loss: 0.4931 val r: 0.7883; time: 0.94sec
[401/800][24/24] total train loss: 0.0063; total val loss: 0.4968 val r: 0.7882; time: 0.94sec
[402/800][24/24] total train loss: 0.0064; total val loss: 0.5004 val r: 0.7882; time: 0.94sec
[403/800][24/24] total train loss: 0.0064; total val loss: 0.4975 val r: 0.7866; time: 0.95sec
[404/800][24/24] total train loss: 0.0063; total val loss: 0.4892 val r: 0.7888; time: 0.94sec
[405/800][24/24] total train loss: 0.0062; total val loss: 0.4960 val r: 0.7882; time: 0.94sec
[406/800][24/24] total train loss: 0.0061; total val loss: 0.4913 val r: 0.7894; time: 0.95sec
[407/800][24/24] total train loss: 0.0062; total val loss: 0.4858 val r: 0.7891; time: 0.94sec
[408/800][24/24] total train loss: 0.0063; total val loss: 0.5019 val r: 0.7866; time: 0.95sec
[409/800][24/24] total train loss: 0.0064; total val loss: 0.4956 val r: 0.7885; time: 0.94sec
[410/800][24/24] total train loss: 0.0063; total val loss: 0.4974 val r: 0.7872; time: 0.95sec
[411/800][24/24] total train loss: 0.0063; total val loss: 0.4927 val r: 0.7880; time: 0.95sec
[412/800][24/24] total train loss: 0.0061; total val loss: 0.5146 val r: 0.7882; time: 0.95sec
[413/800][24/24] total train loss: 0.0064; total val loss: 0.4935 val r: 0.7889; time: 0.95sec
[414/800][24/24] total train loss: 0.0065; total val loss: 0.4822 val r: 0.7900; time: 0.94sec
[415/800][24/24] total train loss: 0.0065; total val loss: 0.4986 val r: 0.7876; time: 0.94sec
[416/800][24/24] total train loss: 0.0064; total val loss: 0.4931 val r: 0.7884; time: 0.94sec
[417/800][24/24] total train loss: 0.0066; total val loss: 0.5054 val r: 0.7888; time: 0.95sec
[418/800][24/24] total train loss: 0.0069; total val loss: 0.5002 val r: 0.7872; time: 0.95sec
[419/800][24/24] total train loss: 0.0064; total val loss: 0.5105 val r: 0.7878; time: 0.95sec
[420/800][24/24] total train loss: 0.0065; total val loss: 0.5007 val r: 0.7909; time: 0.94sec
[421/800][24/24] total train loss: 0.0064; total val loss: 0.4909 val r: 0.7878; time: 0.95sec
[422/800][24/24] total train loss: 0.0064; total val loss: 0.4991 val r: 0.7891; time: 0.94sec
[423/800][24/24] total train loss: 0.0064; total val loss: 0.4921 val r: 0.7874; time: 0.94sec
[424/800][24/24] total train loss: 0.0062; total val loss: 0.4984 val r: 0.7899; time: 0.95sec
[425/800][24/24] total train loss: 0.0061; total val loss: 0.5110 val r: 0.7903; time: 0.95sec
[426/800][24/24] total train loss: 0.0064; total val loss: 0.4976 val r: 0.7920; time: 0.95sec
[427/800][24/24] total train loss: 0.0064; total val loss: 0.5157 val r: 0.7895; time: 0.94sec
[428/800][24/24] total train loss: 0.0062; total val loss: 0.4880 val r: 0.7919; time: 0.95sec
[429/800][24/24] total train loss: 0.0065; total val loss: 0.4932 val r: 0.7880; time: 0.94sec
[430/800][24/24] total train loss: 0.0064; total val loss: 0.5032 val r: 0.7883; time: 0.95sec
[431/800][24/24] total train loss: 0.0063; total val loss: 0.4941 val r: 0.7877; time: 0.95sec
[432/800][24/24] total train loss: 0.0064; total val loss: 0.5047 val r: 0.7879; time: 0.96sec
[433/800][24/24] total train loss: 0.0063; total val loss: 0.5050 val r: 0.7868; time: 0.95sec
[434/800][24/24] total train loss: 0.0062; total val loss: 0.4963 val r: 0.7865; time: 0.95sec
[435/800][24/24] total train loss: 0.0062; total val loss: 0.5014 val r: 0.7886; time: 0.95sec
[436/800][24/24] total train loss: 0.0062; total val loss: 0.4895 val r: 0.7881; time: 0.95sec
[437/800][24/24] total train loss: 0.0063; total val loss: 0.4856 val r: 0.7892; time: 0.95sec
[438/800][24/24] total train loss: 0.0065; total val loss: 0.5024 val r: 0.7913; time: 0.95sec
[439/800][24/24] total train loss: 0.0065; total val loss: 0.4868 val r: 0.7866; time: 0.95sec
[440/800][24/24] total train loss: 0.0064; total val loss: 0.5018 val r: 0.7895; time: 0.93sec
[441/800][24/24] total train loss: 0.0064; total val loss: 0.4962 val r: 0.7909; time: 0.94sec
[442/800][24/24] total train loss: 0.0063; total val loss: 0.4975 val r: 0.7892; time: 0.94sec
[443/800][24/24] total train loss: 0.0064; total val loss: 0.4964 val r: 0.7888; time: 0.95sec
[444/800][24/24] total train loss: 0.0064; total val loss: 0.5113 val r: 0.7883; time: 0.94sec
[445/800][24/24] total train loss: 0.0065; total val loss: 0.4839 val r: 0.7909; time: 0.95sec
[446/800][24/24] total train loss: 0.0064; total val loss: 0.4993 val r: 0.7891; time: 0.94sec
[447/800][24/24] total train loss: 0.0064; total val loss: 0.4946 val r: 0.7885; time: 0.95sec
[448/800][24/24] total train loss: 0.0065; total val loss: 0.5043 val r: 0.7885; time: 0.95sec
[449/800][24/24] total train loss: 0.0063; total val loss: 0.5070 val r: 0.7879; time: 0.94sec
[450/800][24/24] total train loss: 0.0062; total val loss: 0.4871 val r: 0.7884; time: 0.95sec
[451/800][24/24] total train loss: 0.0064; total val loss: 0.5121 val r: 0.7879; time: 0.94sec
[452/800][24/24] total train loss: 0.0065; total val loss: 0.5092 val r: 0.7863; time: 0.95sec
[453/800][24/24] total train loss: 0.0066; total val loss: 0.4928 val r: 0.7895; time: 0.95sec
[454/800][24/24] total train loss: 0.0064; total val loss: 0.4968 val r: 0.7919; time: 0.94sec
[455/800][24/24] total train loss: 0.0065; total val loss: 0.4957 val r: 0.7894; time: 0.95sec
[456/800][24/24] total train loss: 0.0062; total val loss: 0.4879 val r: 0.7885; time: 0.94sec
[457/800][24/24] total train loss: 0.0063; total val loss: 0.5026 val r: 0.7873; time: 0.94sec
[458/800][24/24] total train loss: 0.0063; total val loss: 0.4830 val r: 0.7856; time: 0.94sec
[459/800][24/24] total train loss: 0.0060; total val loss: 0.4899 val r: 0.7889; time: 0.95sec
[460/800][24/24] total train loss: 0.0061; total val loss: 0.5024 val r: 0.7880; time: 0.96sec
[461/800][24/24] total train loss: 0.0063; total val loss: 0.4976 val r: 0.7882; time: 0.95sec
[462/800][24/24] total train loss: 0.0063; total val loss: 0.4974 val r: 0.7872; time: 0.95sec
[463/800][24/24] total train loss: 0.0062; total val loss: 0.5101 val r: 0.7877; time: 0.94sec
[464/800][24/24] total train loss: 0.0064; total val loss: 0.5141 val r: 0.7870; time: 0.95sec
[465/800][24/24] total train loss: 0.0062; total val loss: 0.4969 val r: 0.7868; time: 0.95sec
[466/800][24/24] total train loss: 0.0062; total val loss: 0.4871 val r: 0.7866; time: 0.94sec
[467/800][24/24] total train loss: 0.0061; total val loss: 0.4998 val r: 0.7895; time: 0.95sec
[468/800][24/24] total train loss: 0.0063; total val loss: 0.4998 val r: 0.7878; time: 0.95sec
[469/800][24/24] total train loss: 0.0063; total val loss: 0.5050 val r: 0.7893; time: 0.95sec
[470/800][24/24] total train loss: 0.0064; total val loss: 0.4839 val r: 0.7891; time: 0.94sec
[471/800][24/24] total train loss: 0.0064; total val loss: 0.5050 val r: 0.7884; time: 0.95sec
[472/800][24/24] total train loss: 0.0064; total val loss: 0.4889 val r: 0.7870; time: 0.95sec
[473/800][24/24] total train loss: 0.0064; total val loss: 0.4893 val r: 0.7893; time: 0.95sec
[474/800][24/24] total train loss: 0.0062; total val loss: 0.5101 val r: 0.7890; time: 0.95sec
[475/800][24/24] total train loss: 0.0066; total val loss: 0.5110 val r: 0.7900; time: 0.95sec
[476/800][24/24] total train loss: 0.0062; total val loss: 0.5033 val r: 0.7884; time: 0.94sec
[477/800][24/24] total train loss: 0.0062; total val loss: 0.4924 val r: 0.7902; time: 0.95sec
[478/800][24/24] total train loss: 0.0061; total val loss: 0.4996 val r: 0.7891; time: 0.94sec
[479/800][24/24] total train loss: 0.0062; total val loss: 0.5034 val r: 0.7886; time: 0.94sec
[480/800][24/24] total train loss: 0.0064; total val loss: 0.5060 val r: 0.7872; time: 0.95sec
[481/800][24/24] total train loss: 0.0063; total val loss: 0.5153 val r: 0.7894; time: 0.95sec
[482/800][24/24] total train loss: 0.0061; total val loss: 0.4965 val r: 0.7880; time: 0.95sec
[483/800][24/24] total train loss: 0.0060; total val loss: 0.4959 val r: 0.7907; time: 0.95sec
[484/800][24/24] total train loss: 0.0062; total val loss: 0.5057 val r: 0.7897; time: 0.95sec
[485/800][24/24] total train loss: 0.0061; total val loss: 0.5081 val r: 0.7897; time: 0.95sec
[486/800][24/24] total train loss: 0.0060; total val loss: 0.5000 val r: 0.7891; time: 0.95sec
[487/800][24/24] total train loss: 0.0063; total val loss: 0.4856 val r: 0.7892; time: 0.95sec
[488/800][24/24] total train loss: 0.0066; total val loss: 0.5116 val r: 0.7894; time: 0.95sec
[489/800][24/24] total train loss: 0.0064; total val loss: 0.4958 val r: 0.7875; time: 0.94sec
[490/800][24/24] total train loss: 0.0062; total val loss: 0.4912 val r: 0.7890; time: 0.95sec
[491/800][24/24] total train loss: 0.0063; total val loss: 0.4878 val r: 0.7898; time: 0.94sec
[492/800][24/24] total train loss: 0.0063; total val loss: 0.5130 val r: 0.7870; time: 0.95sec
[493/800][24/24] total train loss: 0.0065; total val loss: 0.5038 val r: 0.7883; time: 0.95sec
[494/800][24/24] total train loss: 0.0064; total val loss: 0.5134 val r: 0.7873; time: 0.94sec
[495/800][24/24] total train loss: 0.0062; total val loss: 0.5027 val r: 0.7892; time: 0.94sec
[496/800][24/24] total train loss: 0.0062; total val loss: 0.4808 val r: 0.7869; time: 0.94sec
[497/800][24/24] total train loss: 0.0062; total val loss: 0.4880 val r: 0.7893; time: 0.94sec
[498/800][24/24] total train loss: 0.0063; total val loss: 0.4971 val r: 0.7873; time: 0.95sec
[499/800][24/24] total train loss: 0.0063; total val loss: 0.4970 val r: 0.7887; time: 0.94sec
learning rate updated: 0.001
[500/800][24/24] total train loss: 0.0061; total val loss: 0.4956 val r: 0.7906; time: 0.95sec
[501/800][24/24] total train loss: 0.0062; total val loss: 0.5008 val r: 0.7875; time: 0.94sec
[502/800][24/24] total train loss: 0.0062; total val loss: 0.4716 val r: 0.7902; time: 0.95sec
[503/800][24/24] total train loss: 0.0064; total val loss: 0.4899 val r: 0.7886; time: 0.96sec
[504/800][24/24] total train loss: 0.0064; total val loss: 0.5060 val r: 0.7880; time: 0.96sec
[505/800][24/24] total train loss: 0.0063; total val loss: 0.5007 val r: 0.7874; time: 0.94sec
[506/800][24/24] total train loss: 0.0062; total val loss: 0.4938 val r: 0.7892; time: 0.95sec
[507/800][24/24] total train loss: 0.0065; total val loss: 0.4873 val r: 0.7893; time: 0.94sec
[508/800][24/24] total train loss: 0.0064; total val loss: 0.5039 val r: 0.7895; time: 0.94sec
[509/800][24/24] total train loss: 0.0061; total val loss: 0.5022 val r: 0.7870; time: 0.95sec
[510/800][24/24] total train loss: 0.0063; total val loss: 0.5107 val r: 0.7846; time: 0.94sec
[511/800][24/24] total train loss: 0.0061; total val loss: 0.4985 val r: 0.7908; time: 0.94sec
[512/800][24/24] total train loss: 0.0062; total val loss: 0.4965 val r: 0.7890; time: 0.95sec
[513/800][24/24] total train loss: 0.0064; total val loss: 0.5010 val r: 0.7870; time: 0.94sec
[514/800][24/24] total train loss: 0.0063; total val loss: 0.5101 val r: 0.7861; time: 0.94sec
[515/800][24/24] total train loss: 0.0064; total val loss: 0.4966 val r: 0.7867; time: 0.95sec
[516/800][24/24] total train loss: 0.0064; total val loss: 0.5085 val r: 0.7906; time: 0.94sec
[517/800][24/24] total train loss: 0.0062; total val loss: 0.4925 val r: 0.7898; time: 0.94sec
[518/800][24/24] total train loss: 0.0061; total val loss: 0.4900 val r: 0.7890; time: 0.95sec
[519/800][24/24] total train loss: 0.0062; total val loss: 0.5135 val r: 0.7881; time: 0.95sec
[520/800][24/24] total train loss: 0.0061; total val loss: 0.4928 val r: 0.7859; time: 0.96sec
[521/800][24/24] total train loss: 0.0062; total val loss: 0.4958 val r: 0.7894; time: 0.94sec
[522/800][24/24] total train loss: 0.0059; total val loss: 0.5124 val r: 0.7898; time: 0.95sec
[523/800][24/24] total train loss: 0.0064; total val loss: 0.4987 val r: 0.7881; time: 0.95sec
[524/800][24/24] total train loss: 0.0063; total val loss: 0.5039 val r: 0.7859; time: 0.95sec
[525/800][24/24] total train loss: 0.0065; total val loss: 0.4937 val r: 0.7900; time: 0.95sec
[526/800][24/24] total train loss: 0.0063; total val loss: 0.4950 val r: 0.7893; time: 0.94sec
[527/800][24/24] total train loss: 0.0062; total val loss: 0.4977 val r: 0.7912; time: 0.95sec
[528/800][24/24] total train loss: 0.0063; total val loss: 0.4908 val r: 0.7893; time: 0.96sec
[529/800][24/24] total train loss: 0.0064; total val loss: 0.4967 val r: 0.7865; time: 0.95sec
[530/800][24/24] total train loss: 0.0064; total val loss: 0.4971 val r: 0.7874; time: 0.94sec
[531/800][24/24] total train loss: 0.0065; total val loss: 0.4972 val r: 0.7859; time: 0.95sec
[532/800][24/24] total train loss: 0.0062; total val loss: 0.4937 val r: 0.7921; time: 0.95sec
[533/800][24/24] total train loss: 0.0063; total val loss: 0.5035 val r: 0.7882; time: 0.95sec
[534/800][24/24] total train loss: 0.0062; total val loss: 0.4858 val r: 0.7908; time: 0.94sec
[535/800][24/24] total train loss: 0.0060; total val loss: 0.5048 val r: 0.7897; time: 0.94sec
[536/800][24/24] total train loss: 0.0059; total val loss: 0.5078 val r: 0.7880; time: 0.95sec
[537/800][24/24] total train loss: 0.0063; total val loss: 0.5049 val r: 0.7881; time: 0.95sec
[538/800][24/24] total train loss: 0.0061; total val loss: 0.4965 val r: 0.7873; time: 0.94sec
[539/800][24/24] total train loss: 0.0063; total val loss: 0.5032 val r: 0.7904; time: 0.94sec
[540/800][24/24] total train loss: 0.0065; total val loss: 0.4946 val r: 0.7902; time: 0.95sec
[541/800][24/24] total train loss: 0.0062; total val loss: 0.5197 val r: 0.7899; time: 0.95sec
[542/800][24/24] total train loss: 0.0064; total val loss: 0.5107 val r: 0.7865; time: 0.95sec
[543/800][24/24] total train loss: 0.0061; total val loss: 0.5125 val r: 0.7879; time: 0.95sec
[544/800][24/24] total train loss: 0.0062; total val loss: 0.4902 val r: 0.7866; time: 0.94sec
[545/800][24/24] total train loss: 0.0062; total val loss: 0.4994 val r: 0.7861; time: 0.94sec
[546/800][24/24] total train loss: 0.0063; total val loss: 0.5001 val r: 0.7856; time: 0.94sec
[547/800][24/24] total train loss: 0.0063; total val loss: 0.5131 val r: 0.7881; time: 0.95sec
[548/800][24/24] total train loss: 0.0063; total val loss: 0.4852 val r: 0.7880; time: 0.95sec
[549/800][24/24] total train loss: 0.0063; total val loss: 0.5035 val r: 0.7858; time: 0.95sec
[550/800][24/24] total train loss: 0.0061; total val loss: 0.4862 val r: 0.7878; time: 0.95sec
[551/800][24/24] total train loss: 0.0063; total val loss: 0.5087 val r: 0.7867; time: 0.95sec
[552/800][24/24] total train loss: 0.0062; total val loss: 0.5013 val r: 0.7870; time: 0.94sec
[553/800][24/24] total train loss: 0.0062; total val loss: 0.5070 val r: 0.7873; time: 0.95sec
[554/800][24/24] total train loss: 0.0063; total val loss: 0.4860 val r: 0.7886; time: 0.95sec
[555/800][24/24] total train loss: 0.0062; total val loss: 0.4898 val r: 0.7865; time: 0.94sec
[556/800][24/24] total train loss: 0.0061; total val loss: 0.4978 val r: 0.7886; time: 0.94sec
[557/800][24/24] total train loss: 0.0062; total val loss: 0.5250 val r: 0.7840; time: 0.95sec
[558/800][24/24] total train loss: 0.0063; total val loss: 0.4936 val r: 0.7870; time: 0.95sec
[559/800][24/24] total train loss: 0.0062; total val loss: 0.4791 val r: 0.7869; time: 0.94sec
[560/800][24/24] total train loss: 0.0062; total val loss: 0.4863 val r: 0.7873; time: 0.95sec
[561/800][24/24] total train loss: 0.0063; total val loss: 0.4871 val r: 0.7897; time: 0.94sec
[562/800][24/24] total train loss: 0.0061; total val loss: 0.5014 val r: 0.7891; time: 0.95sec
[563/800][24/24] total train loss: 0.0063; total val loss: 0.5098 val r: 0.7872; time: 0.95sec
[564/800][24/24] total train loss: 0.0062; total val loss: 0.4954 val r: 0.7910; time: 0.95sec
[565/800][24/24] total train loss: 0.0060; total val loss: 0.4842 val r: 0.7891; time: 0.95sec
[566/800][24/24] total train loss: 0.0061; total val loss: 0.4953 val r: 0.7889; time: 0.94sec
[567/800][24/24] total train loss: 0.0060; total val loss: 0.4887 val r: 0.7899; time: 0.95sec
[568/800][24/24] total train loss: 0.0060; total val loss: 0.4966 val r: 0.7880; time: 0.95sec
[569/800][24/24] total train loss: 0.0061; total val loss: 0.4977 val r: 0.7886; time: 0.95sec
[570/800][24/24] total train loss: 0.0061; total val loss: 0.5067 val r: 0.7894; time: 0.95sec
[571/800][24/24] total train loss: 0.0062; total val loss: 0.4758 val r: 0.7898; time: 0.96sec
[572/800][24/24] total train loss: 0.0062; total val loss: 0.5003 val r: 0.7898; time: 0.95sec
[573/800][24/24] total train loss: 0.0059; total val loss: 0.4949 val r: 0.7895; time: 0.94sec
[574/800][24/24] total train loss: 0.0062; total val loss: 0.5022 val r: 0.7892; time: 0.94sec
[575/800][24/24] total train loss: 0.0062; total val loss: 0.5056 val r: 0.7878; time: 0.95sec
[576/800][24/24] total train loss: 0.0060; total val loss: 0.4971 val r: 0.7867; time: 0.95sec
[577/800][24/24] total train loss: 0.0063; total val loss: 0.4996 val r: 0.7865; time: 0.95sec
[578/800][24/24] total train loss: 0.0064; total val loss: 0.5041 val r: 0.7891; time: 0.96sec
[579/800][24/24] total train loss: 0.0062; total val loss: 0.4991 val r: 0.7892; time: 0.94sec
[580/800][24/24] total train loss: 0.0061; total val loss: 0.4979 val r: 0.7890; time: 0.95sec
[581/800][24/24] total train loss: 0.0063; total val loss: 0.4784 val r: 0.7913; time: 0.95sec
[582/800][24/24] total train loss: 0.0064; total val loss: 0.5017 val r: 0.7883; time: 0.95sec
[583/800][24/24] total train loss: 0.0064; total val loss: 0.4997 val r: 0.7866; time: 0.94sec
[584/800][24/24] total train loss: 0.0062; total val loss: 0.4935 val r: 0.7906; time: 0.95sec
[585/800][24/24] total train loss: 0.0062; total val loss: 0.5037 val r: 0.7871; time: 0.95sec
[586/800][24/24] total train loss: 0.0062; total val loss: 0.5100 val r: 0.7872; time: 0.95sec
[587/800][24/24] total train loss: 0.0062; total val loss: 0.5178 val r: 0.7874; time: 0.96sec
[588/800][24/24] total train loss: 0.0060; total val loss: 0.4753 val r: 0.7877; time: 0.95sec
[589/800][24/24] total train loss: 0.0062; total val loss: 0.4958 val r: 0.7883; time: 0.95sec
[590/800][24/24] total train loss: 0.0062; total val loss: 0.5041 val r: 0.7894; time: 0.95sec
[591/800][24/24] total train loss: 0.0061; total val loss: 0.4884 val r: 0.7888; time: 0.95sec
[592/800][24/24] total train loss: 0.0061; total val loss: 0.5001 val r: 0.7894; time: 0.95sec
[593/800][24/24] total train loss: 0.0060; total val loss: 0.5024 val r: 0.7888; time: 0.94sec
[594/800][24/24] total train loss: 0.0061; total val loss: 0.4954 val r: 0.7884; time: 0.94sec
[595/800][24/24] total train loss: 0.0060; total val loss: 0.4820 val r: 0.7912; time: 0.95sec
[596/800][24/24] total train loss: 0.0060; total val loss: 0.4945 val r: 0.7889; time: 0.96sec
[597/800][24/24] total train loss: 0.0063; total val loss: 0.4985 val r: 0.7909; time: 0.96sec
[598/800][24/24] total train loss: 0.0062; total val loss: 0.4955 val r: 0.7897; time: 0.96sec
[599/800][24/24] total train loss: 0.0063; total val loss: 0.5041 val r: 0.7879; time: 0.95sec
learning rate updated: 0.001
[600/800][24/24] total train loss: 0.0061; total val loss: 0.4835 val r: 0.7894; time: 0.94sec
[601/800][24/24] total train loss: 0.0062; total val loss: 0.5039 val r: 0.7900; time: 0.95sec
[602/800][24/24] total train loss: 0.0063; total val loss: 0.5094 val r: 0.7907; time: 0.95sec
[603/800][24/24] total train loss: 0.0060; total val loss: 0.5050 val r: 0.7877; time: 0.94sec
[604/800][24/24] total train loss: 0.0059; total val loss: 0.5024 val r: 0.7870; time: 0.94sec
[605/800][24/24] total train loss: 0.0060; total val loss: 0.5042 val r: 0.7892; time: 0.95sec
[606/800][24/24] total train loss: 0.0060; total val loss: 0.4968 val r: 0.7882; time: 0.95sec
[607/800][24/24] total train loss: 0.0060; total val loss: 0.4957 val r: 0.7902; time: 0.94sec
[608/800][24/24] total train loss: 0.0061; total val loss: 0.5029 val r: 0.7873; time: 0.95sec
[609/800][24/24] total train loss: 0.0060; total val loss: 0.5159 val r: 0.7879; time: 0.94sec
[610/800][24/24] total train loss: 0.0060; total val loss: 0.5003 val r: 0.7858; time: 0.95sec
[611/800][24/24] total train loss: 0.0059; total val loss: 0.4989 val r: 0.7918; time: 0.94sec
[612/800][24/24] total train loss: 0.0061; total val loss: 0.5049 val r: 0.7869; time: 0.95sec
[613/800][24/24] total train loss: 0.0060; total val loss: 0.5144 val r: 0.7884; time: 0.94sec
[614/800][24/24] total train loss: 0.0060; total val loss: 0.5021 val r: 0.7873; time: 0.95sec
[615/800][24/24] total train loss: 0.0064; total val loss: 0.4781 val r: 0.7905; time: 0.94sec
[616/800][24/24] total train loss: 0.0066; total val loss: 0.5055 val r: 0.7879; time: 0.96sec
[617/800][24/24] total train loss: 0.0064; total val loss: 0.5194 val r: 0.7871; time: 0.95sec
[618/800][24/24] total train loss: 0.0061; total val loss: 0.5147 val r: 0.7883; time: 0.95sec
[619/800][24/24] total train loss: 0.0060; total val loss: 0.4918 val r: 0.7878; time: 0.95sec
[620/800][24/24] total train loss: 0.0060; total val loss: 0.4808 val r: 0.7890; time: 0.95sec
[621/800][24/24] total train loss: 0.0060; total val loss: 0.5176 val r: 0.7848; time: 0.94sec
[622/800][24/24] total train loss: 0.0060; total val loss: 0.5150 val r: 0.7889; time: 0.96sec
[623/800][24/24] total train loss: 0.0060; total val loss: 0.5000 val r: 0.7892; time: 0.95sec
[624/800][24/24] total train loss: 0.0061; total val loss: 0.5056 val r: 0.7859; time: 0.95sec
[625/800][24/24] total train loss: 0.0061; total val loss: 0.4995 val r: 0.7870; time: 0.95sec
[626/800][24/24] total train loss: 0.0061; total val loss: 0.5000 val r: 0.7885; time: 0.94sec
[627/800][24/24] total train loss: 0.0061; total val loss: 0.4965 val r: 0.7890; time: 0.94sec
[628/800][24/24] total train loss: 0.0060; total val loss: 0.5013 val r: 0.7867; time: 0.95sec
[629/800][24/24] total train loss: 0.0059; total val loss: 0.5074 val r: 0.7873; time: 0.95sec
[630/800][24/24] total train loss: 0.0060; total val loss: 0.5201 val r: 0.7842; time: 0.95sec
[631/800][24/24] total train loss: 0.0060; total val loss: 0.5125 val r: 0.7882; time: 0.94sec
[632/800][24/24] total train loss: 0.0060; total val loss: 0.5036 val r: 0.7860; time: 0.94sec
[633/800][24/24] total train loss: 0.0057; total val loss: 0.5106 val r: 0.7833; time: 0.95sec
[634/800][24/24] total train loss: 0.0060; total val loss: 0.4994 val r: 0.7885; time: 0.94sec
[635/800][24/24] total train loss: 0.0060; total val loss: 0.5120 val r: 0.7856; time: 0.95sec
[636/800][24/24] total train loss: 0.0062; total val loss: 0.5009 val r: 0.7881; time: 0.94sec
[637/800][24/24] total train loss: 0.0062; total val loss: 0.5104 val r: 0.7888; time: 0.94sec
[638/800][24/24] total train loss: 0.0059; total val loss: 0.5035 val r: 0.7833; time: 0.96sec
[639/800][24/24] total train loss: 0.0059; total val loss: 0.4937 val r: 0.7888; time: 0.94sec
[640/800][24/24] total train loss: 0.0060; total val loss: 0.5137 val r: 0.7880; time: 0.95sec
[641/800][24/24] total train loss: 0.0059; total val loss: 0.4881 val r: 0.7883; time: 0.95sec
[642/800][24/24] total train loss: 0.0064; total val loss: 0.5026 val r: 0.7866; time: 0.94sec
[643/800][24/24] total train loss: 0.0059; total val loss: 0.5144 val r: 0.7873; time: 0.94sec
[644/800][24/24] total train loss: 0.0061; total val loss: 0.5073 val r: 0.7870; time: 0.95sec
[645/800][24/24] total train loss: 0.0060; total val loss: 0.5045 val r: 0.7876; time: 0.95sec
[646/800][24/24] total train loss: 0.0062; total val loss: 0.5143 val r: 0.7875; time: 0.93sec
[647/800][24/24] total train loss: 0.0061; total val loss: 0.4864 val r: 0.7882; time: 0.94sec
[648/800][24/24] total train loss: 0.0059; total val loss: 0.4772 val r: 0.7880; time: 0.94sec
[649/800][24/24] total train loss: 0.0060; total val loss: 0.5056 val r: 0.7891; time: 0.94sec
[650/800][24/24] total train loss: 0.0062; total val loss: 0.4983 val r: 0.7841; time: 0.95sec
[651/800][24/24] total train loss: 0.0063; total val loss: 0.5168 val r: 0.7859; time: 0.95sec
[652/800][24/24] total train loss: 0.0062; total val loss: 0.5076 val r: 0.7878; time: 0.95sec
[653/800][24/24] total train loss: 0.0062; total val loss: 0.5037 val r: 0.7876; time: 0.94sec
[654/800][24/24] total train loss: 0.0059; total val loss: 0.5215 val r: 0.7897; time: 0.95sec
[655/800][24/24] total train loss: 0.0059; total val loss: 0.5071 val r: 0.7902; time: 0.95sec
[656/800][24/24] total train loss: 0.0060; total val loss: 0.5109 val r: 0.7887; time: 0.94sec
[657/800][24/24] total train loss: 0.0060; total val loss: 0.4799 val r: 0.7871; time: 0.95sec
[658/800][24/24] total train loss: 0.0059; total val loss: 0.5147 val r: 0.7888; time: 0.95sec
[659/800][24/24] total train loss: 0.0060; total val loss: 0.5085 val r: 0.7880; time: 0.95sec
[660/800][24/24] total train loss: 0.0059; total val loss: 0.5143 val r: 0.7882; time: 0.95sec
[661/800][24/24] total train loss: 0.0059; total val loss: 0.4936 val r: 0.7877; time: 0.95sec
[662/800][24/24] total train loss: 0.0061; total val loss: 0.4994 val r: 0.7871; time: 0.95sec
[663/800][24/24] total train loss: 0.0059; total val loss: 0.4944 val r: 0.7885; time: 0.95sec
[664/800][24/24] total train loss: 0.0060; total val loss: 0.5061 val r: 0.7881; time: 0.95sec
[665/800][24/24] total train loss: 0.0059; total val loss: 0.4873 val r: 0.7876; time: 0.94sec
[666/800][24/24] total train loss: 0.0059; total val loss: 0.5254 val r: 0.7864; time: 0.95sec
[667/800][24/24] total train loss: 0.0060; total val loss: 0.4916 val r: 0.7892; time: 0.94sec
[668/800][24/24] total train loss: 0.0060; total val loss: 0.5146 val r: 0.7864; time: 0.95sec
[669/800][24/24] total train loss: 0.0061; total val loss: 0.5079 val r: 0.7893; time: 0.96sec
[670/800][24/24] total train loss: 0.0061; total val loss: 0.5084 val r: 0.7898; time: 0.95sec
[671/800][24/24] total train loss: 0.0059; total val loss: 0.4873 val r: 0.7909; time: 0.94sec
[672/800][24/24] total train loss: 0.0059; total val loss: 0.4938 val r: 0.7889; time: 0.95sec
[673/800][24/24] total train loss: 0.0060; total val loss: 0.5158 val r: 0.7894; time: 0.95sec
[674/800][24/24] total train loss: 0.0063; total val loss: 0.5145 val r: 0.7862; time: 0.95sec
[675/800][24/24] total train loss: 0.0061; total val loss: 0.5041 val r: 0.7846; time: 0.95sec
[676/800][24/24] total train loss: 0.0059; total val loss: 0.4965 val r: 0.7840; time: 0.94sec
[677/800][24/24] total train loss: 0.0061; total val loss: 0.4999 val r: 0.7852; time: 0.95sec
[678/800][24/24] total train loss: 0.0061; total val loss: 0.5043 val r: 0.7883; time: 0.95sec
[679/800][24/24] total train loss: 0.0059; total val loss: 0.4947 val r: 0.7893; time: 0.95sec
[680/800][24/24] total train loss: 0.0061; total val loss: 0.4970 val r: 0.7867; time: 0.95sec
[681/800][24/24] total train loss: 0.0059; total val loss: 0.5224 val r: 0.7866; time: 0.95sec
[682/800][24/24] total train loss: 0.0063; total val loss: 0.5058 val r: 0.7897; time: 0.95sec
[683/800][24/24] total train loss: 0.0062; total val loss: 0.5100 val r: 0.7921; time: 0.95sec
[684/800][24/24] total train loss: 0.0059; total val loss: 0.4919 val r: 0.7876; time: 0.94sec
[685/800][24/24] total train loss: 0.0060; total val loss: 0.4935 val r: 0.7871; time: 0.95sec
[686/800][24/24] total train loss: 0.0060; total val loss: 0.5233 val r: 0.7857; time: 0.95sec
[687/800][24/24] total train loss: 0.0060; total val loss: 0.5140 val r: 0.7884; time: 0.94sec
[688/800][24/24] total train loss: 0.0060; total val loss: 0.4843 val r: 0.7869; time: 0.95sec
[689/800][24/24] total train loss: 0.0061; total val loss: 0.4977 val r: 0.7868; time: 0.95sec
[690/800][24/24] total train loss: 0.0061; total val loss: 0.5130 val r: 0.7867; time: 0.94sec
[691/800][24/24] total train loss: 0.0062; total val loss: 0.5066 val r: 0.7873; time: 0.95sec
[692/800][24/24] total train loss: 0.0061; total val loss: 0.5112 val r: 0.7863; time: 0.95sec
[693/800][24/24] total train loss: 0.0063; total val loss: 0.5339 val r: 0.7862; time: 0.95sec
[694/800][24/24] total train loss: 0.0061; total val loss: 0.5088 val r: 0.7887; time: 0.95sec
[695/800][24/24] total train loss: 0.0060; total val loss: 0.4846 val r: 0.7878; time: 0.94sec
[696/800][24/24] total train loss: 0.0062; total val loss: 0.5288 val r: 0.7890; time: 0.95sec
[697/800][24/24] total train loss: 0.0060; total val loss: 0.4928 val r: 0.7874; time: 0.95sec
[698/800][24/24] total train loss: 0.0061; total val loss: 0.5042 val r: 0.7867; time: 0.94sec
[699/800][24/24] total train loss: 0.0061; total val loss: 0.5162 val r: 0.7859; time: 0.95sec
learning rate updated: 0.001
[700/800][24/24] total train loss: 0.0062; total val loss: 0.4982 val r: 0.7907; time: 0.95sec
[701/800][24/24] total train loss: 0.0062; total val loss: 0.5215 val r: 0.7877; time: 0.95sec
[702/800][24/24] total train loss: 0.0063; total val loss: 0.4762 val r: 0.7878; time: 0.95sec
[703/800][24/24] total train loss: 0.0061; total val loss: 0.5078 val r: 0.7904; time: 0.94sec
[704/800][24/24] total train loss: 0.0061; total val loss: 0.4882 val r: 0.7846; time: 0.93sec
[705/800][24/24] total train loss: 0.0061; total val loss: 0.4885 val r: 0.7870; time: 0.94sec
[706/800][24/24] total train loss: 0.0061; total val loss: 0.5200 val r: 0.7884; time: 0.93sec
[707/800][24/24] total train loss: 0.0060; total val loss: 0.5164 val r: 0.7856; time: 0.93sec
[708/800][24/24] total train loss: 0.0060; total val loss: 0.4943 val r: 0.7894; time: 0.93sec
[709/800][24/24] total train loss: 0.0059; total val loss: 0.4976 val r: 0.7891; time: 0.94sec
[710/800][24/24] total train loss: 0.0060; total val loss: 0.5109 val r: 0.7890; time: 0.94sec
[711/800][24/24] total train loss: 0.0061; total val loss: 0.5054 val r: 0.7887; time: 0.94sec
[712/800][24/24] total train loss: 0.0060; total val loss: 0.5033 val r: 0.7869; time: 0.95sec
[713/800][24/24] total train loss: 0.0058; total val loss: 0.5271 val r: 0.7875; time: 0.95sec
[714/800][24/24] total train loss: 0.0063; total val loss: 0.4963 val r: 0.7881; time: 0.94sec
[715/800][24/24] total train loss: 0.0061; total val loss: 0.4957 val r: 0.7903; time: 0.96sec
[716/800][24/24] total train loss: 0.0060; total val loss: 0.4893 val r: 0.7895; time: 0.94sec
[717/800][24/24] total train loss: 0.0062; total val loss: 0.5137 val r: 0.7865; time: 0.94sec
[718/800][24/24] total train loss: 0.0059; total val loss: 0.5057 val r: 0.7864; time: 0.95sec
[719/800][24/24] total train loss: 0.0059; total val loss: 0.5227 val r: 0.7879; time: 0.95sec
[720/800][24/24] total train loss: 0.0060; total val loss: 0.5192 val r: 0.7888; time: 0.95sec
[721/800][24/24] total train loss: 0.0059; total val loss: 0.4841 val r: 0.7891; time: 0.95sec
[722/800][24/24] total train loss: 0.0060; total val loss: 0.5018 val r: 0.7883; time: 0.95sec
[723/800][24/24] total train loss: 0.0059; total val loss: 0.4910 val r: 0.7867; time: 0.94sec
[724/800][24/24] total train loss: 0.0061; total val loss: 0.5154 val r: 0.7891; time: 0.95sec
[725/800][24/24] total train loss: 0.0058; total val loss: 0.5138 val r: 0.7887; time: 0.95sec
[726/800][24/24] total train loss: 0.0058; total val loss: 0.4887 val r: 0.7895; time: 0.95sec
[727/800][24/24] total train loss: 0.0059; total val loss: 0.5078 val r: 0.7905; time: 0.94sec
[728/800][24/24] total train loss: 0.0057; total val loss: 0.5125 val r: 0.7891; time: 0.95sec
[729/800][24/24] total train loss: 0.0056; total val loss: 0.5116 val r: 0.7895; time: 0.95sec
[730/800][24/24] total train loss: 0.0061; total val loss: 0.5069 val r: 0.7934; time: 0.95sec
[731/800][24/24] total train loss: 0.0060; total val loss: 0.5281 val r: 0.7887; time: 0.95sec
[732/800][24/24] total train loss: 0.0059; total val loss: 0.5009 val r: 0.7907; time: 0.94sec
[733/800][24/24] total train loss: 0.0062; total val loss: 0.5183 val r: 0.7882; time: 0.95sec
[734/800][24/24] total train loss: 0.0062; total val loss: 0.5151 val r: 0.7908; time: 0.95sec
[735/800][24/24] total train loss: 0.0061; total val loss: 0.4961 val r: 0.7893; time: 0.95sec
[736/800][24/24] total train loss: 0.0063; total val loss: 0.5115 val r: 0.7878; time: 0.95sec
[737/800][24/24] total train loss: 0.0064; total val loss: 0.4884 val r: 0.7862; time: 0.95sec
[738/800][24/24] total train loss: 0.0061; total val loss: 0.4953 val r: 0.7860; time: 0.94sec
[739/800][24/24] total train loss: 0.0059; total val loss: 0.5147 val r: 0.7867; time: 0.95sec
[740/800][24/24] total train loss: 0.0058; total val loss: 0.5237 val r: 0.7862; time: 0.94sec
[741/800][24/24] total train loss: 0.0061; total val loss: 0.5258 val r: 0.7851; time: 0.94sec
[742/800][24/24] total train loss: 0.0059; total val loss: 0.5094 val r: 0.7861; time: 0.94sec
[743/800][24/24] total train loss: 0.0058; total val loss: 0.5012 val r: 0.7860; time: 0.95sec
[744/800][24/24] total train loss: 0.0060; total val loss: 0.5299 val r: 0.7878; time: 0.94sec
[745/800][24/24] total train loss: 0.0059; total val loss: 0.5084 val r: 0.7877; time: 0.94sec
[746/800][24/24] total train loss: 0.0059; total val loss: 0.5109 val r: 0.7892; time: 0.95sec
[747/800][24/24] total train loss: 0.0059; total val loss: 0.5004 val r: 0.7905; time: 0.94sec
[748/800][24/24] total train loss: 0.0060; total val loss: 0.5142 val r: 0.7865; time: 0.95sec
[749/800][24/24] total train loss: 0.0060; total val loss: 0.5008 val r: 0.7878; time: 0.95sec
[750/800][24/24] total train loss: 0.0060; total val loss: 0.5116 val r: 0.7895; time: 0.95sec
[751/800][24/24] total train loss: 0.0060; total val loss: 0.5122 val r: 0.7899; time: 0.95sec
[752/800][24/24] total train loss: 0.0060; total val loss: 0.5109 val r: 0.7863; time: 0.95sec
[753/800][24/24] total train loss: 0.0058; total val loss: 0.5075 val r: 0.7887; time: 0.96sec
[754/800][24/24] total train loss: 0.0057; total val loss: 0.5099 val r: 0.7877; time: 0.94sec
[755/800][24/24] total train loss: 0.0059; total val loss: 0.5128 val r: 0.7862; time: 0.95sec
[756/800][24/24] total train loss: 0.0062; total val loss: 0.5221 val r: 0.7864; time: 0.95sec
[757/800][24/24] total train loss: 0.0060; total val loss: 0.5059 val r: 0.7885; time: 0.94sec
[758/800][24/24] total train loss: 0.0059; total val loss: 0.5031 val r: 0.7896; time: 0.95sec
[759/800][24/24] total train loss: 0.0060; total val loss: 0.5064 val r: 0.7900; time: 0.94sec
[760/800][24/24] total train loss: 0.0059; total val loss: 0.4911 val r: 0.7874; time: 0.94sec
[761/800][24/24] total train loss: 0.0061; total val loss: 0.5150 val r: 0.7906; time: 0.95sec
[762/800][24/24] total train loss: 0.0061; total val loss: 0.5001 val r: 0.7885; time: 0.95sec
[763/800][24/24] total train loss: 0.0060; total val loss: 0.5244 val r: 0.7885; time: 0.95sec
[764/800][24/24] total train loss: 0.0060; total val loss: 0.5108 val r: 0.7889; time: 0.94sec
[765/800][24/24] total train loss: 0.0057; total val loss: 0.4888 val r: 0.7894; time: 0.95sec
[766/800][24/24] total train loss: 0.0060; total val loss: 0.4913 val r: 0.7883; time: 0.94sec
[767/800][24/24] total train loss: 0.0061; total val loss: 0.5132 val r: 0.7907; time: 0.94sec
[768/800][24/24] total train loss: 0.0059; total val loss: 0.5015 val r: 0.7905; time: 0.95sec
[769/800][24/24] total train loss: 0.0059; total val loss: 0.5132 val r: 0.7900; time: 0.94sec
[770/800][24/24] total train loss: 0.0059; total val loss: 0.4888 val r: 0.7889; time: 0.94sec
[771/800][24/24] total train loss: 0.0059; total val loss: 0.5134 val r: 0.7884; time: 1.01sec
[772/800][24/24] total train loss: 0.0058; total val loss: 0.5175 val r: 0.7877; time: 0.99sec
[773/800][24/24] total train loss: 0.0058; total val loss: 0.5266 val r: 0.7896; time: 0.96sec
[774/800][24/24] total train loss: 0.0060; total val loss: 0.5048 val r: 0.7892; time: 0.95sec
[775/800][24/24] total train loss: 0.0060; total val loss: 0.5237 val r: 0.7889; time: 0.95sec
[776/800][24/24] total train loss: 0.0058; total val loss: 0.5115 val r: 0.7879; time: 0.94sec
[777/800][24/24] total train loss: 0.0059; total val loss: 0.5059 val r: 0.7893; time: 0.95sec
[778/800][24/24] total train loss: 0.0058; total val loss: 0.5248 val r: 0.7888; time: 0.94sec
[779/800][24/24] total train loss: 0.0059; total val loss: 0.5198 val r: 0.7865; time: 0.95sec
[780/800][24/24] total train loss: 0.0060; total val loss: 0.5101 val r: 0.7883; time: 0.95sec
[781/800][24/24] total train loss: 0.0059; total val loss: 0.5026 val r: 0.7884; time: 0.95sec
[782/800][24/24] total train loss: 0.0061; total val loss: 0.5111 val r: 0.7869; time: 0.94sec
[783/800][24/24] total train loss: 0.0060; total val loss: 0.4867 val r: 0.7885; time: 0.96sec
[784/800][24/24] total train loss: 0.0059; total val loss: 0.5278 val r: 0.7873; time: 0.94sec
[785/800][24/24] total train loss: 0.0058; total val loss: 0.5136 val r: 0.7882; time: 0.95sec
[786/800][24/24] total train loss: 0.0058; total val loss: 0.5061 val r: 0.7884; time: 0.95sec
[787/800][24/24] total train loss: 0.0058; total val loss: 0.5076 val r: 0.7891; time: 0.95sec
[788/800][24/24] total train loss: 0.0061; total val loss: 0.5226 val r: 0.7881; time: 0.94sec
[789/800][24/24] total train loss: 0.0060; total val loss: 0.5006 val r: 0.7875; time: 0.95sec
[790/800][24/24] total train loss: 0.0061; total val loss: 0.4942 val r: 0.7917; time: 0.95sec
[791/800][24/24] total train loss: 0.0061; total val loss: 0.5166 val r: 0.7907; time: 0.95sec
[792/800][24/24] total train loss: 0.0059; total val loss: 0.5034 val r: 0.7889; time: 0.95sec
[793/800][24/24] total train loss: 0.0060; total val loss: 0.5043 val r: 0.7886; time: 0.95sec
[794/800][24/24] total train loss: 0.0059; total val loss: 0.5000 val r: 0.7885; time: 0.94sec
[795/800][24/24] total train loss: 0.0058; total val loss: 0.4925 val r: 0.7900; time: 0.95sec
[796/800][24/24] total train loss: 0.0058; total val loss: 0.5078 val r: 0.7902; time: 0.95sec
[797/800][24/24] total train loss: 0.0061; total val loss: 0.4946 val r: 0.7893; time: 0.95sec
[798/800][24/24] total train loss: 0.0061; total val loss: 0.5103 val r: 0.7917; time: 0.94sec
[799/800][24/24] total train loss: 0.0060; total val loss: 0.4926 val r: 0.7927; time: 0.94sec
learning rate updated: 0.001
[800/800][24/24] total train loss: 0.0060; total val loss: 0.5028 val r: 0.7889; time: 0.95sec
Best epoch 730 with val_r = 0.7934.
Highest avg. r=0.7663 achieved at epoch 369 (on validation set).
Avg. train loss: [1.1836038291454316, 0.5995741073042155, 0.4252953477203846, 0.30091523183509705, 0.2107493751682341, 0.13863532631658018, 0.09766225959174335, 0.07475562274921685, 0.060262424929533154, 0.044266775948926806, 0.0345083182444796, 0.027878562384285033, 0.024838589312275873, 0.02420175595325418, 0.02299055437906645, 0.021841401801793836, 0.020485333848046138, 0.019156964065041394, 0.019489199607050978, 0.018661775754299014, 0.018054060818394647, 0.018014628300443293, 0.01648230738937855, 0.01635790609871037, 0.016564487616415137, 0.016766258503776044, 0.015875772009894717, 0.014893915166612714, 0.016473397283698434, 0.015862229984486477, 0.015069274381676222, 0.015069273876724765, 0.014853665939881466, 0.014921895052248146, 0.016641269854153505, 0.016053915850352495, 0.016132082609692587, 0.015433310467051342, 0.014815938047831878, 0.01387955913087353, 0.013153682467236649, 0.01397463881294243, 0.014724356516671833, 0.014481370082648937, 0.01361166682181647, 0.013460111184394918, 0.01320577357255388, 0.013750168847036549, 0.013665457937167957, 0.014533148964983412, 0.014792919081810397, 0.014631585200550034, 0.01474555932363728, 0.0136883064857102, 0.013130243525665719, 0.013230755568656605, 0.012569137124228292, 0.01233938338700682, 0.012371497561980504, 0.012423664567177185, 0.012964335360447877, 0.01243204367783619, 0.012124342824972701, 0.012210917520860676, 0.012427699216641486, 0.01252194810876972, 0.012087051005801186, 0.012603793288872112, 0.012532176032254937, 0.012797586864326149, 0.012285564634657931, 0.011976681064697913, 0.011591051003779284, 0.01161435346948565, 0.012208326347899857, 0.011787476248719031, 0.012158114789053797, 0.011834093293873593, 0.012348145862779348, 0.012614924303488807, 0.0126974928934942, 0.012052935965766665, 0.011890276535996235, 0.0114462369485409, 0.01161410205240827, 0.011929109433549457, 0.011546124565938953, 0.011247698926308659, 0.011354347803717246, 0.011329754343023524, 0.011189087171806023, 0.011368122848216445, 0.011241067396622385, 0.011199722180026583, 0.011145459792169276, 0.011272125782124932, 0.011216016059916002, 0.01136234773148317, 0.011324618496291804, 0.011241038794105407, 0.011000733837136067, 0.011492522172193275, 0.01160898381640436, 0.010926698602270335, 0.01067456053715432, 0.010573839482094626, 0.010822741035372018, 0.01036239140375983, 0.010642120629927376, 0.011066010723880026, 0.010622708444134332, 0.010511410389153753, 0.01079224726126995, 0.010368308448960306, 0.010329188889591024, 0.00988270700108842, 0.010214880273269954, 0.010424805935326732, 0.010668048583465862, 0.010624338245543185, 0.010582901961606694, 0.010376480747072491, 0.010414478614984546, 0.011157471463957336, 0.01138919868899393, 0.011544707637949615, 0.011063208973791917, 0.010524771644850262, 0.010711657887441106, 0.010895389631332363, 0.010698979832523037, 0.010375101972022094, 0.01067383594927378, 0.01044479001138825, 0.010114292421349091, 0.010328672094328795, 0.010048735418968136, 0.009742958947026637, 0.009692117021040758, 0.00975898152537411, 0.009907755827589427, 0.010202170211414341, 0.010547083072015084, 0.010563371793978149, 0.010525453221634961, 0.01083060895834933, 0.011090141722525005, 0.010873980187170673, 0.010851954483950977, 0.010223020187549992, 0.010022372824460035, 0.010194090547156521, 0.010244027129374444, 0.009722888576652622, 0.009576551209465833, 0.010007928600680316, 0.010267536229366669, 0.009903286847111304, 0.009814153284969507, 0.009820352791575716, 0.009741840708011295, 0.009528894491086248, 0.009622922758717322, 0.009945326007436962, 0.009936491949338233, 0.009728554569301195, 0.009598265877866653, 0.009441119812981924, 0.009481665930798045, 0.009782525443733902, 0.009706792252836749, 0.009606176489614881, 0.009566063976672012, 0.009333131337916712, 0.009340304470970295, 0.009740961393981706, 0.010036369415320223, 0.009626907285564812, 0.009815690596587956, 0.009462273149983958, 0.009587723381991963, 0.009619834141994943, 0.00968078197183786, 0.009760516252572415, 0.009487209614599123, 0.009424713294720277, 0.009276764870446642, 0.00901778715706314, 0.008969492946926038, 0.008953392284092842, 0.009343115462252171, 0.00971166133749648, 0.009422328755317722, 0.009227439352980583, 0.009146342382882722, 0.009375705618731444, 0.009249823307254702, 0.009240136473817984, 0.009194809386099224, 0.009304654437801218, 0.009279652401164639, 0.009132974024032592, 0.009137074394675437, 0.009102780158718815, 0.009271555310988333, 0.009240126069926191, 0.009245528396422741, 0.009348714723819285, 0.009410129972093274, 0.009282245853319182, 0.00949049901246326, 0.009294424965628423, 0.008963839102216297, 0.009011013902636478, 0.0087477808319818, 0.008907876790544833, 0.009263872864175937, 0.009326810298807687, 0.008914202132291393, 0.008852366917562905, 0.009370695795951178, 0.009351841274474281, 0.008909163375938079, 0.008998115879512625, 0.008642083049198845, 0.008733823757938807, 0.009013990896710311, 0.009087180536153028, 0.009003705911891303, 0.009193200140180125, 0.009294739939650753, 0.009227885025029536, 0.009181538045959314, 0.009167881179746474, 0.00901810944051249, 0.008959263673023087, 0.00887779120275809, 0.008882181416629465, 0.008664215535463881, 0.009018220524012577, 0.009106028076712392, 0.00901078430142661, 0.009057249423494795, 0.008778017379518133, 0.00864219735012739, 0.008647485772235087, 0.008481443568962277, 0.00856356104122824, 0.00870197437761817, 0.008631470267937402, 0.008795165299306972, 0.008999935596511932, 0.008734534924224135, 0.008563574634172256, 0.00878848860738799, 0.008888695982750505, 0.008791237464538425, 0.008627784277268801, 0.008697807018688764, 0.008755820378428324, 0.008573499519116012, 0.008648031967459247, 0.008721383590818732, 0.00850312025831954, 0.00862554379109497, 0.00850144586111128, 0.008699412910937098, 0.008928040540195071, 0.00866617120700539, 0.008643550766282714, 0.00846084389340831, 0.008529793586058076, 0.008719638171533007, 0.00878139806445688, 0.008620247912404011, 0.008582983372616582, 0.008575956580534694, 0.008494815610902151, 0.008473013954426279, 0.00839405566221103, 0.008489253040534096, 0.008504980416910257, 0.008343277861058596, 0.008382357408117968, 0.008409055689480738, 0.008397606095968513, 0.00848387841724616, 0.008526865778549109, 0.008557433205351118, 0.00863446762523381, 0.008592711000528653, 0.008420515157195042, 0.008492719611240318, 0.008530730411803234, 0.0084633058799227, 0.00849218199855386, 0.008602487542157177, 0.00852959856420057, 0.008587493667437229, 0.008737613941775635, 0.008683093454783375, 0.00856850970594678, 0.008417025206290419, 0.008492279800520919, 0.008542558679255307, 0.008488117117485672, 0.008351228294486646, 0.008207370202580933, 0.008162738736064056, 0.008348264039159402, 0.008282004957800381, 0.008326999881319352, 0.008252828571494319, 0.008124328066696763, 0.008295319726676098, 0.008326722272977349, 0.008366727678367169, 0.00848578533878026, 0.008463440057312255, 0.008215774388008867, 0.008244035144161898, 0.008190062766516348, 0.008267993558911257, 0.008277557511428313, 0.008155291634102469, 0.008386972597327258, 0.00835663052421296, 0.008153852769100921, 0.008180620880739297, 0.008225229443996795, 0.008154206095059634, 0.008136710075450537, 0.008233233177816147, 0.008118735559219204, 0.008198586511753092, 0.008285456769226585, 0.008366818504509866, 0.008270162887129118, 0.008276503615343244, 0.008098205204805708, 0.00808017434719659, 0.008244453498264193, 0.00813267341145547, 0.008125815680978121, 0.008065241874646745, 0.007991002298149396, 0.008075419030501508, 0.00935858606808324, 0.01483634221367538, 0.015869796469269205, 0.01474347832481726, 0.011486780199265922, 0.009767824028313044, 0.009208223943278426, 0.00869214914564509, 0.008388552493124734, 0.008243039762601257, 0.007942814471789461, 0.008171311670230353, 0.008099435973963409, 0.008010070926502522, 0.0079604214799474, 0.008039798240133678, 0.007893720595711784, 0.008020693609614682, 0.00826272967933619, 0.008070151742685994, 0.008010802230273839, 0.008131099477395765, 0.008023505388337071, 0.008086618519519107, 0.008019552592850232, 0.007930667675827863, 0.00806474921246263, 0.008067870450395276, 0.008019447090191534, 0.008000979959433607, 0.008031812739500311, 0.00791658429607196, 0.008069943404734659, 0.00796267625737528, 0.008139073307938815, 0.008009245144239684, 0.007955236759335094, 0.0077909530005854325, 0.007930381836740708, 0.007836855948335142, 0.008007284712039108, 0.007929018787763198, 0.007753675443382235, 0.007832015437634255, 0.00791628995193605, 0.007907638428696373, 0.00808707091891847, 0.008188554455773555, 0.008140817048115423, 0.008174942996993196, 0.00814965547342581, 0.007889206291656592, 0.007915327475893718, 0.007954228965536459, 0.00789725025952066, 0.007912604450029902, 0.007885049246033305, 0.00771195061133767, 0.007830003491835668, 0.007890076985859196, 0.007827478771105234, 0.007777902779344004, 0.007907512063502509, 0.007881970912239921, 0.007739553539795452, 0.007789003539437544, 0.007821844057070848, 0.008019831849742332, 0.007897201485320693, 0.007880441624729428, 0.008151518049089646, 0.00789489594189945, 0.007846058507493581, 0.007848812675911176, 0.007851337198735564, 0.007787025120160251, 0.007812597280008049, 0.007804704702539311, 0.00782281578740367, 0.008001308596612943, 0.007917507167621806, 0.008153856392891613, 0.008103198658500333, 0.00799343661929015, 0.007896821847862157, 0.007839764058189758, 0.007911250455981645, 0.007883077910628344, 0.007793862428115972, 0.007974667707458138, 0.007967303621626343, 0.007894000031956238, 0.009488135971969314, 0.013417399292575283, 0.012921313924925926, 0.011451072889030911, 0.010452478772094764, 0.00919913688867382, 0.008675062584734406, 0.008068382399505936, 0.008087730233455659, 0.007905064356782532, 0.0079290593334008, 0.007884053090856468, 0.007947814526960428, 0.007957125202119641, 0.007829726662748726, 0.00793273111776216, 0.007797628692969738, 0.007706317994416167, 0.007813734647334059, 0.007744965561869321, 0.00786330574837848, 0.00787271172303008, 0.007843947691799257, 0.007734162162341818, 0.007913411824483773, 0.007864391944349337, 0.007806531319693022, 0.007858075344483951, 0.007761478644715681, 0.007817187401906267, 0.007852108618499188, 0.007783272688720899, 0.0078102362380377596, 0.00783502385202155, 0.0077219061317009615, 0.007784371110392385, 0.007744136610199348, 0.007721781201598788, 0.007748484723015281, 0.007921248737329734, 0.007861044329729339, 0.007856170821651177, 0.007740775924867193, 0.0076393935980377135, 0.007624942149959679, 0.007772425592793297, 0.0076906146487090155, 0.007816951416316442, 0.007840669372671982, 0.007744378546158259, 0.007728884859898244, 0.00785563308872952, 0.007886983648859314, 0.007857041778243002, 0.007939742960115837, 0.007732528347514744, 0.007764273177963332, 0.007774392855390033, 0.00776789208775881, 0.007820075720519525, 0.007722814219050633, 0.00782587133871857, 0.0077628599354284235, 0.007731623608924565, 0.007757500479601731, 0.007689977360860212, 0.007682824772291497, 0.007691883795450849, 0.007625907180772629, 0.007923381521777628, 0.007812103994001518, 0.008209508651816577, 0.00839346987377212, 0.009488163082460232, 0.0095563111388401, 0.009511850526541821, 0.009613509382415942, 0.00857848310679401, 0.008392319828271867, 0.008056313056749786, 0.007837729915809177, 0.007830803043907509, 0.007740512712280179, 0.00783128199291241, 0.007759026872554387, 0.007783622010538238, 0.007749496417636692, 0.007709189339584555, 0.007720498935668729, 0.007787683662809286, 0.007791429519602389, 0.007704672504496557, 0.007708411060957587, 0.007682912123709684, 0.00763819357362081, 0.00770408790131114, 0.007608173552216613, 0.007740260957143618, 0.0076278084148725615, 0.007688234449142328, 0.007728227124243858, 0.007628176019716193, 0.0076216808834033145, 0.007641610542304988, 0.007570265749291138, 0.007701759360497817, 0.0076485957088152645, 0.007706847249573911, 0.007581731739628594, 0.0077265875917873926, 0.007762366041333735, 0.007718159586056572, 0.007636810395160865, 0.007670768789103022, 0.007691940813356268, 0.007618448838911718, 0.007631841886268376, 0.007606050994763791, 0.007774666398108821, 0.007668068865496025, 0.007733507021657715, 0.0075730859232862715, 0.007594463441728294, 0.007551189586320106, 0.007530621440128016, 0.007623086697822146, 0.007592571259283432, 0.007684629731920722, 0.007569457386489375, 0.007708513176385168, 0.007666161533961713, 0.007663567266172322, 0.007617460180154012, 0.007544114436404925, 0.007616276225780894, 0.007601290155434981, 0.007619891013746383, 0.007483901807518123, 0.007674853866956255, 0.007569892542778689, 0.007567037998887827, 0.007642338507503154, 0.007628381720223842, 0.007774800798324577, 0.0076255725442024415, 0.007705820003320696, 0.007560746433227905, 0.007526025810147985, 0.0074603253377063085, 0.007582055166585633, 0.007513968192324682, 0.007787585963251331, 0.00774686088634553, 0.007608450611678563, 0.007769122628269542, 0.007588743892301864, 0.007742428875644691, 0.007603980291787593, 0.007635406190820504, 0.007697926542641653, 0.007628519907302689, 0.007560718440527125, 0.0075015075025476104, 0.007381629064821027, 0.007627288475123351, 0.007400451069770497, 0.007563897140789777, 0.007748087762502109, 0.007612135479575954, 0.0076145595959133065, 0.0076694563528690194, 0.007535440206174826, 0.007519461090305412, 0.007663333173695719, 0.007654277590791026, 0.007604502981848782, 0.007711567062051472, 0.007640869297119934, 0.007529498937765311, 0.0075878807129811324, 0.007487734986625583, 0.007448267661948194, 0.007725564283555286, 0.007697904905126052, 0.007455995082636946, 0.0076094730302429525, 0.007481564473619073, 0.0076212018351725416, 0.007513627431399073, 0.007576025196431147, 0.0074577382813913575, 0.007652355849586456, 0.007581840058537637, 0.0074971163760892525, 0.007491047688836261, 0.007486158024767065, 0.007605612594579725, 0.007685509407201608, 0.007496527288822108, 0.007542326373823016, 0.007489680556591338, 0.007577311206296145, 0.007700974524777848, 0.007542886204555543, 0.007500744315211705, 0.007475884466293792, 0.007686286164243938, 0.007485971134383362, 0.007445969649779727, 0.007535041708024437, 0.007553461087263713, 0.007645566930023051, 0.007492771691067901, 0.007385829182294401, 0.007486919608527387, 0.007604841352076619, 0.00773350298168225, 0.007498153030974208, 0.007475384684221353, 0.007489427851578512, 0.007681158357081585, 0.007346602383586287, 0.007401638070859917, 0.0075132821503757444, 0.0074667509155915465, 0.007587641833742964, 0.007414980641624424, 0.007470560958154238, 0.007732090658009838, 0.007463127670234826, 0.0074884563729028745, 0.0076608879109699045, 0.0074465281095399405, 0.007584549816147046, 0.0075921082388049396, 0.007611451177763229, 0.007384879889650619, 0.007447038495411107, 0.007513864694919903, 0.007564068149986269, 0.007726443398223637, 0.00755008451806134, 0.0077172620215606004, 0.007499115776408871, 0.007453766319213173, 0.007524081055271381, 0.007530526568689311, 0.007368739493358589, 0.007599748002849083, 0.007643466523040843, 0.007548648132797098, 0.0075349059427026075, 0.007511066301594838, 0.007469389474317722, 0.007701923590320803, 0.007480060431316815, 0.007640784424893354, 0.00756177819075674, 0.007537165272788115, 0.007504882461762463, 0.007509597211264918, 0.0075103897842836885, 0.007607030599774589, 0.007390939589822665, 0.007640290773451852, 0.007553879697388766, 0.0074329252647657995, 0.007489008990978619, 0.007436548960868095, 0.007370289338632574, 0.007533107671633843, 0.007466203197373034, 0.0073936750122811645, 0.007370811440159742, 0.007445933848521236, 0.007362393246512511, 0.007609958789998927, 0.007657596953777102, 0.007529506566606869, 0.0073991236287838545, 0.007545020812176517, 0.007617583772753278, 0.007611538512355765, 0.007586857721116757, 0.007383440614466963, 0.007298672319211619, 0.007393773958574457, 0.007480525527944338, 0.0073158911731752594, 0.007359628825452091, 0.007295304481249332, 0.0073479784677147105, 0.007450439788772201, 0.007427060832105781, 0.007466499652264247, 0.00743607249823981, 0.007461279246399499, 0.007483419085428977, 0.0077661942927079505, 0.007527800973730336, 0.007455356553145975, 0.007581468757598487, 0.007574030510477314, 0.007510870687292481, 0.007458868379762862, 0.0075651921881217275, 0.007605425830206514, 0.007377783941319649, 0.007472625867922034, 0.007531767579257576, 0.007676094362886942, 0.007449199557413522, 0.0074284217212152726, 0.007580786196422195, 0.007375998771567538, 0.007392335699159957, 0.007342163742123375, 0.007568413582794165, 0.007424341616069796, 0.0073610582420769784, 0.007689949042787703, 0.007537088566868988, 0.007696732820659235, 0.0075153124936150565, 0.007429678833159414, 0.007586154932141653, 0.008328198996059655, 0.008994321955378836, 0.008937903429432481, 0.01035249749884315, 0.008782020827356973, 0.008590275054666563, 0.00806776150366204, 0.007689490810344068, 0.0076889873308573446, 0.0076237455390128165, 0.00742060852371651, 0.007552408147921597, 0.007409712890148512, 0.007580236198009516, 0.007502943493273051, 0.007491087519633765, 0.007537324290797187, 0.007538098377517599, 0.007460671260469098, 0.0074893603513373815, 0.007376570592441567, 0.00741611551038659, 0.007407536511118451, 0.007372460020178551, 0.007521139116488484, 0.007396472952223121, 0.007494776047087726, 0.007584479718070724, 0.007480825021411874, 0.007423418203961774, 0.007634026494451973, 0.007570540628967138, 0.007368579771764416, 0.0074168782457036285, 0.007464066911234113]
Avg. validation loss: [0.4569307744503021, 0.43886678442358973, 0.48882304728031156, 0.4799553968012333, 0.5148689679801464, 0.5192307397723198, 0.4966708704829216, 0.5044738404452801, 0.484308473020792, 0.5020983338356018, 0.5047754168510437, 0.500947042554617, 0.4896546870470047, 0.5031868755817414, 0.4833370640873909, 0.48559941798448564, 0.48811383098363875, 0.49410380199551585, 0.49107133224606514, 0.5037888914346695, 0.49083151668310165, 0.5020345769822597, 0.4929586127400398, 0.49299010038375857, 0.4863777384161949, 0.49790555238723755, 0.49459461569786073, 0.49102977216243743, 0.48325804620981216, 0.48559625297784803, 0.5011834688484669, 0.48611256331205366, 0.49840456396341326, 0.5084529846906662, 0.5007524937391281, 0.49149759858846664, 0.4869782358407974, 0.48756060302257537, 0.4967395581305027, 0.4883259154856205, 0.5020925506949425, 0.4874980241060257, 0.4971097782254219, 0.48776835501194, 0.48923213332891463, 0.4895996913313866, 0.4863340355455875, 0.4919620051980019, 0.4828989565372467, 0.48175962045788767, 0.49729731380939485, 0.4729042276740074, 0.49189291447401046, 0.4897833563387394, 0.4927546218037605, 0.4941320553421974, 0.4969819724559784, 0.4887807086110115, 0.4784685388207436, 0.48394561260938646, 0.48892042338848113, 0.49121685326099396, 0.48712514713406563, 0.4876035526394844, 0.4917845241725445, 0.4883180566132069, 0.4882285431027412, 0.4869487628340721, 0.4823873594403267, 0.49693852588534354, 0.49575580805540087, 0.48535448536276815, 0.48351198583841326, 0.4869801938533783, 0.4872580453753471, 0.4911032021045685, 0.4898043662309647, 0.4866266041994095, 0.48201919719576836, 0.4975258782505989, 0.4886698789894581, 0.4837049260735512, 0.4940374791622162, 0.4871759615838528, 0.48494709134101865, 0.48372309356927873, 0.48640556260943413, 0.4862983599305153, 0.4826881498098373, 0.48330156654119494, 0.4936329424381256, 0.4915312394499779, 0.49019443392753603, 0.48396496698260305, 0.4897936373949051, 0.4892399996519089, 0.49657989144325254, 0.48716878816485404, 0.47059220969676974, 0.4847350768744946, 0.48116152361035347, 0.4881003350019455, 0.4865956798195839, 0.4854713059961796, 0.4841287612915039, 0.48890508264303206, 0.48930913060903547, 0.47458471432328225, 0.4782287023961544, 0.486721009016037, 0.4845479644834995, 0.489288917183876, 0.48448515087366106, 0.4841278277337551, 0.4854955732822418, 0.4831576496362686, 0.48507509380578995, 0.47605776488780976, 0.4893657982349396, 0.4881161913275719, 0.49011293053627014, 0.4800483323633671, 0.4755246892571449, 0.48531086593866346, 0.4877358987927437, 0.4885129988193512, 0.4894914776086807, 0.4855149440467358, 0.4846486791968346, 0.48081511855125425, 0.4868972487747669, 0.488319194316864, 0.48779628351330756, 0.4925058573484421, 0.48910651057958604, 0.48918613865971566, 0.4882078066468239, 0.4855542741715908, 0.4875458344817162, 0.4874865636229515, 0.4906897559762001, 0.4957118213176727, 0.4822940967977047, 0.48801783546805383, 0.47266926765441897, 0.47361287474632263, 0.4845579795539379, 0.48137183040380477, 0.47889858260750773, 0.4798357754945755, 0.487582852691412, 0.4925220787525177, 0.47521418929100034, 0.49006674364209174, 0.48822171315550805, 0.48066879212856295, 0.4901518478989601, 0.49267019480466845, 0.48555964082479475, 0.47847321927547454, 0.48073228299617765, 0.4794061467051506, 0.4764628246426582, 0.49398512542247774, 0.4895299822092056, 0.48109537959098814, 0.4853007778525352, 0.4775423273444176, 0.4867420315742493, 0.490295571833849, 0.47952180802822114, 0.48454001545906067, 0.48700471222400665, 0.4889079689979553, 0.48439107537269593, 0.47162842005491257, 0.4813487738370895, 0.4791299901902676, 0.48434211015701295, 0.48480679765343665, 0.4884703256189823, 0.46769560500979424, 0.4845359377563, 0.4865816459059715, 0.492879169434309, 0.4864714056253433, 0.4864947095513344, 0.47826688587665556, 0.4814715921878815, 0.491254360973835, 0.4816797114908695, 0.48868540972471236, 0.4899796634912491, 0.48299094289541245, 0.49318241849541666, 0.47404746115207674, 0.48795748203992845, 0.481953651458025, 0.49325002655386924, 0.4853022575378418, 0.4848123475909233, 0.48826138526201246, 0.48022988364100455, 0.4884225234389305, 0.49785819202661513, 0.4836532101035118, 0.4855560764670372, 0.47719546779990196, 0.48800201416015626, 0.4895682767033577, 0.4979386106133461, 0.4861868001520634, 0.4792144030332565, 0.48339262753725054, 0.4912989616394043, 0.4859789557754993, 0.4858654856681824, 0.47821695655584334, 0.48909829556941986, 0.4921561822295189, 0.4906917169690132, 0.48615275919437406, 0.49148762971162796, 0.48256275355815886, 0.483277603238821, 0.49633087068796156, 0.4942764438688755, 0.48535868972539903, 0.48537336140871046, 0.49439393579959867, 0.47699962109327315, 0.4870331481099129, 0.49678262174129484, 0.4841822534799576, 0.485040832310915, 0.48724078983068464, 0.48775987774133683, 0.48965795934200285, 0.4783387154340744, 0.4910245016217232, 0.4926281586289406, 0.48516946732997895, 0.491111009567976, 0.4838863596320152, 0.4856811694800854, 0.48579818308353423, 0.48912175223231313, 0.4828014522790909, 0.49384673982858657, 0.4814179837703705, 0.47752960324287413, 0.4801329143345356, 0.48998322859406473, 0.49232632368803025, 0.4911541178822517, 0.4891100227832794, 0.4862318731844425, 0.49345454573631287, 0.4882119119167328, 0.4950808443129063, 0.49099377542734146, 0.47970675826072695, 0.4838886596262455, 0.48567166924476624, 0.48967305570840836, 0.49218489825725553, 0.48501923829317095, 0.48190019875764845, 0.4864366248250008, 0.4826700806617737, 0.49484180212020873, 0.4881132036447525, 0.4878946378827095, 0.48550162091851234, 0.4808015935122967, 0.4871102228760719, 0.48619038984179497, 0.49315742403268814, 0.48233144357800484, 0.4838095635175705, 0.48707700744271276, 0.4827914111316204, 0.4771702915430069, 0.49070034474134444, 0.48539103344082835, 0.4971254125237465, 0.49188153371214866, 0.4923484638333321, 0.5016330376267433, 0.4855804406106472, 0.4853408753871918, 0.4819160096347332, 0.48842021748423575, 0.4809468753635883, 0.4865006282925606, 0.4846100077033043, 0.486487103253603, 0.4882653161883354, 0.493657935410738, 0.48766354769468306, 0.48311723172664645, 0.49069899022579194, 0.4933182023465633, 0.48735029250383377, 0.4890481546521187, 0.4887034773826599, 0.49384753331542014, 0.48759234622120856, 0.48643435537815094, 0.4847586676478386, 0.49757795333862304, 0.49165128022432325, 0.48212439864873885, 0.4878690347075462, 0.4906793862581253, 0.4936161071062088, 0.4875146083533764, 0.4831415683031082, 0.4897314511239529, 0.4779777877032757, 0.4810680389404297, 0.4858664721250534, 0.501881343126297, 0.49067257940769193, 0.49702283889055254, 0.49496363252401354, 0.48107691705226896, 0.48953804224729536, 0.4864661455154419, 0.48554017692804335, 0.48540926575660703, 0.48521697521209717, 0.49000984206795695, 0.4875761330127716, 0.49024356752634046, 0.49404545947909356, 0.49049784541130065, 0.48569910824298856, 0.48656508028507234, 0.49017634317278863, 0.48692573308944703, 0.4921253427863121, 0.4952420830726624, 0.4894148990511894, 0.48677126616239547, 0.48404840379953384, 0.47986658439040186, 0.4796320557594299, 0.4902834311127663, 0.4784074440598488, 0.49401929453015325, 0.49402315095067023, 0.48393062204122544, 0.4863370358943939, 0.4856821998953819, 0.4973665438592434, 0.4821403153240681, 0.49199583157897, 0.4842779576778412, 0.48820901215076445, 0.4877216547727585, 0.4780149295926094, 0.48730313330888747, 0.4843473345041275, 0.47831838130950927, 0.4956133559346199, 0.48840581625699997, 0.48655194938182833, 0.4864349581301212, 0.48442240953445437, 0.49431673586368563, 0.4885341554880142, 0.4763503596186638, 0.4943220868706703, 0.4944420963525772, 0.48287880048155785, 0.4842975527048111, 0.4944543048739433, 0.4963265724480152, 0.48173566460609435, 0.49180359989404676, 0.4874005541205406, 0.4784594148397446, 0.48513021469116213, 0.4863632507622242, 0.49045361652970315, 0.4843900099396706, 0.48990596905350686, 0.4845441788434982, 0.48044097125530244, 0.4928902819752693, 0.49329095184803007, 0.49069916307926176, 0.48979114890098574, 0.48837157115340235, 0.4919287383556366, 0.47878446727991103, 0.47598733827471734, 0.4953428566455841, 0.49137366414070127, 0.4946800500154495, 0.4889569878578186, 0.4884225748479366, 0.4888481289148331, 0.48429353162646294, 0.49366855174303054, 0.4831562228500843, 0.4876429721713066, 0.49008129090070723, 0.49227291643619536, 0.48824758008122443, 0.4918483138084412, 0.48186159133911133, 0.48515821546316146, 0.4852360934019089, 0.49604652896523477, 0.47952646762132645, 0.49347734823822975, 0.4843983374536037, 0.4853295564651489, 0.4850014917552471, 0.48969407230615614, 0.4890656486153603, 0.4887287274003029, 0.48775513023138045, 0.4842310294508934, 0.49537897258996966, 0.4875890575349331, 0.49156416952610016, 0.4918010547757149, 0.4859632305800915, 0.4940197244286537, 0.48828926384449006, 0.4806963138282299, 0.4932499870657921, 0.48672597110271454, 0.49312798082828524, 0.4887775868177414, 0.488250008970499, 0.490437938272953, 0.4906303912401199, 0.49214951545000074, 0.49402467235922815, 0.4938620090484619, 0.4878497585654259, 0.48667130023241045, 0.4900091841816902, 0.48281384781003, 0.4848591834306717, 0.487711538374424, 0.4898661598563194, 0.4927689552307129, 0.48262733966112137, 0.4852105028927326, 0.4859293833374977, 0.4919335678219795, 0.48835850656032564, 0.4908482253551483, 0.4836547240614891, 0.4851696327328682, 0.4926135204732418, 0.4862047865986824, 0.4869447693228722, 0.4916202753782272, 0.4828640088438988, 0.48637951985001565, 0.4922081671655178, 0.48823957443237304, 0.4957831010222435, 0.47767908200621606, 0.4948834337294102, 0.4830578178167343, 0.4882779262959957, 0.4890921555459499, 0.48755870535969736, 0.4897698760032654, 0.48624613136053085, 0.4906575821340084, 0.4882077470421791, 0.49113585874438287, 0.48886715695261956, 0.4924908570945263, 0.4899890385568142, 0.4904691994190216, 0.49091883301734923, 0.4846771419048309, 0.48592939749360087, 0.49499851539731027, 0.490566711127758, 0.4879598289728165, 0.4908768579363823, 0.4917726442217827, 0.4857574887573719, 0.4887523576617241, 0.4928534761071205, 0.4891871452331543, 0.48610152006149293, 0.4831045985221863, 0.48958549499511717, 0.48481164276599886, 0.49011810272932055, 0.4872331842780113, 0.48126021549105646, 0.49742920994758605, 0.49273812845349313, 0.49001592174172404, 0.4875621870160103, 0.4978677585721016, 0.4905349835753441, 0.4983071818947792, 0.49279097840189934, 0.4818652831017971, 0.48950471729040146, 0.491452094912529, 0.4863508567214012, 0.4967201821506023, 0.4930314257740974, 0.48004285171628, 0.48911393582820895, 0.49301943406462667, 0.49047003835439684, 0.48231358975172045, 0.48595061153173447, 0.48961207941174506, 0.4886984795331955, 0.49218823835253717, 0.482549449801445, 0.48564993739128115, 0.4839507967233658, 0.4915788248181343, 0.48778942227363586, 0.48002090454101565, 0.48698490411043166, 0.4873997405171394, 0.4865855351090431, 0.4926340788602829, 0.48879023641347885, 0.47936073541641233, 0.49297205209732053, 0.48806251510977744, 0.4940586283802986, 0.48705019503831865, 0.4875971630215645, 0.4870409041643143, 0.4894625745713711, 0.4865083031356335, 0.4928686149418354, 0.4907864429056644, 0.48431384935975075, 0.4871939912438393, 0.49277001321315766, 0.49168273285031316, 0.49034792482852935, 0.48842243254184725, 0.4824178464710712, 0.4931830517947674, 0.5006805844604969, 0.48457531854510305, 0.4852517552673817, 0.48909698277711866, 0.48583979830145835, 0.4894407667219639, 0.4921930268406868, 0.4791955702006817, 0.4897379852831364, 0.4897174522280693, 0.4877686560153961, 0.48618790656328204, 0.4810041651129723, 0.48680230230093, 0.48024267256259917, 0.492112372815609, 0.49085274040699006, 0.4872408665716648, 0.48631315007805825, 0.48725236877799033, 0.4915865369141102, 0.49111077934503555, 0.4902633920311928, 0.49209523648023606, 0.4915286585688591, 0.48235846757888795, 0.4853593185544014, 0.4810534939169884, 0.4928041368722916, 0.49582702815532687, 0.49104021191596986, 0.4883517175912857, 0.4857688210904598, 0.4909746825695038, 0.48419475853443145, 0.48754944652318954, 0.4910215899348259, 0.4815690711140633, 0.4772552356123924, 0.4891762174665928, 0.4902622863650322, 0.4947171024978161, 0.4935719072818756, 0.4859093680977821, 0.4812083296477795, 0.4840638615190983, 0.49175295829772947, 0.494536030292511, 0.4884084865450859, 0.4924113407731056, 0.4921391695737839, 0.48268155604600904, 0.4957276061177254, 0.4842470109462738, 0.48801913037896155, 0.49297123551368716, 0.48995873108506205, 0.48697679713368414, 0.4874026671051979, 0.4891771458089352, 0.4880465067923069, 0.4961338996887207, 0.4970742627978325, 0.4803417704999447, 0.49449873715639114, 0.496074940264225, 0.48041837513446806, 0.49204554259777067, 0.49258428514003755, 0.4902721390128136, 0.48744679167866706, 0.47923526763916013, 0.49555438086390496, 0.49520702213048934, 0.48756563663482666, 0.4943681672215462, 0.486075596511364, 0.48405035138130187, 0.4900681532919407, 0.4945934548974037, 0.48975326791405677, 0.4913651019334793, 0.4845240443944931, 0.4978205278515816, 0.4895914763212204, 0.4860440373420715, 0.49390040040016175, 0.4872294381260872, 0.4859947495162487, 0.4883828416466713, 0.48023726269602773, 0.48333433717489244, 0.4892052672803402, 0.48786441683769227, 0.4924992874264717, 0.4889469131827354, 0.4869571000337601, 0.49650816023349764, 0.4821844376623631, 0.486126172542572, 0.48126109763979913, 0.493247228115797, 0.49134145081043246, 0.4931881621479988, 0.4964618481695652, 0.4840745598077774, 0.4916079081594944, 0.4908151999115944, 0.48926759213209153, 0.4915297329425812, 0.49114921391010286, 0.49668623730540273, 0.49361709505319595, 0.4911188334226608, 0.4889961056411266, 0.4828286707401276, 0.4892661809921265, 0.49457131773233415, 0.49642126336693765, 0.4872477546334267, 0.48993982300162314, 0.4937638774514198, 0.49541445821523666, 0.48700771033763884, 0.4947082094848156, 0.4857200957834721, 0.49041929841041565, 0.487150951474905, 0.4894735261797905, 0.4930256322026253, 0.4939840093255043, 0.4834458529949188, 0.48412483260035516, 0.4868958629667759, 0.49324384033679963, 0.491991351544857, 0.489127080142498, 0.48574342802166937, 0.48714028000831605, 0.4906399890780449, 0.4922119311988354, 0.49322124272584916, 0.4919698551297188, 0.49352680891752243, 0.4910909466445446, 0.4835572876036167, 0.49475469067692757, 0.4852083370089531, 0.4866494297981262, 0.49442178905010226, 0.4941735193133354, 0.4848157957196236, 0.4852275617420673, 0.4897757187485695, 0.49140726774930954, 0.48586517944931984, 0.501334385573864, 0.48107141107320783, 0.48493496477603915, 0.4921778984367847, 0.4985558748245239, 0.4811487913131714, 0.5023445591330529, 0.4955277591943741, 0.4856252118945122, 0.49031359180808065, 0.48349362313747407, 0.49290377274155617, 0.49686684012413024, 0.4839960463345051, 0.4939791724085808, 0.4926218330860138, 0.4917395576834679, 0.4894360080361366, 0.4990625575184822, 0.4902100019156933, 0.4951784431934357, 0.49221170619130133, 0.49197917282581327, 0.4943667486310005, 0.48225877434015274, 0.4854418084025383, 0.4918471023440361, 0.49538185596466067, 0.49208163246512415, 0.4925062820315361, 0.48501397743821145, 0.49749004319310186, 0.49070581048727036, 0.48832704573869706, 0.48442985862493515, 0.502384002506733, 0.4918637230992317, 0.4879026755690575, 0.49451824724674226, 0.49564882516860964, 0.49573745802044866, 0.48226305693387983, 0.48841051012277603, 0.49911345839500426, 0.4897936165332794, 0.49001029655337336, 0.4887049816548824, 0.4895965203642845, 0.4927752032876015, 0.4877462528645992, 0.5010982811450958, 0.4968469113111496, 0.48148149996995926, 0.4982139155268669, 0.48276415914297105, 0.48331509679555895, 0.496419158577919, 0.4862182781100273, 0.49524770900607107, 0.49891208335757253, 0.4936255358159542, 0.48748899847269056, 0.49398920983076094, 0.4935093730688095, 0.48785570710897447, 0.5022981360554695, 0.49498703330755234, 0.4835529699921608, 0.4966392800211906, 0.4889316014945507, 0.49012049585580825, 0.4985561728477478, 0.4866962142288685, 0.49473234340548516, 0.4952974945306778, 0.4962366931140423, 0.4895818755030632, 0.4900006726384163, 0.49115360528230667, 0.49005375653505323, 0.49378331899642947, 0.4915536239743233, 0.49809938222169875, 0.49750434011220934, 0.4875262536108494, 0.49241989105939865, 0.48794810101389885, 0.48556418567895887]
Avg. validation r: [0.6639861332694406, 0.7326308647354388, 0.7481210724369447, 0.7392873896849617, 0.7248180765518153, 0.726180011111374, 0.732701183494559, 0.7359565595648936, 0.7359901340962665, 0.7384038594942008, 0.7385931053272721, 0.7378173251942448, 0.7387395325424249, 0.7392894713816094, 0.7401427391928862, 0.73995037680456, 0.738913864906466, 0.7354375701207441, 0.7445766049121878, 0.7444405148786299, 0.7385147048548308, 0.7444466347566985, 0.7424723293382405, 0.7465791502303109, 0.7449792238846981, 0.7455698697223974, 0.744828998143567, 0.7456073994198407, 0.7439150578426599, 0.7477396911813929, 0.7427526700008656, 0.7459281384610358, 0.7468077999843115, 0.7477063592391533, 0.7499497376573876, 0.7453525490657539, 0.7456842412786161, 0.7496378647184587, 0.7490789826362858, 0.7465414448070262, 0.7480490982180873, 0.7487051364883619, 0.747271575257942, 0.7488456752795457, 0.751337247002411, 0.7483730128864429, 0.7508892179816966, 0.749596260065382, 0.7479326494438371, 0.7523441062319947, 0.7497443248045637, 0.7509874481961906, 0.7490673099946383, 0.7514924891878975, 0.7499627360453907, 0.7495634507161044, 0.7528108823198286, 0.7508903463278597, 0.7496080909855467, 0.7525464120767225, 0.7530109678594211, 0.750007850182494, 0.7545211869348034, 0.7512150951508361, 0.7540941736650311, 0.753904655019572, 0.7520626120306503, 0.7501538883435213, 0.7549349753227477, 0.753789485666649, 0.7542528195609588, 0.7524688510234682, 0.7500234388414395, 0.7530366385778754, 0.7520812131834943, 0.7531808132581469, 0.7522842951212356, 0.7548606569322114, 0.7532742580460334, 0.757130354159842, 0.7522936238009902, 0.7560870438662859, 0.7564254270355647, 0.7550760699965332, 0.7543962966227771, 0.7550176834998062, 0.7559123643108503, 0.7554019519811835, 0.7565363375796641, 0.7558529046177022, 0.7570661118792883, 0.7554810411236504, 0.7578030703457561, 0.7561828333426499, 0.7593359439490961, 0.754537469038096, 0.7578575498938734, 0.755929290116077, 0.7571963105259687, 0.7571151478876242, 0.755326631734506, 0.7567406322773689, 0.7587170139984231, 0.7564497426964996, 0.7569187153539412, 0.7552868073736809, 0.7573434715852323, 0.7559124234511894, 0.756327622504113, 0.7571052951396574, 0.7586985863342928, 0.7567187341332763, 0.7575945235051295, 0.7566545664188091, 0.757112926654633, 0.7579597894159916, 0.7595667798200175, 0.7575184736256692, 0.7570668297755285, 0.7593720771311839, 0.7575351150612335, 0.7584656193597065, 0.7572783375477373, 0.7576137985578273, 0.7592132184593304, 0.7571119111590183, 0.7592435467888411, 0.7592685706627155, 0.7581261351480106, 0.7597714452390597, 0.7580452466621365, 0.7590385582598806, 0.7573771815514072, 0.7585372976232805, 0.7594166065639, 0.7599932088254577, 0.7610960662486148, 0.7599968115658445, 0.7603273540593166, 0.7599552841709141, 0.7584062922328922, 0.7576872862751716, 0.7606391663164598, 0.7604245268542005, 0.760583020542388, 0.7573700221667219, 0.762477411961438, 0.7589265905376016, 0.7601097056718965, 0.7583253841559089, 0.7630025786499506, 0.7590661259152575, 0.7605787730320626, 0.7623773718747191, 0.7607616950126953, 0.758483924402176, 0.7585768772665519, 0.7640315783895973, 0.7596593118724334, 0.7601892062784084, 0.7595624907198427, 0.7622248458580481, 0.7605062808666202, 0.7599951129382918, 0.7600802180860843, 0.7599269490665852, 0.7607946315997532, 0.759825708095198, 0.7616755933101086, 0.7624707865761, 0.7592936218511496, 0.7588616678757863, 0.7607135072558456, 0.761247661943826, 0.7616155243657348, 0.7601728325981238, 0.760564430353007, 0.7616060377868157, 0.7588991069618659, 0.7599607365513427, 0.7619614367779345, 0.7631724315638018, 0.7608819470253814, 0.7624452138093633, 0.7604739929077858, 0.7618780890791008, 0.7612462683210508, 0.7633522861210458, 0.7618149949025963, 0.7635569633225863, 0.7626620310770269, 0.7642384831796707, 0.7620058647857542, 0.7601239909378522, 0.7628046840009759, 0.7628172975420893, 0.7627940133253642, 0.7629996007523466, 0.7624753998380214, 0.7620514447555127, 0.7609016589088411, 0.7633693959434257, 0.7625537268251694, 0.7621744889782074, 0.7629379017901199, 0.7610970707341638, 0.7632979632308554, 0.7631670076557132, 0.7640295078667185, 0.7630965083084289, 0.7620705200885818, 0.7636907027011368, 0.7608723057668362, 0.7626975771558426, 0.7632194083418209, 0.7633305357657669, 0.7619305077183067, 0.762223156807688, 0.7613169751624417, 0.7635900998974128, 0.7613489170325061, 0.7643364152991473, 0.7627463743685895, 0.7606625872610264, 0.7610303430635007, 0.7627387881895765, 0.7641332819283612, 0.7626599024605445, 0.7629269632713304, 0.7627839664384944, 0.7616633380711002, 0.7637669511316119, 0.7637474030860163, 0.7628352390212411, 0.7633312085778048, 0.762257865451862, 0.7610108779613078, 0.7614369587697467, 0.7623879600584438, 0.7629828968905036, 0.7616521604970923, 0.7634814123163236, 0.7612626489807857, 0.7628259483329305, 0.7634593091314701, 0.7627754484053328, 0.7624770997146735, 0.7620714539844077, 0.7622287953546676, 0.7638705351867296, 0.761124847352187, 0.7615182642134835, 0.7627282791090574, 0.7614537094357205, 0.761337867950786, 0.7640245108252104, 0.7606129611138324, 0.7633094335632418, 0.7635880766977048, 0.7616397268873965, 0.764016300172717, 0.7611321907341844, 0.7598445994587507, 0.762361844948672, 0.761308398349168, 0.7647030015349596, 0.7608196623756383, 0.7628778649884067, 0.7628647487070894, 0.7618000578979336, 0.7625258026767618, 0.7628905173697514, 0.7604387032277933, 0.7636454438419825, 0.7610218682317245, 0.76218900629624, 0.7618660588781488, 0.7638121004529989, 0.7634947208230509, 0.763166565383473, 0.7628533310674495, 0.764108736907813, 0.7637017322884079, 0.7624233767087611, 0.7628151529874472, 0.763415333808037, 0.7596807081529358, 0.7627634395106642, 0.7620746564937667, 0.7627287429630949, 0.7629977999634596, 0.7615587259781329, 0.7638070741724109, 0.7640482540744322, 0.7638046576393008, 0.764380969987941, 0.7636759280498338, 0.7604678086599866, 0.7617707559632839, 0.7617076026976606, 0.7608965292886826, 0.7619595129887314, 0.7616128748421194, 0.7604111520303289, 0.7615515967946049, 0.7601288490566105, 0.764089880956168, 0.7601570307317362, 0.7610997602636219, 0.7604444415848693, 0.7630116041851325, 0.7616738278093698, 0.7625393010925438, 0.7604096998312985, 0.7618039404458028, 0.7630521233268119, 0.760858782677835, 0.7632428913977023, 0.7635292484244955, 0.7602018203973395, 0.7601945455704888, 0.7643313201634653, 0.7615906478926038, 0.7626372457362434, 0.7609610768313958, 0.7619158194473138, 0.7626966364408865, 0.7619241869348995, 0.761603934597493, 0.7621095081743452, 0.7627591325053258, 0.7637323308138072, 0.7616916206121764, 0.7623420143458839, 0.7624452170811129, 0.7627249059658244, 0.7618002590143381, 0.7624060305789092, 0.7646794700765864, 0.7623400768771542, 0.7624742757810161, 0.7620695206508021, 0.762256378704852, 0.762952309792112, 0.7654399860244704, 0.7633922873505595, 0.7623765215681549, 0.7554890126667115, 0.7583398310076752, 0.7586703513009083, 0.7622209865142389, 0.7619126029307257, 0.7625959043018141, 0.7619690365780539, 0.7639613176935743, 0.7634089238384405, 0.7604898508392618, 0.7622668735961122, 0.7614925842904346, 0.7628497042896002, 0.7629306370803006, 0.7641877029164494, 0.7637236666403756, 0.7651224911521559, 0.7624118721558464, 0.7625725203465228, 0.7630481292908857, 0.7653851865509134, 0.7663225458109331, 0.7623289649998967, 0.7613496306285589, 0.7630223478208729, 0.7628465301647507, 0.7641970731485317, 0.7611823997020242, 0.7617826007712656, 0.7643239492123376, 0.7649701719199994, 0.7615479644104278, 0.7611627701977707, 0.7625046839323801, 0.7639223943876775, 0.7629280702798391, 0.763196785188795, 0.7647908656950809, 0.7642668929494106, 0.7642980943001914, 0.7633501438106304, 0.763719556387789, 0.7620355325803099, 0.7626097901059089, 0.7653617210579551, 0.764049454820355, 0.761132166344983, 0.7636759852742839, 0.7628043910904004, 0.7644590205621755, 0.7650524656418639, 0.7602304771502586, 0.7632551534598317, 0.7624245428134712, 0.7619229684015432, 0.7629287941591538, 0.763795755302955, 0.7648004512560276, 0.7618006444464414, 0.7646656858201356, 0.761390754133822, 0.762721606680821, 0.761705367134493, 0.7642678129069056, 0.7630651747688937, 0.7645120343698995, 0.7625259493224573, 0.7631347147424608, 0.7635417196442474, 0.7636537480362444, 0.764385407743418, 0.7616824244829378, 0.7611569601892441, 0.7604060890303497, 0.7616985013719747, 0.7622269578205227, 0.763453672754062, 0.7644744434790938, 0.7637900308261614, 0.7610102299970636, 0.7630726564971164, 0.7619765766041457, 0.7615719292474121, 0.7632675512499734, 0.7603157755111137, 0.7607188759000076, 0.7623097315934457, 0.7630178673413183, 0.7630071770947089, 0.7628828851690088, 0.7618630621323952, 0.7611079900743778, 0.7596096275727307, 0.760268045964519, 0.7555948562841672, 0.7617388292534644, 0.7593024811283089, 0.7611692227515363, 0.7597660643945164, 0.7609492847690105, 0.7581781367149203, 0.7612402248055175, 0.7604278418257208, 0.7572305550081371, 0.7580768048781805, 0.7568846810004353, 0.7615268708348704, 0.7619056560264883, 0.7614307317233386, 0.7604658239157567, 0.7613272030620714, 0.7604092665966651, 0.7599720633609095, 0.7620299244924971, 0.7602795961841652, 0.7594741813703413, 0.7610999647719241, 0.7603407319513678, 0.7593190571142493, 0.7613375275032984, 0.7590139548156012, 0.7605021297107172, 0.7617323554931292, 0.7583839352125531, 0.7592401543897678, 0.7609860263669782, 0.7617143362674778, 0.7602644922515337, 0.7618223517454966, 0.7596140771558242, 0.7607857134451541, 0.7603688591204391, 0.7597875796342541, 0.7626595894062567, 0.7607148870314802, 0.7614760796238299, 0.7601972778929325, 0.7610494084543087, 0.7605999593159064, 0.7597339881597026, 0.7608218421388534, 0.7591207374099775, 0.7599649648240294, 0.7623989696108658, 0.760807429996745, 0.7596957214483895, 0.7624488305212418, 0.7607729143116557, 0.7619808716317535, 0.7590633390675401, 0.7595680529675871, 0.761092326155034, 0.7617377969447295, 0.7595816335547004, 0.7617565041322746, 0.7606578553058977, 0.7610347695007552, 0.7622404209644349, 0.7615262595963231, 0.7607060634174887, 0.7614291022618204, 0.7615626472553035, 0.7598031549217541, 0.7601036400588328, 0.755392228472856, 0.7555594741554637, 0.757566899715344, 0.7573372838360286, 0.7569228461930362, 0.7616943721099748, 0.7575557638929296, 0.758079321872852, 0.7614516921518375, 0.7613244411225989, 0.7608634556664708, 0.763067960538983, 0.7606424686079378, 0.7609279134520278, 0.7598258099874813, 0.7602079472508527, 0.7603227385585047, 0.7597878115840495, 0.7612419288117793, 0.7599952070837503, 0.7604801614434389, 0.7604740139196053, 0.7609149611535505, 0.7608107799529965, 0.7599372210446669, 0.7595540206850594, 0.7584776392203889, 0.7616547859511525, 0.7603812273372498, 0.7593094096250319, 0.7599282315678224, 0.760454367175773, 0.7594544892965718, 0.761104232270321, 0.7604154604833784, 0.7598551071467355, 0.7606355021965274, 0.7595522744439867, 0.7615131444228046, 0.7600278529230485, 0.7621607144353161, 0.7572834765516759, 0.7606512508369091, 0.7615668116429001, 0.7607293065064299, 0.7598812644373929, 0.7607653878915992, 0.75761054406609, 0.7602910929955106, 0.7591171721393734, 0.7586486416996138, 0.7610090936678112, 0.7595395637948215, 0.7605810183519294, 0.7592386062998455, 0.7601438971926496, 0.7609556772604081, 0.7593035402069466, 0.7599102270680135, 0.7597906123272793, 0.7587544858606788, 0.7581621443237061, 0.7608213080185091, 0.7590018941911391, 0.7603157999327486, 0.7598764420611419, 0.7604124505536227, 0.7603831461052886, 0.7596438865529549, 0.7606099727820885, 0.7597041272542634, 0.7589642022821377, 0.7614145778120547, 0.7583757507174707, 0.7589134040597527, 0.7590956820385302, 0.7604897656947054, 0.7590052485167835, 0.759219020204442, 0.7588505598059376, 0.7597175219040129, 0.7606986451294236, 0.7587820845282149, 0.7603011110532656, 0.7592434500006104, 0.7589009333545554, 0.760074895354385, 0.7598076048598378, 0.7590452650354824, 0.7598358566780565, 0.7610640520551656, 0.7589737942611757, 0.7593118209773515, 0.7585164545208972, 0.7592334361213848, 0.7595374867561664, 0.7600052244231181, 0.7587317624603243, 0.7585632215497208, 0.7610337782186349, 0.7591780141636271, 0.758801764215006, 0.7576271311330252, 0.7604154237481836, 0.7602785504373885, 0.7596842969522453, 0.7586253887316553, 0.7574050177338396, 0.7581378415722444, 0.7604750425609941, 0.758520247958576, 0.7569448899159051, 0.7599238425212999, 0.7599510285928217, 0.7582806141611145, 0.7582020699263858, 0.757849174684376, 0.7596745014804913, 0.7562989492497845, 0.7602740290809288, 0.7595446976349813, 0.7580990951555995, 0.75922606650183, 0.7592855483182064, 0.761093390122088, 0.7592821320203914, 0.7601227635537298, 0.7586512616118626, 0.7583281906771623, 0.7591481601485485, 0.7580219203674927, 0.759729266889364, 0.7581529347261946, 0.7581595303252551, 0.7570972422353297, 0.7580091939793492, 0.7588855425468057, 0.7581210758752259, 0.7569338124484712, 0.757738672166739, 0.7579825240124912, 0.756857079168553, 0.75975917540203, 0.759785219422781, 0.7588001307786657, 0.7580327615749304, 0.7603343375476241, 0.7580190607440613, 0.7585750458992123, 0.7594287986224202, 0.7581487425667086, 0.7565824754619263, 0.7576996371164982, 0.7600200610687308, 0.7571951779329207, 0.7592707363277894, 0.758632760441875, 0.758967758898443, 0.7593616508227352, 0.7593051277132313, 0.7585484069087106, 0.7585558886996158, 0.7585785407788771, 0.757948227478763, 0.7586952116188972, 0.7583872951407645, 0.7602537339869044, 0.7598974337092296, 0.7595914106042913, 0.7580179032206742, 0.7582445380354368, 0.7592160804794417, 0.7596530513519894, 0.7587709728226875, 0.7575823141763451, 0.7591391987672058, 0.7568690054328299, 0.7578882982031081, 0.7576376641122137, 0.75820561172703, 0.7583267869840948, 0.7574811746997734, 0.7595744889940118, 0.7592097441963266, 0.7577349082383262, 0.7589144384387557, 0.7590755330333447, 0.7564133579224609, 0.7584409022633652, 0.7573370153007251, 0.7592500642789752, 0.7596245117527526, 0.7578350551812059, 0.7583250648234018, 0.7566617232993719, 0.7579240658212714, 0.7580957498414806, 0.7580977200315769, 0.7592703419833483, 0.7595940791413656, 0.7582693475745284, 0.7581527664310215, 0.7588243942867748, 0.7609682261732494, 0.7592631506095812, 0.7592870103478523, 0.7583555544843984, 0.7580298554368842, 0.7588425756673629, 0.7588601646394205, 0.7611118753557686, 0.7603251576047437, 0.7594592369551035, 0.7593752533820419, 0.7607850112362249, 0.7609921834249114, 0.759939313145469, 0.7588992496006404, 0.7614854668777822, 0.7595765783740027, 0.7588495671505158, 0.7588004738781631, 0.7584130238683032, 0.7584625045715983, 0.7581820047006401, 0.7595132496868967, 0.7580665803271949, 0.7585901366519517, 0.7594451340959647, 0.756830697185167, 0.7582944497817831, 0.7591249297373772, 0.7595425788375086, 0.7583393628937805, 0.7582659669836256, 0.7592666470107765, 0.7581772765890544, 0.7585698455973752, 0.7594747414627987, 0.7587827230632127, 0.7588865751622605, 0.7598018120514137, 0.759032886368719, 0.7584520720598247, 0.7596971543693376, 0.7607788182035532, 0.7590028257699685, 0.7585471024705174, 0.7581491214240884, 0.7600870215517821, 0.7585300389645196, 0.759416389814668, 0.7564583123193557, 0.757773673648388, 0.7575385177336573, 0.7553343271602663, 0.7617770131857894, 0.7552846655163016, 0.7563795881781542, 0.7521259733588047, 0.7530769046654039, 0.7550053216615534, 0.7566365106719066, 0.7566580993979279, 0.7556004970355864, 0.7552299665758823, 0.7546539806299701, 0.7546395079462793, 0.7547688154176198, 0.7561577336311706, 0.755096389748104, 0.7549316995399742, 0.7570072779243497, 0.7564204667053381, 0.7546449156613295, 0.7555019575532713, 0.7553359647820608, 0.7564884678714785, 0.7576538265311206, 0.7569385535632114, 0.7557151100153902, 0.7582623590767047, 0.756184070308964, 0.7564624723136134, 0.7558749518259372, 0.7556064326045207, 0.7573120422775095, 0.7569934927002759, 0.7551247163339183]
